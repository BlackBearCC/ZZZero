#!/usr/bin/env python3
"""
è§’è‰²æ‰®æ¼”æ•°æ®ç”ŸæˆæœåŠ¡å™¨ - ç®€åŒ–ç‰ˆMCPæœåŠ¡
ä¸¤æ­¥æ ¸å¿ƒæµç¨‹ï¼š
1. æ ¹æ®CSVè§„åˆ’ç”Ÿæˆä¸­ç­‰æ—¥æœŸå®‰æ’
2. æ ¹æ®ä¸­ç­‰å®‰æ’ç”Ÿæˆæ¯å¤©5æ—¶é—´æ®µå…·ä½“å®‰æ’åŠæ¦‚è¦
"""
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import json
import asyncio
import logging
import csv
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

# ä½¿ç”¨æœ¬åœ°mcpæ¨¡å—
from mcp.server.stdio_server import StdioMCPServer
from mcp.types import Tool, ToolInputSchema

# å¯¼å…¥é¡¹ç›®çš„LLMç³»ç»Ÿ
from src.llm.base import LLMFactory
from src.core.types import LLMConfig, Message, MessageRole

# ç¡®ä¿LLMæä¾›å•†å·²æ³¨å†Œ
try:
    from src.llm.doubao import DoubaoLLM
except ImportError:
    pass

logger = logging.getLogger(__name__)


class SimpleScheduleData:
    """ç®€åŒ–çš„æ—¥ç¨‹æ•°æ®ç»“æ„"""
    
    def __init__(self):
        self.csv_events = []  # CSVä¸­çš„å¹´åº¦äº‹ä»¶
        self.medium_arrangements = []  # ä¸­ç­‰ç²’åº¦å®‰æ’ï¼ˆç¬¬ä¸€æ­¥è¾“å‡ºï¼‰
        self.daily_summaries = {}  # æ¯æ—¥æ¦‚è¦ {day_index: summary}
        self.character_description = ""
        self.csv_file_path = ""


class SimpleLLMCaller:
    """ç®€åŒ–çš„LLMè°ƒç”¨å™¨"""
    
    def __init__(self):
        self.llm_provider = None
        self._initialize_llm()
        
    def _initialize_llm(self):
        """åˆå§‹åŒ–LLMæä¾›è€…"""
        provider = os.getenv("LLM_PROVIDER", "doubao")
        model_name = os.getenv("LLM_MODEL_NAME", "ep-20250221154410-vh78x")
        api_key = os.getenv("ARK_API_KEY") or os.getenv("DOUBAO_API_KEY")
        api_base = os.getenv("DOUBAO_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
        
        try:
            llm_config = LLMConfig(
                provider=provider,
                model_name=model_name,
                api_key=api_key,
                api_base=api_base,
                temperature=0.4,
                timeout=600
            )
            
            self.llm_provider = LLMFactory.create(llm_config)
            logger.info(f"âœ… LLMåˆå§‹åŒ–æˆåŠŸ: {provider}/{model_name}")
            
        except Exception as e:
            logger.error(f"âŒ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_provider = None
    
    async def call_llm(self, prompt: str, max_tokens: int = 2000) -> Tuple[bool, str]:
        """è°ƒç”¨LLM"""
        if not self.llm_provider:
            return False, "LLMæœåŠ¡æœªåˆå§‹åŒ–"
        
        try:
            await self.llm_provider.initialize()
            
            messages = [
                Message(role=MessageRole.SYSTEM, 
                       content="ä½ æ˜¯ä¸“ä¸šçš„æ—¥ç¨‹è§„åˆ’åŠ©æ‰‹ï¼Œèƒ½å¤Ÿç”Ÿæˆè¯¦ç»†å®ç”¨çš„æ—¥ç¨‹å®‰æ’ã€‚"),
                Message(role=MessageRole.USER, content=prompt)
            ]
            
            response = await self.llm_provider.generate(
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            return True, response.content
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return False, f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.llm_provider:
            try:
                await self.llm_provider.cleanup()
            except Exception as e:
                logger.warning(f"LLMæ¸…ç†å¤±è´¥: {e}")


class SimpleScheduleGenerator:
    """ç®€åŒ–çš„æ—¥ç¨‹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.llm_caller = SimpleLLMCaller()
        self.output_dir = Path("workspace/simple_schedule_output")
        self.output_dir.mkdir(exist_ok=True)
        
    def load_csv_schedule(self, csv_file_path: str) -> Tuple[bool, str, List[Dict[str, Any]]]:
        """åŠ è½½CSVå¹´åº¦æ—¥ç¨‹æ–‡ä»¶"""
        try:
            csv_path = Path(csv_file_path)
            if not csv_path.exists():
                return False, f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}", []
            
            events = []
            with open(csv_path, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row_idx, row in enumerate(reader, 1):
                    # åŸºæœ¬å­—æ®µéªŒè¯
                    if not all(row.get(field, '').strip() for field in ['æœˆä»½', 'æ—¥æœŸ', 'æ´»åŠ¨ç±»å‹', 'å…·ä½“å®‰æ’']):
                        logger.warning(f"ç¬¬{row_idx}è¡Œæ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡")
                        continue
                    
                    # è§£ææ—¥æœŸ
                    start_date, end_date = self._parse_date_range(row.get('æœˆä»½', ''), row.get('æ—¥æœŸ', ''))
                    if not start_date:
                        logger.warning(f"ç¬¬{row_idx}è¡Œæ—¥æœŸè§£æå¤±è´¥ï¼Œè·³è¿‡")
                        continue
                    
                    event = {
                        'month': row.get('æœˆä»½', '').strip(),
                        'date_range': row.get('æ—¥æœŸ', '').strip(),
                        'start_date': start_date,
                        'end_date': end_date,
                        'activity_type': row.get('æ´»åŠ¨ç±»å‹', '').strip(),
                        'activity_name': row.get('å…·ä½“å®‰æ’', '').strip(),
                        'location': row.get('åœ°ç‚¹', '').strip(),
                        'remarks': row.get('å¤‡æ³¨', '').strip()
                    }
                    events.append(event)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(events)} ä¸ªå¹´åº¦äº‹ä»¶")
            return True, f"æˆåŠŸåŠ è½½ {len(events)} ä¸ªå¹´åº¦äº‹ä»¶", events
            
        except Exception as e:
            error_msg = f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg, []
    
    def _parse_date_range(self, month_str: str, date_range: str) -> Tuple[Optional[datetime], Optional[datetime]]:
        """è§£ææ—¥æœŸèŒƒå›´ï¼Œæ˜ å°„åˆ°2025å¹´6æœˆ24æ—¥å¼€å§‹çš„557å¤©"""
        try:
            month = int(month_str.replace('æœˆ', ''))
            base_date = datetime(2025, 6, 24)
            total_days = 557  # åˆ°2027å¹´1æœˆ1æ—¥
            
            # å°†åŸå§‹12ä¸ªæœˆæ˜ å°„åˆ°557å¤©
            month_start_ratio = (month - 1) / 12.0
            month_end_ratio = month / 12.0
            
            # è§£ææ—¥æœŸèŒƒå›´
            if '-' in date_range:
                start_day, end_day = date_range.split('-')
                start_day = int(start_day)
                end_day = int(end_day)
            else:
                start_day = end_day = int(date_range)
            
            # è®¡ç®—åœ¨æœˆä»½å†…çš„ä½ç½®
            days_in_month = 31
            day_start_ratio = (start_day - 1) / days_in_month
            day_end_ratio = end_day / days_in_month
            
            # è®¡ç®—åœ¨æ•´ä¸ª557å¤©ä¸­çš„ä½ç½®
            absolute_start_ratio = month_start_ratio + (month_end_ratio - month_start_ratio) * day_start_ratio
            absolute_end_ratio = month_start_ratio + (month_end_ratio - month_start_ratio) * day_end_ratio
            
            start_offset_days = int(absolute_start_ratio * total_days)
            end_offset_days = int(absolute_end_ratio * total_days)
            
            start_date = base_date + timedelta(days=start_offset_days)
            end_date = base_date + timedelta(days=end_offset_days)
            
            return start_date, end_date
            
        except Exception as e:
            logger.error(f"æ—¥æœŸè§£æå¤±è´¥ {month_str}-{date_range}: {e}")
            return None, None
    
    async def generate_schedule(self, csv_file_path: str, character_description: str = "", 
                               max_days: int = 7) -> Dict[str, Any]:
        """
        ä¸¤æ­¥ç”Ÿæˆæ—¥ç¨‹ï¼š
        1. ç”Ÿæˆä¸­ç­‰æ—¥æœŸå®‰æ’
        2. ç”Ÿæˆæ¯å¤©å…·ä½“å®‰æ’
        """
        start_time = datetime.now()
        generation_id = f"simple_{int(start_time.timestamp())}"
        
        logger.info(f"ğŸš€ å¼€å§‹ç®€åŒ–æ—¥ç¨‹ç”Ÿæˆï¼Œç”ŸæˆID: {generation_id}")
        logger.info(f"ğŸ“‹ CSVæ–‡ä»¶: {csv_file_path}")
        logger.info(f"ğŸ¯ ç”Ÿæˆå¤©æ•°: {max_days}")
        
        try:
            # åŠ è½½CSV
            success, message, events = self.load_csv_schedule(csv_file_path)
            if not success:
                return {"success": False, "error": message}
            
            # åˆå§‹åŒ–æ•°æ®
            schedule_data = SimpleScheduleData()
            schedule_data.csv_events = events
            schedule_data.character_description = character_description
            schedule_data.csv_file_path = csv_file_path
            
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆä¸­ç­‰æ—¥æœŸå®‰æ’
            logger.info("ğŸ“Š ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆä¸­ç­‰æ—¥æœŸå®‰æ’...")
            medium_success = await self._generate_medium_arrangements(schedule_data, max_days)
            if not medium_success:
                return {"success": False, "error": "ä¸­ç­‰æ—¥æœŸå®‰æ’ç”Ÿæˆå¤±è´¥"}
            
            # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ¯å¤©å…·ä½“å®‰æ’
            logger.info("ğŸ“… ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ¯å¤©å…·ä½“å®‰æ’...")
            daily_results = await self._generate_daily_arrangements(schedule_data, max_days)
            
            # ä¿å­˜ä¸ºCSV
            csv_file = await self._save_to_csv(daily_results, max_days)
            
            end_time = datetime.now()
            total_time = (end_time - start_time).total_seconds()
            
            return {
                "generation_id": generation_id,
                "success": True,
                "csv_file_path": csv_file_path,
                "character_description": character_description[:100] + "..." if len(character_description) > 100 else character_description,
                "max_days": max_days,
                "csv_events_count": len(events),
                "medium_arrangements_count": len(schedule_data.medium_arrangements),
                "daily_results": daily_results,
                "output_csv_file": csv_file,
                "generation_time": total_time,
                "started_at": start_time.isoformat(),
                "completed_at": end_time.isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ æ—¥ç¨‹ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "generation_id": generation_id,
                "success": False,
                "error": f"æ—¥ç¨‹ç”Ÿæˆå¤±è´¥: {str(e)}",
                "started_at": start_time.isoformat()
            }
    
    async def _generate_medium_arrangements(self, schedule_data: SimpleScheduleData, max_days: int) -> bool:
        """ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆä¸­ç­‰ç²’åº¦çš„æ—¥æœŸå®‰æ’"""
        try:
            # æ„å»ºCSVäº‹ä»¶æ‘˜è¦
            events_summary = "å¹´åº¦é‡è¦äº‹ä»¶å®‰æ’:\n"
            for event in schedule_data.csv_events:
                events_summary += f"- {event['start_date'].strftime('%Y-%m-%d')} è‡³ {event['end_date'].strftime('%Y-%m-%d')}: {event['activity_type']} - {event['activity_name']}\n"
            
            # æ„å»ºä¸­ç­‰å®‰æ’ç”Ÿæˆæç¤ºè¯
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¹´åº¦äº‹ä»¶å®‰æ’ï¼Œä¸ºè§’è‰²åˆ¶å®š{max_days}å¤©çš„ä¸­ç­‰ç²’åº¦æ—¥æœŸå®‰æ’ã€‚

ã€è§’è‰²è®¾å®šã€‘
{schedule_data.character_description if schedule_data.character_description else "æœªæŒ‡å®šè§’è‰²ï¼Œè¯·è®¾å®šä¸€ä¸ªåˆç†çš„æ—¥å¸¸ç”Ÿæ´»è§’è‰²"}

ã€å¹´åº¦äº‹ä»¶å®‰æ’ã€‘
{events_summary}

ã€æ—¶é—´èŒƒå›´ã€‘
ä»2025å¹´6æœˆ24æ—¥å¼€å§‹çš„{max_days}å¤©

è¯·ç”Ÿæˆä¸­ç­‰ç²’åº¦çš„å®‰æ’ï¼ˆä»¥3-7å¤©ä¸ºä¸€ä¸ªå‘¨æœŸï¼‰ï¼Œä¸ºåç»­æ¯æ—¥å…·ä½“å®‰æ’æä¾›æ¡†æ¶ã€‚

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{
  "arrangements": [
    {{
      "period": "ç¬¬1-3å¤©",
      "theme": "å®‰æ’ä¸»é¢˜",
      "focus": "é‡ç‚¹å…³æ³¨å†…å®¹",
      "description": "è¿™å‡ å¤©çš„æ•´ä½“å®‰æ’æè¿°"
    }}
  ]
}}

è¦æ±‚ï¼š
1. åˆç†åˆ†é…æ—¶é—´å‘¨æœŸ
2. ç»“åˆå¹´åº¦äº‹ä»¶åˆ¶å®šä¸»é¢˜
3. ä¸ºæ¯æ—¥å…·ä½“å®‰æ’æä¾›æŒ‡å¯¼æ¡†æ¶
4. ä½¿ç”¨ä¸­æ–‡å›å¤"""

            success, content = await self.llm_caller.call_llm(prompt, max_tokens=2000)
            
            if success:
                # è§£æJSON
                arrangements = self._parse_json_content(content)
                if arrangements and "arrangements" in arrangements:
                    schedule_data.medium_arrangements = arrangements["arrangements"]
                    logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(schedule_data.medium_arrangements)} ä¸ªä¸­ç­‰å®‰æ’")
                    return True
                else:
                    logger.error("âŒ ä¸­ç­‰å®‰æ’JSONè§£æå¤±è´¥")
                    return False
            else:
                logger.error(f"âŒ ä¸­ç­‰å®‰æ’LLMç”Ÿæˆå¤±è´¥: {content}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¸­ç­‰å®‰æ’å¼‚å¸¸: {e}")
            return False
    
    async def _generate_daily_arrangements(self, schedule_data: SimpleScheduleData, max_days: int) -> List[Dict[str, Any]]:
        """ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ¯å¤©å…·ä½“çš„5æ—¶é—´æ®µå®‰æ’"""
        daily_results = []
        base_date = datetime(2025, 6, 24)
        
        for day_index in range(max_days):
            current_date = base_date + timedelta(days=day_index)
            weekday = ["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"][current_date.weekday()]
            
            logger.info(f"ğŸ“… ç”Ÿæˆç¬¬{day_index + 1}å¤©: {current_date.strftime('%Y-%m-%d')} {weekday}")
            
            try:
                # è·å–å½“å¤©ç›¸å…³çš„äº‹ä»¶
                day_events = self._get_day_events(day_index, base_date, schedule_data.csv_events)
                
                # è·å–ç›¸å…³çš„ä¸­ç­‰å®‰æ’
                relevant_arrangement = self._get_relevant_arrangement(day_index, schedule_data.medium_arrangements)
                
                # è·å–å‰ä¸€å¤©çš„æ¦‚è¦
                previous_summary = schedule_data.daily_summaries.get(day_index - 1, "è¿™æ˜¯ç¬¬ä¸€å¤©") if day_index > 0 else "è¿™æ˜¯ç¬¬ä¸€å¤©"
                
                # æ„å»ºæ¯æ—¥å®‰æ’ç”Ÿæˆæç¤ºè¯
                prompt = f"""è¯·ä¸ºè§’è‰²åˆ¶å®šä»Šå¤©çš„è¯¦ç»†5æ—¶é—´æ®µæ—¥ç¨‹å®‰æ’ã€‚

ã€è§’è‰²è®¾å®šã€‘
{schedule_data.character_description if schedule_data.character_description else "æ™®é€šä¸Šç­æ—ï¼Œè§„å¾‹ä½œæ¯"}

ã€ä»Šæ—¥åŸºæœ¬ä¿¡æ¯ã€‘
- æ—¥æœŸ: {current_date.strftime('%Y-%m-%d')}
- æ˜ŸæœŸ: {weekday}
- å¤©æ•°: ç¬¬{day_index + 1}å¤©

ã€ä»Šæ—¥é¢„å®šäº‹ä»¶ã€‘
{day_events if day_events else "ä»Šæ—¥æ— ç‰¹æ®Šäº‹ä»¶"}

ã€ä¸­ç­‰å®‰æ’æŒ‡å¯¼ã€‘
{relevant_arrangement if relevant_arrangement else "æŒ‰å¸¸è§„å®‰æ’"}

ã€æ˜¨æ—¥æ¦‚è¦ã€‘
{previous_summary}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼åˆ¶å®šä»Šæ—¥è¯¦ç»†å®‰æ’ï¼š
{{
  "daily_summary": "ä»Šæ—¥ç®€è¦æ¦‚è¿°ï¼ˆä¾›æ˜å¤©å‚è€ƒï¼‰",
  "morning": ["ä¸Šåˆæ´»åŠ¨1", "ä¸Šåˆæ´»åŠ¨2"],
  "noon": ["ä¸­åˆæ´»åŠ¨1", "ä¸­åˆæ´»åŠ¨2"],
  "afternoon": ["ä¸‹åˆæ´»åŠ¨1", "ä¸‹åˆæ´»åŠ¨2"],
  "evening": ["æ™šä¸Šæ´»åŠ¨1", "æ™šä¸Šæ´»åŠ¨2"],
  "night": ["å¤œé—´æ´»åŠ¨1"]
}}

è¦æ±‚ï¼š
1. æ¯ä¸ªæ—¶é—´æ®µå®‰æ’2-3ä¸ªæ´»åŠ¨
2. æ´»åŠ¨è¦å…·ä½“å¯æ‰§è¡Œ
3. ç¬¦åˆè§’è‰²è®¾å®šå’Œä½œæ¯ä¹ æƒ¯
4. daily_summaryè¦ç®€æ´ï¼Œä¸ºæ˜å¤©æä¾›èƒŒæ™¯
5. ä½¿ç”¨ä¸­æ–‡å›å¤"""

                success, content = await self.llm_caller.call_llm(prompt, max_tokens=3000)
                
                if success:
                    daily_data = self._parse_json_content(content)
                    if daily_data and "daily_summary" in daily_data:
                        # ä¿å­˜å½“æ—¥æ¦‚è¦ä¾›ä¸‹ä¸€å¤©ä½¿ç”¨
                        schedule_data.daily_summaries[day_index] = daily_data["daily_summary"]
                        
                        daily_result = {
                            "day": day_index + 1,
                            "date": current_date.strftime('%Y-%m-%d'),
                            "weekday": weekday,
                            "success": True,
                            "daily_summary": daily_data["daily_summary"],
                            "morning": daily_data.get("morning", []),
                            "noon": daily_data.get("noon", []),
                            "afternoon": daily_data.get("afternoon", []),
                            "evening": daily_data.get("evening", []),
                            "night": daily_data.get("night", [])
                        }
                        
                        logger.info(f"âœ… ç¬¬{day_index + 1}å¤©ç”ŸæˆæˆåŠŸ")
                        daily_results.append(daily_result)
                    else:
                        logger.error(f"âŒ ç¬¬{day_index + 1}å¤©JSONè§£æå¤±è´¥")
                        daily_results.append({
                            "day": day_index + 1,
                            "date": current_date.strftime('%Y-%m-%d'),
                            "success": False,
                            "error": "JSONè§£æå¤±è´¥"
                        })
                else:
                    logger.error(f"âŒ ç¬¬{day_index + 1}å¤©LLMç”Ÿæˆå¤±è´¥")
                    daily_results.append({
                        "day": day_index + 1,
                        "date": current_date.strftime('%Y-%m-%d'),
                        "success": False,
                        "error": f"LLMç”Ÿæˆå¤±è´¥: {content}"
                    })
                
                # é˜²æ­¢è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ ç¬¬{day_index + 1}å¤©ç”Ÿæˆå¼‚å¸¸: {e}")
                daily_results.append({
                    "day": day_index + 1,
                    "date": current_date.strftime('%Y-%m-%d'),
                    "success": False,
                    "error": f"ç”Ÿæˆå¼‚å¸¸: {str(e)}"
                })
        
        return daily_results
    
    def _get_day_events(self, day_index: int, base_date: datetime, events: List[Dict[str, Any]]) -> str:
        """è·å–å½“å¤©çš„äº‹ä»¶"""
        current_date = base_date + timedelta(days=day_index)
        day_events = []
        
        for event in events:
            if event['start_date'] <= current_date <= event['end_date']:
                day_events.append(f"- {event['activity_type']}: {event['activity_name']}")
        
        return "\n".join(day_events) if day_events else ""
    
    def _get_relevant_arrangement(self, day_index: int, arrangements: List[Dict[str, Any]]) -> str:
        """è·å–ç›¸å…³çš„ä¸­ç­‰å®‰æ’"""
        if not arrangements:
            return ""
        
        # ç®€å•çš„åŒ¹é…é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä¼˜åŒ–
        for arr in arrangements:
            period = arr.get("period", "")
            if f"ç¬¬{day_index + 1}" in period or f"{day_index + 1}å¤©" in period:
                return f"ä¸»é¢˜: {arr.get('theme', '')}\né‡ç‚¹: {arr.get('focus', '')}\næè¿°: {arr.get('description', '')}"
        
        # å¦‚æœæ²¡æœ‰ç›´æ¥åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªä½œä¸ºå‚è€ƒ
        if arrangements:
            arr = arrangements[0]
            return f"å‚è€ƒä¸»é¢˜: {arr.get('theme', '')}\nå‚è€ƒé‡ç‚¹: {arr.get('focus', '')}"
        
        return ""
    
    def _parse_json_content(self, content: str) -> Optional[Dict[str, Any]]:
        """è§£æJSONå†…å®¹"""
        try:
            json_start = content.find('{')
            json_end = content.rfind('}')
            
            if json_start != -1 and json_end != -1:
                json_str = content[json_start:json_end + 1]
                return json.loads(json_str)
            else:
                logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return None
        except Exception as e:
            logger.error(f"è§£æJSONå¼‚å¸¸: {e}")
            return None
    
    async def _save_to_csv(self, daily_results: List[Dict[str, Any]], max_days: int) -> str:
        """ä¿å­˜ç»“æœä¸ºCSVæ–‡ä»¶"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"schedule_{max_days}days_{timestamp}.csv"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['å¤©æ•°', 'æ—¥æœŸ', 'æ˜ŸæœŸ', 'æ—¶é—´æ®µ', 'æ´»åŠ¨å®‰æ’', 'å½“æ—¥æ¦‚è¦']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in daily_results:
                    if not result.get("success", False):
                        continue
                    
                    day = result["day"]
                    date = result["date"]
                    weekday = result["weekday"]
                    summary = result["daily_summary"]
                    
                    # å†™å…¥5ä¸ªæ—¶é—´æ®µ
                    time_phases = [
                        ("ä¸Šåˆ", result.get("morning", [])),
                        ("ä¸­åˆ", result.get("noon", [])),
                        ("ä¸‹åˆ", result.get("afternoon", [])),
                        ("æ™šä¸Š", result.get("evening", [])),
                        ("å¤œé—´", result.get("night", []))
                    ]
                    
                    for phase_name, activities in time_phases:
                        activity_text = "; ".join(activities) if activities else "æ— å®‰æ’"
                        writer.writerow({
                            'å¤©æ•°': day,
                            'æ—¥æœŸ': date,
                            'æ˜ŸæœŸ': weekday,
                            'æ—¶é—´æ®µ': phase_name,
                            'æ´»åŠ¨å®‰æ’': activity_text,
                            'å½“æ—¥æ¦‚è¦': summary if phase_name == "ä¸Šåˆ" else ""  # åªåœ¨ä¸Šåˆæ˜¾ç¤ºæ¦‚è¦
                        })
            
            logger.info(f"âœ… CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.llm_caller:
            await self.llm_caller.cleanup()


class SimpleRolePlayDataServer(StdioMCPServer):
    """ç®€åŒ–çš„è§’è‰²æ‰®æ¼”æ•°æ®ç”ŸæˆMCPæœåŠ¡å™¨"""
    
    def __init__(self):
        super().__init__("simple-roleplay-data-server")
        self.generator = SimpleScheduleGenerator()
        self._register_tools()
    
    def _register_tools(self):
        """æ³¨å†Œå·¥å…·"""
        
        # ç”Ÿæˆæ—¥ç¨‹å®‰æ’å·¥å…·
        self.register_tool(Tool(
            name="generate_schedule",
            description="ç”Ÿæˆè§’è‰²æ‰®æ¼”æ—¥ç¨‹å®‰æ’ã€‚æ ¹æ®å¹´åº¦è§„åˆ’CSVæ–‡ä»¶ï¼Œä¸ºæ–¹çŸ¥è¡¡ï¼ˆå¤©æ–‡æ•™æˆï¼‰ç”ŸæˆæŒ‡å®šå¤©æ•°çš„è¯¦ç»†æ—¥ç¨‹ï¼ŒåŒ…å«æ¯å¤©5ä¸ªæ—¶é—´æ®µï¼ˆä¸Šåˆ/ä¸­åˆ/ä¸‹åˆ/æ™šä¸Š/å¤œé—´ï¼‰çš„å…·ä½“æ´»åŠ¨å®‰æ’ï¼Œå¹¶è¾“å‡ºCSVæ–‡ä»¶",
            inputSchema=ToolInputSchema(
                type="object",
                properties={
                    "max_days": {
                        "type": "integer",
                        "description": "ç”Ÿæˆçš„å¤©æ•°ï¼Œé»˜è®¤7å¤©",
                        "minimum": 1,
                        "maximum": 557,
                        "default": 7
                    }
                },
                required=["max_days"]
            )
        ))
    
    async def _call_tool(self, name: str, arguments: Dict[str, Any], context) -> Dict[str, Any]:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        try:
            logger.info(f"ç®€åŒ–æ—¥ç¨‹ç”Ÿæˆå·¥å…·è°ƒç”¨: {name}")
            logger.info(f"å‚æ•°: {arguments}")
            
            if name == "generate_schedule":
                # ç¡¬ç¼–ç CSVæ–‡ä»¶è·¯å¾„å’Œè§’è‰²æè¿°
                csv_file_path = "workspace/æ–¹çŸ¥è¡¡å¹´åº¦æ—¥ç¨‹è§„åˆ’.csv"
                character_description = """
                æ–¹çŸ¥è¡¡ï¼Œ28å²ï¼Œå¤©æ–‡ç³»å®¢åº§æ•™æˆ
                æ€§æ ¼æ¸…å†·ä½†è´Ÿè´£ä»»ï¼Œå–œæ¬¢åœ¨å’–å•¡åº—å·¥ä½œ
                ä½œæ¯è§„å¾‹ï¼Œæœ‰æ™¨è·‘ä¹ æƒ¯ï¼Œçƒ­çˆ±é˜…è¯»å’Œç ”ç©¶
                """
                max_days = arguments.get("max_days", 7)
                
                return await self.generator.generate_schedule(
                    csv_file_path, character_description, max_days
                )
            
            else:
                return {"error": f"æœªçŸ¥å·¥å…·: {name}"}
                
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥ {name}: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {
                "error": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                "tool_name": name,
                "arguments": arguments,
                "timestamp": datetime.now().isoformat()
            }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'generator') and self.generator:
            await self.generator.cleanup()


async def test_simple_generation():
    """æµ‹è¯•ç®€åŒ–ç‰ˆç”ŸæˆåŠŸèƒ½"""
    print("ğŸš€ ç®€åŒ–è§’è‰²æ‰®æ¼”æ•°æ®ç”ŸæˆæœåŠ¡ - æœ¬åœ°æµ‹è¯•")
    print("=" * 60)
    
    generator = SimpleScheduleGenerator()
    
    try:
        # æµ‹è¯•å‚æ•°
        csv_file_path = "workspace/æ–¹çŸ¥è¡¡å¹´åº¦æ—¥ç¨‹è§„åˆ’.csv"
        character_description = """
        æ–¹çŸ¥è¡¡ï¼Œ28å²ï¼Œå¤©æ–‡ç³»å®¢åº§æ•™æˆ
        æ€§æ ¼æ¸…å†·ä½†è´Ÿè´£ä»»ï¼Œå–œæ¬¢åœ¨å’–å•¡åº—å·¥ä½œ
        ä½œæ¯è§„å¾‹ï¼Œæœ‰æ™¨è·‘ä¹ æƒ¯ï¼Œçƒ­çˆ±é˜…è¯»å’Œç ”ç©¶
        """
        max_days = 3  # æµ‹è¯•3å¤©
        
        print(f"ğŸ“‚ CSVæ–‡ä»¶: {csv_file_path}")
        print(f"ğŸ‘¤ è§’è‰²: {character_description.strip()}")
        print(f"ğŸ“… ç”Ÿæˆå¤©æ•°: {max_days}")
        print("-" * 60)
        
        # å¼€å§‹ç”Ÿæˆ
        result = await generator.generate_schedule(csv_file_path, character_description, max_days)
        
        if result["success"]:
            print("âœ… ç”ŸæˆæˆåŠŸï¼")
            print(f"ğŸ†” ç”ŸæˆID: {result.get('generation_id', 'N/A')}")
            print(f"ğŸ“Š CSVäº‹ä»¶æ•°: {result.get('csv_events_count', 0)}")
            print(f"ğŸ“Š ä¸­ç­‰å®‰æ’æ•°: {result.get('medium_arrangements_count', 0)}")
            print(f"â±ï¸ æ€»è€—æ—¶: {result.get('generation_time', 0):.2f} ç§’")
            print(f"ğŸ“ è¾“å‡ºCSV: {result.get('output_csv_file', 'N/A')}")
            
            # æ˜¾ç¤ºæ¯æ—¥ç»“æœ
            print("\nğŸ“… æ¯æ—¥ç”Ÿæˆç»“æœ:")
            daily_results = result.get("daily_results", [])
            for daily in daily_results[:3]:  # åªæ˜¾ç¤ºå‰3å¤©
                if daily.get("success"):
                    print(f"\nç¬¬{daily['day']}å¤© ({daily['date']} {daily['weekday']}):")
                    print(f"  ğŸ“ æ¦‚è¦: {daily['daily_summary']}")
                    print(f"  ğŸŒ… ä¸Šåˆ: {', '.join(daily.get('morning', []))}")
                    print(f"  â˜€ï¸ ä¸­åˆ: {', '.join(daily.get('noon', []))}")
                    print(f"  ğŸŒ‡ ä¸‹åˆ: {', '.join(daily.get('afternoon', []))}")
                    print(f"  ğŸŒƒ æ™šä¸Š: {', '.join(daily.get('evening', []))}")
                    print(f"  ğŸŒ™ å¤œé—´: {', '.join(daily.get('night', []))}")
                else:
                    print(f"âŒ ç¬¬{daily['day']}å¤©ç”Ÿæˆå¤±è´¥: {daily.get('error', 'N/A')}")
                    
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result.get('error', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await generator.cleanup()
        print("\nğŸ æµ‹è¯•å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # æ£€æŸ¥å¯åŠ¨æ¨¡å¼
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        # æœ¬åœ°æµ‹è¯•æ¨¡å¼
        await test_simple_generation()
    else:
        # MCPæœåŠ¡å™¨æ¨¡å¼
        server = SimpleRolePlayDataServer()
        logger.info("ğŸš€ å¯åŠ¨ç®€åŒ–è§’è‰²æ‰®æ¼”æ•°æ®ç”ŸæˆMCPæœåŠ¡å™¨...")
        await server.start()


if __name__ == "__main__":
    asyncio.run(main()) 
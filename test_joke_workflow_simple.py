#!/usr/bin/env python3
"""
ç®€åŒ–çš„ç¬‘è¯å·¥ä½œæµæµ‹è¯•è„šæœ¬
ä¸ä¾èµ–æ•°æ®åº“ï¼Œä¸“æ³¨æµ‹è¯•ç¬‘è¯ç”ŸæˆåŠŸèƒ½
"""

import asyncio
import json
from pathlib import Path
from src.workflow.joke_workflow import JokeWorkflow
from src.llm.doubao import DoubaoLLM
from core.types import LLMConfig

async def test_joke_generation():
    """æµ‹è¯•ç¬‘è¯ç”ŸæˆåŠŸèƒ½"""
    print("ğŸ­ å¼€å§‹æµ‹è¯•æ–¹çŸ¥è¡¡ç¬‘è¯ç”Ÿæˆ...")
    
    # é…ç½®LLM
    llm_config = LLMConfig(
        provider="doubao",
        model_name="ep-20241230141654-5tvbr",
        api_key="sk-7a7b5c6d4e8f9a0b1c2d3e4f5g6h7i8j",
        api_base="https://ark.cn-beijing.volces.com/api/v3"
    )
    
    # åˆå§‹åŒ–LLM
    llm = DoubaoLLM(config=llm_config)
    
    # åˆå§‹åŒ–å·¥ä½œæµ
    workflow = JokeWorkflow(llm=llm)
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'total_target': 5,  # åªç”Ÿæˆ5æ¡ç¬‘è¯ç”¨äºæµ‹è¯•
        'batch_size': 5,
        'save_to_database': False,  # ä¸ä¿å­˜åˆ°æ•°æ®åº“
        'quality_threshold': 60,
        'joke_categories': [
            'å­¦æœ¯å¹½é»˜', 'ç”Ÿæ´»æ—¥å¸¸', 'æ¯’å¥¶ä½“è´¨', 'ç½‘ç»œè½ä¼', 
            'å¤æ¿è®¤çœŸ', 'æ¸©å’Œåæ§½', 'ç†æ€§åˆ†æ', 'æ„å¤–åå·®'
        ]
    }
    
    print(f"ğŸ“Š æµ‹è¯•é…ç½®: {test_config}")
    
    # æ‰§è¡Œå·¥ä½œæµ
    try:
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œç¬‘è¯ç”Ÿæˆå·¥ä½œæµ...")
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        graph = await workflow.create_joke_graph()
        
        # ç¼–è¯‘å›¾
        compiled_graph = graph.compile()
        
        # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆä½¿ç”¨å·¥ä½œæµçš„æ ‡å‡†æ ¼å¼ï¼‰
        input_data = {
            'protagonist_data': workflow.protagonist_data,
            'config': test_config,
            'protagonist': test_config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
            'batch_size': test_config.get('batch_size', 5),
            'total_target': test_config.get('total_target', 5),
            'joke_categories': test_config.get('joke_categories', []),
            'difficulty_levels': test_config.get('difficulty_levels', ['ç®€å•', 'ä¸­ç­‰', 'å¤æ‚']),
            'humor_styles': test_config.get('humor_styles', ['å†·å¹½é»˜', 'è‡ªå˜²', 'è§‚å¯Ÿå¼', 'åå·®èŒ']),
            'pg_config': test_config.get('pg_config', {}),
            'workflow_chat': None,  # ç®€åŒ–æµ‹è¯•ä¸ä½¿ç”¨èŠå¤©ç•Œé¢
            'llm': llm
        }
        
        # æ‰§è¡Œå·¥ä½œæµ
        final_result = None
        async for result in compiled_graph.stream(input_data):
            if result:
                final_result = result
                # æ˜¾ç¤ºè¿›åº¦
                node_name = result.get('current_node', 'unknown')
                print(f"ğŸ“ å½“å‰èŠ‚ç‚¹: {node_name}")
        
        # åˆ†æç»“æœ
        if final_result:
            print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ!")
            
            # æ£€æŸ¥ç”Ÿæˆçš„ç¬‘è¯
            generated_jokes = final_result.get('generated_jokes', [])
            print(f"ğŸ“ ç”Ÿæˆç¬‘è¯æ•°é‡: {len(generated_jokes)}")
            
            if generated_jokes:
                print("\nğŸ­ ç”Ÿæˆçš„ç¬‘è¯ç¤ºä¾‹:")
                for i, joke in enumerate(generated_jokes[:3], 1):  # æ˜¾ç¤ºå‰3æ¡
                    print(f"\n--- ç¬‘è¯ {i} ---")
                    print(f"ID: {joke.get('joke_id', 'N/A')}")
                    print(f"ç±»å‹: {joke.get('humor_style', 'N/A')}")
                    print(f"æƒ…å¢ƒ: {joke.get('setup', 'N/A')}")
                    print(f"ç¬‘è¯: {joke.get('punchline', 'N/A')}")
                    print(f"äººè®¾ç‰¹å¾: {joke.get('character_traits', [])}")
                    
                    # éªŒè¯æ˜¯å¦ç¬¦åˆè¦æ±‚
                    punchline = joke.get('punchline', '')
                    if 'æˆ‘' in punchline or 'æˆ‘çš„' in punchline:
                        print("âœ… ç¬¦åˆç¬¬ä¸€äººç§°è§†è§’")
                    else:
                        print("âš ï¸ ç¼ºå°‘ç¬¬ä¸€äººç§°è§†è§’")
            
            # æ£€æŸ¥è´¨é‡åˆ†æ•°
            quality_scores = final_result.get('quality_scores', [])
            if quality_scores:
                avg_score = sum(quality_scores) / len(quality_scores)
                print(f"\nğŸ“Š å¹³å‡è´¨é‡åˆ†æ•°: {avg_score:.1f}")
                print(f"ğŸ“Š è´¨é‡åˆ†æ•°èŒƒå›´: {min(quality_scores):.1f} - {max(quality_scores):.1f}")
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            test_output_file = Path("workspace/test_joke_output.json")
            test_output_file.parent.mkdir(exist_ok=True)
            
            with open(test_output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'config': test_config,
                    'generated_jokes': generated_jokes,
                    'quality_scores': quality_scores,
                    'total_jokes': len(generated_jokes)
                }, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_output_file}")
            
        else:
            print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œæ²¡æœ‰è¿”å›ç»“æœ")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def analyze_joke_style():
    """åˆ†æç”Ÿæˆçš„ç¬‘è¯é£æ ¼æ˜¯å¦ç¬¦åˆè¦æ±‚"""
    print("\nğŸ” åˆ†æç¬‘è¯é£æ ¼...")
    
    test_output_file = Path("workspace/test_joke_output.json")
    if not test_output_file.exists():
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ç»“æœæ–‡ä»¶")
        return
    
    with open(test_output_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    jokes = data.get('generated_jokes', [])
    if not jokes:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç”Ÿæˆçš„ç¬‘è¯")
        return
    
    print(f"ğŸ“Š åˆ†æ {len(jokes)} æ¡ç¬‘è¯...")
    
    # åˆ†ææŒ‡æ ‡
    first_person_count = 0
    academic_style_count = 0
    self_deprecating_count = 0
    mild_humor_count = 0
    
    for joke in jokes:
        punchline = joke.get('punchline', '')
        setup = joke.get('setup', '')
        
        # æ£€æŸ¥ç¬¬ä¸€äººç§°
        if 'æˆ‘' in punchline or 'æˆ‘çš„' in punchline:
            first_person_count += 1
        
        # æ£€æŸ¥å­¦æœ¯é£æ ¼
        academic_keywords = ['æ ¹æ®', 'å®šå¾‹', 'ç†è®º', 'åˆ†æ', 'ç ”ç©¶', 'å‘ç°', 'å®éªŒ']
        if any(keyword in punchline for keyword in academic_keywords):
            academic_style_count += 1
        
        # æ£€æŸ¥è‡ªå˜²é£æ ¼
        self_keywords = ['æˆ‘çš„', 'æˆ‘åˆ', 'æˆ‘éƒ½', 'æˆ‘æ€»æ˜¯', 'æˆ‘å‘ç°æˆ‘']
        if any(keyword in punchline for keyword in self_keywords):
            self_deprecating_count += 1
        
        # æ£€æŸ¥æ¸©å’Œå¹½é»˜
        mild_keywords = ['çœ‹æ¥', 'ä¼¼ä¹', 'å¯èƒ½', 'åº”è¯¥', 'å¤§æ¦‚', 'æˆ–è®¸']
        if any(keyword in punchline for keyword in mild_keywords):
            mild_humor_count += 1
    
    # è¾“å‡ºåˆ†æç»“æœ
    print(f"\nğŸ“ˆ é£æ ¼åˆ†æç»“æœ:")
    print(f"âœ… ç¬¬ä¸€äººç§°è§†è§’: {first_person_count}/{len(jokes)} ({first_person_count/len(jokes)*100:.1f}%)")
    print(f"ğŸ“ å­¦æœ¯é£æ ¼: {academic_style_count}/{len(jokes)} ({academic_style_count/len(jokes)*100:.1f}%)")
    print(f"ğŸ˜… è‡ªå˜²é£æ ¼: {self_deprecating_count}/{len(jokes)} ({self_deprecating_count/len(jokes)*100:.1f}%)")
    print(f"ğŸ˜Š æ¸©å’Œå¹½é»˜: {mild_humor_count}/{len(jokes)} ({mild_humor_count/len(jokes)*100:.1f}%)")
    
    # åˆ¤æ–­æ˜¯å¦ç¬¦åˆè¦æ±‚
    if first_person_count >= len(jokes) * 0.8:
        print("âœ… ç¬¬ä¸€äººç§°è§†è§’ç¬¦åˆè¦æ±‚")
    else:
        print("âš ï¸ ç¬¬ä¸€äººç§°è§†è§’éœ€è¦æ”¹è¿›")

if __name__ == "__main__":
    print("ğŸ­ æ–¹çŸ¥è¡¡ç¬‘è¯ç”Ÿæˆæµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_joke_generation())
    
    # åˆ†æç»“æœ
    asyncio.run(analyze_joke_style())
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!") 
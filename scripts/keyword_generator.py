# -*- coding: utf-8 -*-
"""
å…³é”®è¯ç”Ÿæˆå™¨ - è¯»å–CSVæ–‡ä»¶æŒ‡å®šå­—æ®µï¼Œä½¿ç”¨LLMæå–åè¯å®ä½“ä½œä¸ºå…³é”®è¯

åŠŸèƒ½ï¼š
- è¯»å–CSVæ–‡ä»¶çš„æŒ‡å®šå­—æ®µ
- ä½¿ç”¨LLMæå–åè¯å®ä½“ä½œä¸ºå…³é”®è¯
- ä¿å­˜åŸå§‹å†…å®¹+ç”Ÿæˆçš„å…³é”®è¯åˆ°æ–°æ–‡ä»¶
"""

import csv
import json
import os
import sys
import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.llm.doubao import DoubaoLLM
from src.core.types import LLMConfig, Message, MessageRole

logger = logging.getLogger(__name__)

class KeywordGenerator:
    """å…³é”®è¯ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.llm = None
        self._init_llm()
    
    def _init_llm(self):
        """åˆå§‹åŒ–LLM"""
        try:
            # ä½¿ç”¨ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°å’ŒAPIå¯†é’¥
            text_model = os.getenv('DOUBAO_MODEL_DEEPSEEKV3', 'ep-20250221154410-vh78x')
            api_key = os.getenv('ARK_API_KEY', "b633a622-b5d0-4f16-a8a9-616239cf15d1")
            
            # åˆ›å»ºLLMé…ç½®
            llm_config = LLMConfig(
                provider="doubao",
                model_name=text_model,
                api_key=api_key.strip(),
                api_base="https://ark.cn-beijing.volces.com/api/v3"
            )
            self.llm = DoubaoLLM(config=llm_config)
            print(f"âœ… LLMé…ç½®æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {text_model}")
        except Exception as e:
            print(f"âš ï¸ LLMé…ç½®å¤±è´¥: {e}")
            self.llm = None
    
    async def extract_keywords(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆåè¯å®ä½“ï¼‰"""
        if not self.llm or not text.strip():
            return []
        
        try:
            # æ„å»ºæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»æ–‡æœ¬ä¸­æå–åè¯å®ä½“ä½œä¸ºå…³é”®è¯ã€‚

è¯·ä»æä¾›çš„æ–‡æœ¬ä¸­æå–å…·ä½“çš„åè¯å®ä½“ï¼Œä½œä¸ºå…³é”®è¯ã€‚è¦æ±‚ï¼š
1. åªæå–å…·ä½“çš„åè¯å®ä½“ï¼ˆå¦‚ï¼šäººç‰©ã€ç‰©å“ã€åŠ¨ç‰©ã€æ¤ç‰©ã€å»ºç­‘ã€åœ°ç‚¹ç­‰ï¼‰
2. ä¸è¦æŠ½è±¡æ¦‚å¿µã€å½¢å®¹è¯ã€åŠ¨è¯ã€é¢œè‰²ã€æƒ…æ„Ÿè¯æ±‡
3. ä¸è¦é‡å¤çš„è¯æ±‡ï¼Œä¸è¦è¯ç»„ä¾‹å¦‚ï¼šåŸå¸‚è¡—é“ï¼Œä¼šæ‹†åˆ†ä¸ºåŸå¸‚ã€è¡—é“
4. æŒ‰é‡è¦æ€§æ’åºï¼Œæœ€å¤š20ä¸ªå…³é”®è¯
5. ç‰©å“ç¦æ­¢åŒ…å«é¢œè‰²æè¿°

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šJSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- keywords: å…³é”®è¯æ•°ç»„

è¯·ç¡®ä¿è¾“å‡ºä¸ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚
ç¤ºä¾‹ï¼š
{
  "keywords": ["é£è½¦", "æ²¹èœèŠ±", "è“å¤©", "å°çŒ«", "æ ‘æ"]
}"""
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_message = Message(
                role=MessageRole.USER,
                content=f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–åè¯å®ä½“ä½œä¸ºå…³é”®è¯ï¼š\n\n{text}"
            )
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                Message(role=MessageRole.SYSTEM, content=system_prompt),
                user_message
            ]
            
            # è°ƒç”¨LLM
            response = await self.llm.generate(
                messages,
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œç¡®ä¿ä¸€è‡´æ€§
                max_tokens=1024,
                mode="normal"
            )
            
            content = response.content
            
            # ä»å›å¤ä¸­æå–JSON
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•æ‰¾åˆ°å¤§æ‹¬å·åŒ…å›´çš„JSON
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = content
            
            # è§£æJSON
            try:
                result_data = json.loads(json_str.strip())
                keywords = result_data.get('keywords', [])
                if isinstance(keywords, list):
                    return keywords
                else:
                    return []
            except json.JSONDecodeError:
                logger.warning(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å›å¤")
                return []
                
        except Exception as e:
            logger.error(f"å…³é”®è¯æå–å¤±è´¥: {e}")
            return []
    
    async def process_csv_file(self, input_file: str, output_file: str = None, 
                             source_field: str = "æ•…äº‹å†…å®¹", 
                             target_field: str = "LLMå…³é”®è¯",
                             batch_size: int = 5) -> bool:
        """
        å¤„ç†CSVæ–‡ä»¶ï¼Œæå–å…³é”®è¯
        
        Args:
            input_file: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            source_field: æºå­—æ®µåï¼ˆä»å“ªä¸ªå­—æ®µæå–å…³é”®è¯ï¼‰
            target_field: ç›®æ ‡å­—æ®µåï¼ˆæ–°å¢çš„å…³é”®è¯å­—æ®µåï¼‰
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return False
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if output_file is None:
            base_name, ext = os.path.splitext(input_file)
            output_file = f"{base_name}_with_keywords{ext}"
        
        print(f"ğŸ“– è¯»å–æ–‡ä»¶: {input_file}")
        print(f"ğŸ¯ æºå­—æ®µ: {source_field}")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ”¤ ç›®æ ‡å­—æ®µ: {target_field}")
        
        # å°è¯•ä¸åŒç¼–ç è¯»å–æ–‡ä»¶
        encodings = ['utf-8-sig', 'utf-8', 'gbk']
        rows = []
        headers = []
        
        for encoding in encodings:
            try:
                with open(input_file, 'r', encoding=encoding, newline='') as f:
                    reader = csv.DictReader(f)
                    headers = reader.fieldnames
                    rows = list(reader)
                print(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼ˆç¼–ç : {encoding}ï¼‰")
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶å¤±è´¥ ({encoding}): {e}")
                continue
        
        if not rows:
            print("âŒ æ— æ³•è¯»å–æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œç¼–ç ")
            return False
        
        # æ£€æŸ¥æºå­—æ®µæ˜¯å¦å­˜åœ¨
        if source_field not in headers:
            print(f"âŒ æºå­—æ®µ '{source_field}' ä¸å­˜åœ¨")
            print(f"å¯ç”¨å­—æ®µ: {', '.join(headers)}")
            return False
        
        # å‡†å¤‡æ–°çš„å­—æ®µååˆ—è¡¨
        new_headers = list(headers)
        if target_field not in new_headers:
            new_headers.append(target_field)
        
        print(f"ğŸ“Š å¼€å§‹å¤„ç† {len(rows)} æ¡è®°å½•...")
        
        # åˆ†æ‰¹å¤„ç†
        total_batches = (len(rows) + batch_size - 1) // batch_size
        processed_count = 0
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(rows))
            batch_rows = rows[start_idx:end_idx]
            
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {batch_idx + 1}/{total_batches} æ‰¹ ({len(batch_rows)} æ¡è®°å½•)")
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            for i, row in enumerate(batch_rows):
                source_text = row.get(source_field, "")
                if source_text.strip():
                    print(f"  ğŸ“ å¤„ç†ç¬¬ {start_idx + i + 1} æ¡è®°å½•...")
                    keywords = await self.extract_keywords(source_text)
                    row[target_field] = " ".join(keywords) if keywords else ""
                    if keywords:
                        print(f"    âœ… æå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {', '.join(keywords[:15])}{'...' if len(keywords) > 5 else ''}")
                    else:
                        print(f"    âš ï¸ æœªæå–åˆ°å…³é”®è¯")
                else:
                    row[target_field] = ""
                    print(f"    âš ï¸ ç¬¬ {start_idx + i + 1} æ¡è®°å½•çš„æºå­—æ®µä¸ºç©º")
                
                processed_count += 1
            
            print(f"  âœ… ç¬¬ {batch_idx + 1} æ‰¹å¤„ç†å®Œæˆ")
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        try:
            with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=new_headers)
                writer.writeheader()
                writer.writerows(rows)
            
            print(f"\nâœ… å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {processed_count}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å†™å…¥è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            return False

def show_field_menu(headers: List[str]) -> str:
    """æ˜¾ç¤ºå­—æ®µé€‰æ‹©èœå•"""
    print("\n" + "="*60)
    print("ğŸ“‹ å¯ç”¨å­—æ®µåˆ—è¡¨:")
    print("-"*60)
    
    for i, field in enumerate(headers, 1):
        print(f"  {i}. {field}")
    
    print("\nğŸ’¡ è¯·è¾“å…¥æ•°å­—ç¼–å·é€‰æ‹©æºå­—æ®µ (é»˜è®¤é€‰æ‹©åŒ…å«'æ•…äº‹'æˆ–'å†…å®¹'çš„å­—æ®µ)")
    print("-"*60)
    
    # è‡ªåŠ¨æ£€æµ‹åŒ…å«'æ•…äº‹'æˆ–'å†…å®¹'çš„å­—æ®µ
    auto_field = None
    for field in headers:
        if 'æ•…äº‹' in field or 'å†…å®¹' in field:
            auto_field = field
            break
    
    if auto_field:
        print(f"ğŸ¯ è‡ªåŠ¨æ£€æµ‹åˆ°æ¨èå­—æ®µ: {auto_field}")
        choice = input("ğŸ‘‰ è¯·é€‰æ‹© (ç›´æ¥å›è½¦ä½¿ç”¨æ¨èå­—æ®µ): ").strip()
        
        if choice == "":
            return auto_field
    else:
        choice = input("ğŸ‘‰ è¯·é€‰æ‹©: ").strip()
    
    try:
        choice_num = int(choice)
        if 1 <= choice_num <= len(headers):
            return headers[choice_num - 1]
        else:
            print(f"âŒ è¯·è¾“å…¥1-{len(headers)}ä¹‹é—´çš„æ•°å­—")
            return show_field_menu(headers)
    except ValueError:
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
        return show_field_menu(headers)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¤ å…³é”®è¯ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        # é»˜è®¤æ–‡ä»¶
        input_file = "workspace/input/image_recognition_20250704_112047_with_story_with_unique_id.csv"
    
    if not os.path.exists(input_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # å…ˆè¯»å–æ–‡ä»¶å¤´ï¼Œæ˜¾ç¤ºå­—æ®µé€‰æ‹©
    try:
        with open(input_file, 'r', encoding='utf-8-sig', newline='') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤´å¤±è´¥: {e}")
        return
    
    print(f"ğŸ“– è¾“å…¥æ–‡ä»¶: {input_file}")
    
    # é€‰æ‹©æºå­—æ®µ
    source_field = show_field_menu(headers)
    print(f"\nâœ… å·²é€‰æ‹©æºå­—æ®µ: {source_field}")
    
    # è¾“å…¥ç›®æ ‡å­—æ®µå
    target_field = input("\nğŸ”¤ è¯·è¾“å…¥æ–°å…³é”®è¯å­—æ®µå (é»˜è®¤: LLMå…³é”®è¯): ").strip()
    if not target_field:
        target_field = "LLMå…³é”®è¯"
    
    # æ‰¹å¤„ç†å¤§å°
    batch_size_input = input("\nğŸ“¦ è¯·è¾“å…¥æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 3): ").strip()
    try:
        batch_size = int(batch_size_input) if batch_size_input else 3
    except ValueError:
        batch_size = 3
    
    print(f"\nğŸ¯ é…ç½®ç¡®è®¤:")
    print(f"  ğŸ“– è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"  ğŸ“ æºå­—æ®µ: {source_field}")
    print(f"  ğŸ”¤ ç›®æ ‡å­—æ®µ: {target_field}")
    print(f"  ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {batch_size}")
    
    confirm = input("\nâ“ ç¡®è®¤å¼€å§‹å¤„ç†ï¼Ÿ(y/n): ").lower().strip()
    if confirm not in ['y', 'yes', 'æ˜¯']:
        print("ğŸ‘‹ å–æ¶ˆå¤„ç†")
        return
    
    # åˆ›å»ºå…³é”®è¯ç”Ÿæˆå™¨
    generator = KeywordGenerator()
    
    if not generator.llm:
        print("âŒ LLMæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # å¼€å§‹å¤„ç†
    print(f"\nğŸš€ å¼€å§‹å¤„ç†...")
    success = await generator.process_csv_file(
        input_file=input_file,
        source_field=source_field,
        target_field=target_field,
        batch_size=batch_size
    )
    
    if success:
        print("\nğŸ‰ å…³é”®è¯ç”Ÿæˆå®Œæˆï¼")
    else:
        print("\nâŒ å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main())
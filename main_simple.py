# -*- coding: utf-8 -*-
"""
ZZZero AI Agent Framework ç®€åŒ–ç‰ˆä¸»å…¥å£
ç”¨äºæµ‹è¯•æ ¸å¿ƒåŠŸèƒ½ï¼Œè·³è¿‡å¤æ‚çš„ä¾èµ–
"""
import asyncio
import os
import sys
import logging
from pathlib import Path
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æ·»åŠ srcè·¯å¾„
current_dir = Path(__file__).parent
src_path = current_dir / "src"
sys.path.insert(0, str(src_path))

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    # åŠ è½½.envæ–‡ä»¶
    env_file = Path(".env")
    if env_file.exists():
        load_dotenv(env_file)
        print("[æˆåŠŸ] ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ")
    else:
        print("[è­¦å‘Š] .envæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

async def test_core_components():
    """æµ‹è¯•æ ¸å¿ƒç»„ä»¶"""
    try:
        print("=== æµ‹è¯•æ ¸å¿ƒç»„ä»¶ ===")
        
        # æµ‹è¯•åŸºç¡€ç±»å‹
        from core.types import Message, MessageRole, LLMConfig
        print("[æˆåŠŸ] æ ¸å¿ƒç±»å‹æ¨¡å—åŠ è½½å®Œæˆ")
        
        # æµ‹è¯•åŸºç¡€èŠ‚ç‚¹
        from core.base import BaseNode, NodeType
        print("[æˆåŠŸ] åŸºç¡€èŠ‚ç‚¹æ¨¡å—åŠ è½½å®Œæˆ")
        
        # æµ‹è¯•å›¾ç»“æ„
        from core.graph import StateGraph, GraphBuilder
        print("[æˆåŠŸ] å›¾ç»“æ„æ¨¡å—åŠ è½½å®Œæˆ")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾
        class TestNode(BaseNode):
            def __init__(self, name: str):
                super().__init__(name, NodeType.CUSTOM, "æµ‹è¯•èŠ‚ç‚¹")
            
            async def execute(self, state):
                print(f"[æ‰§è¡Œ] æµ‹è¯•èŠ‚ç‚¹ {self.name} æ­£åœ¨è¿è¡Œï¼Œæ¥æ”¶çŠ¶æ€: {state}")
                # è¿”å›çŠ¶æ€æ›´æ–°
                result = {"test_result": f"èŠ‚ç‚¹ {self.name} æ‰§è¡Œå®Œæˆ", "processed_by": self.name}
                print(f"[è¿”å›] èŠ‚ç‚¹ {self.name} è¿”å›ç»“æœ: {result}")
                return result
        
        # æ„å»ºæµ‹è¯•å›¾
        builder = GraphBuilder("test_graph")
        node1 = TestNode("test_node_1")
        node2 = TestNode("test_node_2")
        
        graph = (builder
                .add_node(node1)
                .add_node(node2)
                .connect("test_node_1", "test_node_2")
                .entry("test_node_1")
                .build())
        
        print("[æˆåŠŸ] æµ‹è¯•å›¾æ„å»ºå®Œæˆ")
        print(f"[ä¿¡æ¯] å›¾åŒ…å«èŠ‚ç‚¹: {list(graph.nodes.keys())}")
        
        # ç¼–è¯‘å¹¶æ‰§è¡Œå›¾
        compiled_graph = graph.compile()
        initial_state = {"input": "æµ‹è¯•è¾“å…¥"}
        result = await compiled_graph.invoke(initial_state)
        
        print("[æˆåŠŸ] å›¾æ‰§è¡Œå®Œæˆ")
        print(f"[ç»“æœ] æœ€ç»ˆçŠ¶æ€: {result}")
        
        return True
        
    except Exception as e:
        print(f"[é”™è¯¯] æ ¸å¿ƒç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_llm_modules():
    """æµ‹è¯•LLMæ¨¡å—"""
    try:
        print("\n=== æµ‹è¯•LLMæ¨¡å— ===")
        
        # æµ‹è¯•LLMåŸºç±»
        from llm.base import BaseLLMProvider, LLMFactory
        print("[æˆåŠŸ] LLMåŸºç±»æ¨¡å—åŠ è½½å®Œæˆ")
        
        # æµ‹è¯•å…·ä½“LLMå®ç°
        try:
            from llm.openai import OpenAILLM
            print("[æˆåŠŸ] OpenAIæ¨¡å—åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"[è­¦å‘Š] OpenAIæ¨¡å—åŠ è½½å¤±è´¥: {e}")
        
        try:
            from llm.doubao import DoubaoLLM
            print("[æˆåŠŸ] è±†åŒ…æ¨¡å—åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"[è­¦å‘Š] è±†åŒ…æ¨¡å—åŠ è½½å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"[é”™è¯¯] LLMæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_mcp_modules():
    """æµ‹è¯•MCPæ¨¡å—"""
    try:
        print("\n=== æµ‹è¯•MCPæ¨¡å— ===")
        
        # æµ‹è¯•MCPåŸºç¡€ç±»å‹
        from mcp.types import MCPMethods
        print("[æˆåŠŸ] MCPç±»å‹æ¨¡å—åŠ è½½å®Œæˆ")
        
        # æµ‹è¯•MCPå®¢æˆ·ç«¯
        from mcp.client.base import BaseClient
        print("[æˆåŠŸ] MCPå®¢æˆ·ç«¯åŸºç±»åŠ è½½å®Œæˆ")
        
        # æµ‹è¯•MCPæœåŠ¡å™¨
        from mcp.server.base import BaseServer
        print("[æˆåŠŸ] MCPæœåŠ¡å™¨åŸºç±»åŠ è½½å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"[é”™è¯¯] MCPæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»å‡½æ•°"""
    try:
        print("=== ZZZero AI Agent ç®€åŒ–ç‰ˆæµ‹è¯• ===")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        setup_environment()
        
        # æµ‹è¯•æ ¸å¿ƒç»„ä»¶
        core_success = await test_core_components()
        
        # æµ‹è¯•LLMæ¨¡å—
        llm_success = await test_llm_modules()
        
        # æµ‹è¯•MCPæ¨¡å—
        mcp_success = await test_mcp_modules()
        
        # æ±‡æ€»ç»“æœ
        print("\n=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
        print(f"[ç»“æœ] æ ¸å¿ƒç»„ä»¶: {'âœ“ é€šè¿‡' if core_success else 'âœ— å¤±è´¥'}")
        print(f"[ç»“æœ] LLMæ¨¡å—: {'âœ“ é€šè¿‡' if llm_success else 'âœ— å¤±è´¥'}")
        print(f"[ç»“æœ] MCPæ¨¡å—: {'âœ“ é€šè¿‡' if mcp_success else 'âœ— å¤±è´¥'}")
        
        if all([core_success, llm_success, mcp_success]):
            print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒç»„ä»¶æµ‹è¯•é€šè¿‡ï¼æ¡†æ¶åŸºç¡€åŠŸèƒ½æ­£å¸¸ã€‚")
            print("ğŸ’¡ æç¤º: å¯ä»¥å°è¯•å®‰è£…å®Œæ•´ä¾èµ–åå¯åŠ¨å®Œæ•´ç‰ˆWebç•Œé¢ã€‚")
        else:
            print("\nâš ï¸  éƒ¨åˆ†ç»„ä»¶æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…ã€‚")
        
    except KeyboardInterrupt:
        print("\nğŸ”„ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n[é”™è¯¯] æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("[é€€å‡º] ç®€åŒ–ç‰ˆæµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    # è®¾ç½®Windowså¼‚æ­¥äº‹ä»¶å¾ªç¯ç­–ç•¥
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(main())
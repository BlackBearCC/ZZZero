#!/usr/bin/env python3
"""
æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨ - æœ¬åœ°mainå¯åŠ¨è„šæœ¬
æ”¯æŒæŒ‰æ‰¹æ¬¡ç”Ÿæˆæ—¥ç¨‹ï¼Œæ¯æ‰¹æ¬¡éšæœºé…ç½®ï¼Œä¿å­˜ä¸ºCSVæ ¼å¼
"""

import asyncio
import random
import json
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging



# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
src_path = current_dir / "src"
sys.path.insert(0, str(src_path))

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„ä»¥æ”¯æŒç»å¯¹å¯¼å…¥
sys.path.insert(0, str(current_dir))

from src.workflow.schedule_workflow import ScheduleWorkflow
from src.llm.base import LLMFactory
from src.core.types import LLMConfig
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_schedule_generator.log', encoding='utf-8'),  # æ˜ç¡®æŒ‡å®šUTF-8ç¼–ç 
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class BatchScheduleGenerator:
    """æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨"""
    
    def __init__(self, start_date: str = "2025-07-18", batch_count: int = 100):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            batch_count: æ‰¹æ¬¡æ•°é‡
        """
        self.start_date = datetime.strptime(start_date, '%Y-%m-%d')
        self.batch_count = batch_count
        self.current_date = self.start_date
        self.workflow = None
        self.llm = None
        self.batch_history = []  # å­˜å‚¨æ¯æ‰¹æ¬¡çš„æ€»ç»“ï¼Œç”¨äºè¿ç»­æ€§
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path("workspace/batch_schedule_output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–LLMå’Œå·¥ä½œæµ
        self._init_workflow()
        
        logger.info(f"æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"å¼€å§‹æ—¥æœŸ: {start_date}")
        logger.info(f"æ‰¹æ¬¡æ•°é‡: {batch_count}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def _init_workflow(self):
        """åˆå§‹åŒ–å·¥ä½œæµå’ŒLLM"""
        try:
            # åˆ›å»ºLLMå®ä¾‹
            llm_config = LLMConfig(
                provider="doubao",
                api_key=os.getenv('DOUBAO_API_KEY', 'b633a622-b5d0-4f16-a8a9-616239cf15d1'),
                model_name=os.getenv('DOUBAO_MODEL_DEEPSEEKR1', 'ep-20250221154107-c4qc7'),
                temperature=0.7,
                max_tokens=16384
            )
            
            llm_factory = LLMFactory()
            self.llm = llm_factory.create(llm_config)
            
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            self.workflow = ScheduleWorkflow(llm=self.llm)
            
            logger.info("LLMå’Œå·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"LLMå’Œå·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _get_random_config(self, batch_num: int) -> Dict[str, Any]:
        """ç”Ÿæˆéšæœºé…ç½®"""
        # éšæœºå¤©æ•° (7-14å¤©)
        total_days = random.randint(5, 14)
        end_date = self.current_date + timedelta(days=total_days - 1)
        
        # è·å–å¯ç”¨è§’è‰²åˆ—è¡¨ï¼ˆæ’é™¤ä¸»è§’æ–¹çŸ¥è¡¡ï¼‰
        available_characters = list(self.workflow.characters_data.get("è§’è‰²åˆ—è¡¨", {}).keys())
        if 'æ–¹çŸ¥è¡¡' in available_characters:
            available_characters.remove('æ–¹çŸ¥è¡¡')
        
        # éšæœºé€‰æ‹©è§’è‰² (2-6)
        char_count = min(random.randint(2, 6), len(available_characters))
        selected_characters = random.sample(available_characters, char_count)
        
        # è·å–å¯ç”¨åœ°ç‚¹åˆ—è¡¨
        available_locations = []
        for district_name, district_info in self.workflow.locations_data.get("districts", {}).items():
            for loc_name, loc_info in district_info.get("locations", {}).items():
                available_locations.append(loc_info.get('name', loc_name))
        
        # éšæœºé€‰æ‹©åœ°ç‚¹ (3-9ä¸ª)
        loc_count = min(random.randint(2, 6), len(available_locations))
        selected_locations = random.sample(available_locations, loc_count)
        
        # ç”Ÿæˆé…ç½®
        config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',
            'schedule_type': 'weekly',
            'start_date': self.current_date.strftime('%Y-%m-%d'),
            'end_date': end_date.strftime('%Y-%m-%d'),
            'total_days': total_days,
            'selected_characters': selected_characters,
            'selected_locations': selected_locations,
            'selected_stories': [],  # æš‚æ—¶ä¸ä½¿ç”¨å‰§æƒ…
            'time_slots_config': {
                'å¤œé—´': {'start': '23:00', 'end': '06:00'},
                'ä¸Šåˆ': {'start': '06:00', 'end': '11:00'},
                'ä¸­åˆ': {'start': '11:00', 'end': '14:00'},
                'ä¸‹åˆ': {'start': '14:00', 'end': '18:00'},
                'æ™šä¸Š': {'start': '18:00', 'end': '23:00'}
            },
            'character_distribution': 'balanced',
            'story_integration': 'moderate',
            'include_holidays': True,
            'include_lunar': True,
            'mood_variety': True,
            'location_variety': True,
            # æ·»åŠ ä¸Šä¸€æ‰¹æ¬¡æ€»ç»“ä¿¡æ¯ç”¨äºè¿ç»­æ€§
            'previous_batch_summary': self._get_previous_summary() if batch_num > 1 else ""
        }
        
        return config
    
    def _get_previous_summary(self) -> str:
        """è·å–ä¸Šä¸€æ‰¹æ¬¡çš„æ€»ç»“ä¿¡æ¯ï¼Œç”¨äºä¿æŒè¿ç»­æ€§"""
        if not self.batch_history:
            return ""
        
        last_batch = self.batch_history[-1]
        summary = f"""
## ä¸Šä¸€æ‰¹æ¬¡æ€»ç»“ï¼ˆ{last_batch['start_date']} - {last_batch['end_date']}ï¼‰

**æ—¶é—´èŒƒå›´**: {last_batch['start_date']} è‡³ {last_batch['end_date']}ï¼ˆ{last_batch['total_days']}å¤©ï¼‰
**ä¸»è¦è§’è‰²**: {', '.join(last_batch['characters'])}
**ä¸»è¦åœ°ç‚¹**: {', '.join(last_batch['locations'])}
**é‡è¦äº‹ä»¶**: {last_batch.get('key_events', 'å·¥ä½œã€ç ”ç©¶ã€ç¤¾äº¤ç­‰æ—¥å¸¸æ´»åŠ¨')}
**æƒ…æ„Ÿå‘å±•**: {last_batch.get('emotional_progress', 'ä¸å„è§’è‰²ä¿æŒè‰¯å¥½å…³ç³»')}
**é—ç•™é—®é¢˜**: {last_batch.get('pending_issues', 'æ— ç‰¹åˆ«é—ç•™é—®é¢˜')}

è¯·ç¡®ä¿æ–°çš„æ—¥ç¨‹ä¸ä¸Šè¿°æƒ…å†µè‡ªç„¶è¡”æ¥ï¼Œé¿å…çªå…€çš„å˜åŒ–ã€‚
"""
        return summary
    
    async def _generate_single_batch(self, batch_num: int) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆå•ä¸ªæ‰¹æ¬¡çš„æ—¥ç¨‹"""
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆç¬¬ {batch_num} æ‰¹æ¬¡æ—¥ç¨‹...")
            
            # ç”Ÿæˆéšæœºé…ç½®
            config = self._get_random_config(batch_num)
            
            logger.info(f"æ‰¹æ¬¡ {batch_num} é…ç½®:")
            logger.info(f"  æ—¥æœŸèŒƒå›´: {config['start_date']} - {config['end_date']} ({config['total_days']}å¤©)")
            logger.info(f"  è§’è‰²æ•°é‡: {len(config['selected_characters'])}")
            logger.info(f"  åœ°ç‚¹æ•°é‡: {len(config['selected_locations'])}")
            logger.info(f"  é€‰æ‹©è§’è‰²: {', '.join(config['selected_characters'])}")
            logger.info(f"  é€‰æ‹©åœ°ç‚¹: {', '.join(config['selected_locations'])}")
            
            # åˆ›å»ºç®€åŒ–çš„å·¥ä½œæµèŠå¤©æ¥å£ï¼ˆä¸éœ€è¦UIï¼‰ï¼Œé¿å…ä½¿ç”¨emojiç¬¦å·
            class SimpleWorkflowChat:
                def __init__(self):
                    self.current_node = ""
                
                async def add_node_message(self, node_name: str, message: str, status: str):
                    # ç§»é™¤emojiç¬¦å·ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
                    clean_message = message.replace('âœ…', '[æˆåŠŸ]').replace('âŒ', '[å¤±è´¥]').replace('ğŸ“…', '[æ—¥ç¨‹]').replace('ğŸ’¾', '[ä¿å­˜]')
                    logger.info(f"[{node_name}] {clean_message}")
                
                def _create_workflow_progress(self):
                    return ""
            
            workflow_chat = SimpleWorkflowChat()
            
            # æ‰§è¡Œå·¥ä½œæµ - ä¿®å¤ç»“æœæ”¶é›†é€»è¾‘
            logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
            
            final_state = None
            final_output = None
            progress_count = 0
            
            async for stream_event in self.workflow.execute_workflow_stream(config, workflow_chat):
                progress_count += 1
                logger.info(f"æ”¶åˆ°å·¥ä½œæµäº‹ä»¶ {progress_count}: {type(stream_event)}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆè¾“å‡ºäº‹ä»¶
                if isinstance(stream_event, tuple) and len(stream_event) >= 4:
                    # å…ƒç»„æ ¼å¼: (html, content, message, is_complete)
                    html, content, message, is_complete = stream_event
                    logger.info(f"æ”¶åˆ°UIäº‹ä»¶: message='{message}', is_complete={is_complete}")
                    
                    # å¦‚æœåŒ…å«æˆåŠŸå®Œæˆçš„ä¿¡æ¯ï¼Œè¯´æ˜æœ‰å®é™…çš„æ‰§è¡Œç»“æœ
                    if "æ‰§è¡Œå®Œæˆ" in message or "ç”Ÿæˆå®Œæˆ" in message:
                        logger.info("æ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆä¿¡å·")
                
            logger.info(f"å·¥ä½œæµUIæµæ‰§è¡Œå®Œæˆï¼Œå…±æ”¶åˆ° {progress_count} æ¬¡äº‹ä»¶")
            
            # ä½¿ç”¨æµå¼è·å–æœ€ç»ˆçŠ¶æ€æ•°æ®
            logger.info("é€šè¿‡æµå¼è°ƒç”¨è·å–æœ€ç»ˆæ•°æ®...")
            
            try:
                # å‡†å¤‡ç›¸åŒçš„è¾“å…¥æ•°æ®
                initial_input = {
                    'characters_data': self.workflow.characters_data,
                    'locations_data': self.workflow.locations_data,
                    'stories_data': self.workflow.stories_data,
                    'protagonist_data': self.workflow.protagonist_data,
                    'holidays_data': self.workflow.holidays_data,
                    'config': config,
                    'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
                    'schedule_type': config.get('schedule_type', 'weekly'),
                    'start_date': config.get('start_date', ''),
                    'end_date': config.get('end_date', ''),
                    'total_days': config.get('total_days', 7),
                    'selected_characters': config.get('selected_characters', []),
                    'selected_locations': config.get('selected_locations', []),
                    'selected_stories': config.get('selected_stories', []),
                    'time_slots_config': config.get('time_slots_config', self.workflow.current_config['time_slots_config']),
                    'character_distribution': config.get('character_distribution', 'balanced'),
                    'story_integration': config.get('story_integration', 'moderate'),
                    'include_holidays': config.get('include_holidays', True),
                    'include_lunar': config.get('include_lunar', True),
                    'workflow_chat': workflow_chat,
                    'llm': self.workflow.llm
                }
                
                # ä½¿ç”¨æµå¼æ‰§è¡Œå›¾è·å–æœ€ç»ˆçŠ¶æ€
                if not self.workflow.graph:
                    await self.workflow.create_schedule_graph()
                
                compiled_graph = self.workflow.graph.compile()
                
                # ç®€å•æ‰§è¡Œæµå¼å›¾ï¼Œä¸éœ€è¦æ”¶é›†çŠ¶æ€
                async for stream_chunk in compiled_graph.stream(initial_input):
                    # åªæ˜¯è®©å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œä¸æ”¶é›†çŠ¶æ€
                    pass
                
                logger.info("å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œå‡†å¤‡ä»æ•°æ®åº“è·å–æ•°æ®")
                
                # ç­‰å¾…1ç§’ç¡®ä¿æ•°æ®åº“å†™å…¥å®Œæˆ
                import time
                time.sleep(1)
                
                # ä»æ•°æ®åº“è·å–æœ€æ–°çš„æ—¥ç¨‹è®°å½•
                try:
                    from database.managers.schedule_manager import ScheduleManager
                    schedule_manager = ScheduleManager()
                    
                    # è·å–æœ€æ–°çš„æ—¥ç¨‹è®°å½•ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼‰
                    recent_schedules = schedule_manager.get_schedules_by_filter({}, limit=1)
                    
                    if recent_schedules:
                        latest_schedule = recent_schedules[0]
                        actual_schedule_id = latest_schedule['schedule_id']
                        logger.info(f"ä»æ•°æ®åº“è·å–åˆ°æœ€æ–°æ—¥ç¨‹ID: {actual_schedule_id}")
                        
                        # åˆ›å»ºæœ€ç»ˆçŠ¶æ€
                        final_state = {
                            'schedule_id': actual_schedule_id,
                            'config': config,
                            'database_success': True
                        }
                    else:
                        logger.error("æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°æ–°åˆ›å»ºçš„æ—¥ç¨‹è®°å½•")
                        final_state = {'database_success': False}
                        
                except Exception as db_error:
                    logger.error(f"ä»æ•°æ®åº“è·å–æœ€æ–°è®°å½•å¤±è´¥: {db_error}")
                    final_state = {'database_success': False}
                
                if final_state.get('database_success', False):
                    schedule_id = final_state.get('schedule_id')
                    logger.info(f"æ‰¹æ¬¡ {batch_num} å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼Œæ•°æ®åº“è®°å½•ID: {schedule_id}")
                    
                    # ç›´æ¥ä»æ•°æ®åº“è·å–å®Œæ•´æ•°æ®æ„å»ºæ‰¹æ¬¡ä¿¡æ¯
                    batch_info = self._get_batch_info_from_database(schedule_id)
                    
                    if batch_info:
                        # æ›´æ–°æ‰¹æ¬¡ç¼–å·
                        batch_info['batch_number'] = batch_num
                        # ä¿å­˜åˆ°å†å²è®°å½•
                        self.batch_history.append(batch_info)
                        logger.info(f"æ‰¹æ¬¡ {batch_num} å®Œæˆï¼Œä»æ•°æ®åº“è·å–äº†å®Œæ•´æ•°æ®")
                        return batch_info
                    else:
                        logger.error(f"æ‰¹æ¬¡ {batch_num} ä»æ•°æ®åº“è·å–æ•°æ®å¤±è´¥")
                        return None
                else:
                    logger.error(f"æ‰¹æ¬¡ {batch_num} æ•°æ®åº“æ“ä½œå¤±è´¥")
                    return None
                
            except Exception as graph_error:
                logger.error(f"æµå¼å›¾æ‰§è¡Œå¤±è´¥: {graph_error}")
                import traceback
                logger.error(traceback.format_exc())
                return None
                
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ {batch_num} ç”Ÿæˆå¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _extract_key_events(self, daily_schedules: List[Dict]) -> str:
        """ä»æ—¥ç¨‹ä¸­æå–å…³é”®äº‹ä»¶"""
        key_events = []
        for day in daily_schedules[:3]:  # åªå–å‰3å¤©çš„äº‹ä»¶ä½œä¸ºæ‘˜è¦
            for slot in day.get('time_slots', []):
                content = slot.get('story_content', '')
                if len(content) > 100:  # å†…å®¹è¾ƒä¸°å¯Œçš„äº‹ä»¶
                    key_events.append(f"{day.get('date', '')} {slot.get('slot_name', '')}: {content[:50]}...")
        return '; '.join(key_events[:3])  # æœ€å¤š3ä¸ªå…³é”®äº‹ä»¶
    
    def _extract_emotional_progress(self, daily_schedules: List[Dict]) -> str:
        """æå–æƒ…æ„Ÿå‘å±•çº¿"""
        # ç®€åŒ–æå–ï¼ŒæŸ¥æ‰¾åŒ…å«æƒ…æ„Ÿè¯æ±‡çš„å†…å®¹
        emotional_keywords = ['æ„ŸåŠ¨', 'å¼€å¿ƒ', 'æ‹…å¿ƒ', 'æœŸå¾…', 'æ»¡æ„', 'æ„Ÿè°¢', 'å‹è°Š', 'å…³ç³»', 'äº¤æµ']
        emotional_events = []
        
        for day in daily_schedules:
            for slot in day.get('time_slots', []):
                content = slot.get('story_content', '')
                for keyword in emotional_keywords:
                    if keyword in content:
                        emotional_events.append(f"ä¸{slot.get('assigned_character', '')}çš„{keyword}")
                        break
        
        return '; '.join(set(emotional_events[:3]))  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _extract_pending_issues(self, daily_schedules: List[Dict]) -> str:
        """æå–é—ç•™é—®é¢˜"""
        # ç®€åŒ–æå–ï¼ŒæŸ¥æ‰¾æœ€åä¸€å¤©çš„è®¡åˆ’æˆ–æœªå®Œæˆäº‹é¡¹
        if daily_schedules:
            last_day = daily_schedules[-1]
            daily_plan = last_day.get('daily_plan', '')
            if 'è®¡åˆ’' in daily_plan or 'å‡†å¤‡' in daily_plan:
                return daily_plan[:100] + "..." if len(daily_plan) > 100 else daily_plan
        return "æ— ç‰¹åˆ«é—ç•™é—®é¢˜"
    
    def _get_batch_info_from_database(self, schedule_id: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“è·å–å®Œæ•´çš„æ‰¹æ¬¡ä¿¡æ¯"""
        try:
            from database.managers.schedule_manager import ScheduleManager
            
            # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
            schedule_manager = ScheduleManager()
            
            # è·å–å®Œæ•´çš„æ—¥ç¨‹æ•°æ®
            full_schedule = schedule_manager.get_schedule_by_id(schedule_id)
            
            if not full_schedule:
                logger.warning(f"æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æ—¥ç¨‹: {schedule_id}")
                return None
            
            # æå–æ¯æ—¥å®‰æ’
            daily_schedules = full_schedule.get('daily_schedules', [])
            
            # æ„å»ºæ‰¹æ¬¡ä¿¡æ¯
            batch_info = {
                'batch_number': len(self.batch_history) + 1,  # åŸºäºå½“å‰å†å²æ•°é‡
                'schedule_id': schedule_id,
                'start_date': full_schedule.get('start_date', ''),
                'end_date': full_schedule.get('end_date', ''),
                'total_days': full_schedule.get('total_days', 0),
                'characters': [],  # ä»æ—¶é—´æ®µä¸­æå–
                'locations': [],   # ä»æ—¶é—´æ®µä¸­æå–
                'daily_schedules': daily_schedules,
                'schedule_summary': {},  # å¯ä»¥ä»æè¿°ä¸­è§£æ
                'weekly_plan': full_schedule.get('weekly_plan', ''),
                'key_events': self._extract_key_events(daily_schedules),
                'emotional_progress': self._extract_emotional_progress(daily_schedules),
                'pending_issues': self._extract_pending_issues(daily_schedules)
            }
            
            # ä»æ—¶é—´æ®µä¸­æå–å‚ä¸çš„è§’è‰²å’Œåœ°ç‚¹
            characters = set()
            locations = set()
            
            for day in daily_schedules:
                for slot in day.get('time_slots', []):
                    assigned_char = slot.get('assigned_character', '')
                    if assigned_char and assigned_char != 'æ–¹çŸ¥è¡¡':
                        characters.add(assigned_char)
                    
                    location = slot.get('location', '')
                    if location:
                        locations.add(location)
            
            batch_info['characters'] = list(characters)
            batch_info['locations'] = list(locations)
            
            logger.info(f"ä»æ•°æ®åº“æˆåŠŸè·å–æ‰¹æ¬¡ä¿¡æ¯: {schedule_id}")
            logger.info(f"  åŒ…å« {len(daily_schedules)} å¤©å®‰æ’")
            logger.info(f"  æ¶‰åŠ {len(characters)} ä¸ªè§’è‰²: {', '.join(list(characters)[:3])}...")
            logger.info(f"  æ¶‰åŠ {len(locations)} ä¸ªåœ°ç‚¹: {', '.join(list(locations)[:3])}...")
            
            return batch_info
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–æ‰¹æ¬¡ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    

    
    def _check_holidays_in_batch(self, batch_info: Dict[str, Any]) -> Dict[str, str]:
        """éªŒè¯æ‰¹æ¬¡ä¸­çš„èŠ‚å‡æ—¥"""
        holidays = {}
        try:
            start_date = batch_info['start_date']
            end_date = batch_info['end_date']
            
            # ä½¿ç”¨å·¥ä½œæµçš„èŠ‚å‡æ—¥æ•°æ®
            holidays_data = self.workflow.get_holidays_in_range(start_date, end_date)
            
            if holidays_data:
                logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} åŒ…å«èŠ‚å‡æ—¥: {list(holidays_data.keys())}")
                for date, holiday_info in holidays_data.items():
                    holidays[date] = holiday_info.get('name', '')
            else:
                logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} æ— èŠ‚å‡æ—¥")
                
        except Exception as e:
            logger.warning(f"æ£€æŸ¥èŠ‚å‡æ—¥å¤±è´¥: {e}")
            
        return holidays
    
    def _get_season_from_date(self, date_str: str) -> str:
        """æ ¹æ®æ—¥æœŸç¡®å®šå­£èŠ‚"""
        try:
            from datetime import datetime
            date = datetime.strptime(date_str, '%Y-%m-%d')
            month = date.month
            
            if month in [12, 1, 2]:
                return 'å†¬å­£'
            elif month in [3, 4, 5]:
                return 'æ˜¥å­£'
            elif month in [6, 7, 8]:
                return 'å¤å­£'
            elif month in [9, 10, 11]:
                return 'ç§‹å­£'
            else:
                return 'æœªçŸ¥'
        except:
            return 'æœªçŸ¥'
    

    
    def _save_detailed_json(self, batch_info: Dict[str, Any]):
        """ä¿å­˜è¯¦ç»†çš„JSONæ•°æ®ï¼ˆå¯é€‰ï¼‰"""
        try:
            json_file = self.output_dir / f"batch_{batch_info['batch_number']:03d}_{batch_info['start_date']}.json"
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(batch_info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ° {json_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è¯¦ç»†JSONæ•°æ®å¤±è´¥: {e}")
    
    async def generate_all_batches(self):
        """ç”Ÿæˆæ‰€æœ‰æ‰¹æ¬¡çš„æ—¥ç¨‹"""
        logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {self.batch_count} ä¸ªæ‰¹æ¬¡çš„æ—¥ç¨‹...")
        
        success_count = 0
        failed_count = 0
        
        for batch_num in range(1, self.batch_count + 1):
            try:
                logger.info(f"\n{'='*50}")
                logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{self.batch_count} æ‰¹æ¬¡")
                logger.info(f"{'='*50}")
                
                # ç”Ÿæˆå•ä¸ªæ‰¹æ¬¡
                batch_info = await self._generate_single_batch(batch_num)
                
                if batch_info:
                    # æ›´æ–°å½“å‰æ—¥æœŸä¸ºä¸‹ä¸€æ‰¹æ¬¡çš„å¼€å§‹æ—¥æœŸï¼ˆç¡®ä¿æ—¥æœŸè¿ç»­ï¼‰
                    next_start_date = datetime.strptime(batch_info['end_date'], '%Y-%m-%d') + timedelta(days=1)
                    self.current_date = next_start_date
                    
                    success_count += 1
                    logger.info(f"æ‰¹æ¬¡ {batch_num} å®Œæˆï¼Œä¸‹æ¬¡å¼€å§‹æ—¥æœŸ: {self.current_date.strftime('%Y-%m-%d')}")
                    
                    # æ•°æ®å·²ç»ä»æ•°æ®åº“è·å–ï¼Œæ— éœ€é‡å¤æ“ä½œ
                    
                    # éªŒè¯æ—¥æœŸè¿ç»­æ€§
                    logger.info(f"æ—¥æœŸè¿ç»­æ€§æ£€æŸ¥: å½“å‰æ‰¹æ¬¡ç»“æŸ {batch_info['end_date']}, ä¸‹æ‰¹æ¬¡å¼€å§‹ {self.current_date.strftime('%Y-%m-%d')}")
                else:
                    failed_count += 1
                    logger.error(f"æ‰¹æ¬¡ {batch_num} å¤±è´¥ï¼Œè·³è¿‡")
                    # å³ä½¿å¤±è´¥ä¹Ÿè¦æ¨è¿›æ—¥æœŸï¼Œé¿å…é‡å¤ - ä½¿ç”¨éšæœºå¤©æ•°ç¡®ä¿æ—¶é—´è¿ç»­
                    skip_days = random.randint(7, 14)  # ä¸æˆåŠŸæ—¶çš„éšæœºå¤©æ•°ä¿æŒä¸€è‡´
                    self.current_date += timedelta(days=skip_days)
                    logger.info(f"æ‰¹æ¬¡ {batch_num} å¤±è´¥ï¼Œæ¨è¿›æ—¥æœŸ {skip_days} å¤©åˆ°: {self.current_date.strftime('%Y-%m-%d')}")
                
                # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…APIé™åˆ¶
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡ {batch_num} å¤„ç†å¼‚å¸¸: {e}")
                failed_count += 1
                # å¼‚å¸¸æ—¶ä¹Ÿè¦æ¨è¿›æ—¥æœŸï¼Œé¿å…é‡å¤
                skip_days = random.randint(7, 14)
                self.current_date += timedelta(days=skip_days)
                logger.info(f"æ‰¹æ¬¡ {batch_num} å¼‚å¸¸ï¼Œæ¨è¿›æ—¥æœŸ {skip_days} å¤©åˆ°: {self.current_date.strftime('%Y-%m-%d')}")
                continue
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(success_count, failed_count)
        
        logger.info(f"\næ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        logger.info(f"æˆåŠŸ: {success_count} æ‰¹æ¬¡")
        logger.info(f"å¤±è´¥: {failed_count} æ‰¹æ¬¡")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # ç¡®ä¿ç¨‹åºèƒ½å¤Ÿæ­£å¸¸ç»“æŸ
        print(f"\næ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œç¨‹åºå³å°†é€€å‡º...")
        return success_count, failed_count
    
    def _generate_summary_report(self, success_count: int, failed_count: int):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        try:
            report_file = self.output_dir / f"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆæ€»ç»“æŠ¥å‘Š\n")
                f.write(f"{'='*50}\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å¼€å§‹æ—¥æœŸ: {self.start_date.strftime('%Y-%m-%d')}\n")
                f.write(f"è®¡åˆ’æ‰¹æ¬¡: {self.batch_count}\n")
                f.write(f"æˆåŠŸæ‰¹æ¬¡: {success_count}\n")
                f.write(f"å¤±è´¥æ‰¹æ¬¡: {failed_count}\n")
                f.write(f"æˆåŠŸç‡: {success_count/self.batch_count*100:.1f}%\n\n")
                
                f.write("æ‰¹æ¬¡è¯¦æƒ…:\n")
                f.write("-" * 30 + "\n")
                for batch in self.batch_history:
                    f.write(f"æ‰¹æ¬¡ {batch['batch_number']}: {batch['start_date']} - {batch['end_date']} "
                           f"({batch['total_days']}å¤©, {len(batch['characters'])}è§’è‰², {len(batch['locations'])}åœ°ç‚¹)\n")
                
                if self.batch_history:
                    total_days = sum(batch['total_days'] for batch in self.batch_history)
                    f.write(f"\næ€»è®¡ç”Ÿæˆå¤©æ•°: {total_days} å¤©\n")
                    f.write(f"å¹³å‡æ¯æ‰¹æ¬¡å¤©æ•°: {total_days/len(self.batch_history):.1f} å¤©\n")
            
            logger.info(f"æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨')
    parser.add_argument('--start-date', default='2025-07-03', help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--batch-count', type=int, default=3, help='æ‰¹æ¬¡æ•°é‡')
    
    args = parser.parse_args()
    
    print(f"æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨å¯åŠ¨")
    print(f"å¼€å§‹æ—¥æœŸ: {args.start_date}")
    print(f"æ‰¹æ¬¡æ•°é‡: {args.batch_count}")
    print(f"è¾“å‡ºç›®å½•: workspace/batch_schedule_output/")
    
    try:
        generator = BatchScheduleGenerator(
            start_date=args.start_date,
            batch_count=args.batch_count
        )
        
        success_count, failed_count = await generator.generate_all_batches()
        
        print(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        print(f"è¾“å‡ºç›®å½•: {generator.output_dir}")
        print(f"æˆåŠŸç‡: {success_count}/{generator.batch_count} ({success_count/generator.batch_count*100:.1f}%)")
        
    except KeyboardInterrupt:
        print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print(f"\nç¨‹åºé€€å‡º")
        sys.exit(0)


if __name__ == "__main__":
    # è®¾ç½®Windowså¼‚æ­¥äº‹ä»¶å¾ªç¯ç­–ç•¥
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(main()) 
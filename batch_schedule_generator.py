#!/usr/bin/env python3
"""
æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨ - æœ¬åœ°mainå¯åŠ¨è„šæœ¬
æ”¯æŒæŒ‰æ‰¹æ¬¡ç”Ÿæˆæ—¥ç¨‹ï¼Œæ¯æ‰¹æ¬¡éšæœºé…ç½®ï¼Œä¿å­˜ä¸ºCSVæ ¼å¼
"""

import asyncio
import random
import json
import csv
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging
import io



# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
src_path = current_dir / "src"
sys.path.insert(0, str(src_path))

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„ä»¥æ”¯æŒç»å¯¹å¯¼å…¥
sys.path.insert(0, str(current_dir))

from src.workflow.schedule_workflow import ScheduleWorkflow
from src.llm.base import LLMFactory
from src.core.types import LLMConfig
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_schedule_generator.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class BatchScheduleGenerator:
    """æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨"""
    
    def __init__(self, start_date: str = "2025-07-02", batch_count: int = 3):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            batch_count: æ‰¹æ¬¡æ•°é‡
        """
        self.start_date = datetime.strptime(start_date, '%Y-%m-%d')
        self.batch_count = batch_count
        self.current_date = self.start_date
        self.workflow = None
        self.llm = None
        self.batch_history = []  # å­˜å‚¨æ¯æ‰¹æ¬¡çš„æ€»ç»“ï¼Œç”¨äºè¿ç»­æ€§
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path("workspace/batch_schedule_output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # CSVæ–‡ä»¶è·¯å¾„
        self.csv_file = self.output_dir / f"batch_schedules_{start_date.replace('-', '')}.csv"
        
        # åˆå§‹åŒ–LLMå’Œå·¥ä½œæµ
        self._init_workflow()
        
        logger.info(f"æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"å¼€å§‹æ—¥æœŸ: {start_date}")
        logger.info(f"æ‰¹æ¬¡æ•°é‡: {batch_count}")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {self.csv_file}")
    
    def _init_workflow(self):
        """åˆå§‹åŒ–å·¥ä½œæµå’ŒLLM"""
        try:
            # åˆ›å»ºLLMå®ä¾‹
            llm_config = LLMConfig(
                provider="doubao",
                api_key=os.getenv('DOUBAO_API_KEY', 'b633a622-b5d0-4f16-a8a9-616239cf15d1'),
                model_name=os.getenv('DOUBAO_MODEL_DEEPSEEKR1', 'ep-20250221154107-c4qc7'),
                temperature=0.7,
                max_tokens=16384
            )
            
            llm_factory = LLMFactory()
            self.llm = llm_factory.create(llm_config)
            
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            self.workflow = ScheduleWorkflow(llm=self.llm)
            
            logger.info("LLMå’Œå·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"LLMå’Œå·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _get_random_config(self, batch_num: int) -> Dict[str, Any]:
        """ç”Ÿæˆéšæœºé…ç½®"""
        # éšæœºå¤©æ•° (7-30å¤©)
        total_days = random.randint(7, 30)
        end_date = self.current_date + timedelta(days=total_days - 1)
        
        # è·å–å¯ç”¨è§’è‰²åˆ—è¡¨ï¼ˆæ’é™¤ä¸»è§’æ–¹çŸ¥è¡¡ï¼‰
        available_characters = list(self.workflow.characters_data.get("è§’è‰²åˆ—è¡¨", {}).keys())
        if 'æ–¹çŸ¥è¡¡' in available_characters:
            available_characters.remove('æ–¹çŸ¥è¡¡')
        
        # éšæœºé€‰æ‹©è§’è‰² (3-9ä¸ª)
        char_count = min(random.randint(3, 9), len(available_characters))
        selected_characters = random.sample(available_characters, char_count)
        
        # è·å–å¯ç”¨åœ°ç‚¹åˆ—è¡¨
        available_locations = []
        for district_name, district_info in self.workflow.locations_data.get("districts", {}).items():
            for loc_name, loc_info in district_info.get("locations", {}).items():
                available_locations.append(loc_info.get('name', loc_name))
        
        # éšæœºé€‰æ‹©åœ°ç‚¹ (3-9ä¸ª)
        loc_count = min(random.randint(3, 9), len(available_locations))
        selected_locations = random.sample(available_locations, loc_count)
        
        # ç”Ÿæˆé…ç½®
        config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',
            'schedule_type': 'weekly',
            'start_date': self.current_date.strftime('%Y-%m-%d'),
            'end_date': end_date.strftime('%Y-%m-%d'),
            'total_days': total_days,
            'selected_characters': selected_characters,
            'selected_locations': selected_locations,
            'selected_stories': [],  # æš‚æ—¶ä¸ä½¿ç”¨å‰§æƒ…
            'time_slots_config': {
                'å¤œé—´': {'start': '23:00', 'end': '06:00'},
                'ä¸Šåˆ': {'start': '06:00', 'end': '11:00'},
                'ä¸­åˆ': {'start': '11:00', 'end': '14:00'},
                'ä¸‹åˆ': {'start': '14:00', 'end': '18:00'},
                'æ™šä¸Š': {'start': '18:00', 'end': '23:00'}
            },
            'character_distribution': 'balanced',
            'story_integration': 'moderate',
            'include_holidays': True,
            'include_lunar': True,
            'mood_variety': True,
            'location_variety': True,
            # æ·»åŠ ä¸Šä¸€æ‰¹æ¬¡æ€»ç»“ä¿¡æ¯ç”¨äºè¿ç»­æ€§
            'previous_batch_summary': self._get_previous_summary() if batch_num > 1 else ""
        }
        
        return config
    
    def _get_previous_summary(self) -> str:
        """è·å–ä¸Šä¸€æ‰¹æ¬¡çš„æ€»ç»“ä¿¡æ¯ï¼Œç”¨äºä¿æŒè¿ç»­æ€§"""
        if not self.batch_history:
            return ""
        
        last_batch = self.batch_history[-1]
        summary = f"""
## ä¸Šä¸€æ‰¹æ¬¡æ€»ç»“ï¼ˆ{last_batch['start_date']} - {last_batch['end_date']}ï¼‰

**æ—¶é—´èŒƒå›´**: {last_batch['start_date']} è‡³ {last_batch['end_date']}ï¼ˆ{last_batch['total_days']}å¤©ï¼‰
**ä¸»è¦è§’è‰²**: {', '.join(last_batch['characters'])}
**ä¸»è¦åœ°ç‚¹**: {', '.join(last_batch['locations'])}
**é‡è¦äº‹ä»¶**: {last_batch.get('key_events', 'å·¥ä½œã€ç ”ç©¶ã€ç¤¾äº¤ç­‰æ—¥å¸¸æ´»åŠ¨')}
**æƒ…æ„Ÿå‘å±•**: {last_batch.get('emotional_progress', 'ä¸å„è§’è‰²ä¿æŒè‰¯å¥½å…³ç³»')}
**é—ç•™é—®é¢˜**: {last_batch.get('pending_issues', 'æ— ç‰¹åˆ«é—ç•™é—®é¢˜')}

è¯·ç¡®ä¿æ–°çš„æ—¥ç¨‹ä¸ä¸Šè¿°æƒ…å†µè‡ªç„¶è¡”æ¥ï¼Œé¿å…çªå…€çš„å˜åŒ–ã€‚
"""
        return summary
    
    async def _generate_single_batch(self, batch_num: int) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆå•ä¸ªæ‰¹æ¬¡çš„æ—¥ç¨‹"""
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆç¬¬ {batch_num} æ‰¹æ¬¡æ—¥ç¨‹...")
            
            # ç”Ÿæˆéšæœºé…ç½®
            config = self._get_random_config(batch_num)
            
            logger.info(f"æ‰¹æ¬¡ {batch_num} é…ç½®:")
            logger.info(f"  æ—¥æœŸèŒƒå›´: {config['start_date']} - {config['end_date']} ({config['total_days']}å¤©)")
            logger.info(f"  è§’è‰²æ•°é‡: {len(config['selected_characters'])}")
            logger.info(f"  åœ°ç‚¹æ•°é‡: {len(config['selected_locations'])}")
            logger.info(f"  é€‰æ‹©è§’è‰²: {', '.join(config['selected_characters'])}")
            logger.info(f"  é€‰æ‹©åœ°ç‚¹: {', '.join(config['selected_locations'])}")
            
            # åˆ›å»ºç®€åŒ–çš„å·¥ä½œæµèŠå¤©æ¥å£ï¼ˆä¸éœ€è¦UIï¼‰
            class SimpleWorkflowChat:
                def __init__(self):
                    self.current_node = ""
                
                async def add_node_message(self, node_name: str, message: str, status: str):
                    logger.info(f"[{node_name}] {message}")
                
                def _create_workflow_progress(self):
                    return ""
            
            workflow_chat = SimpleWorkflowChat()
            
            # æ‰§è¡Œå·¥ä½œæµ
            schedule_result = None
            async for progress in self.workflow.execute_workflow_stream(config, workflow_chat):
                # è·å–æœ€ç»ˆç»“æœ
                schedule_result = progress
            
            if schedule_result and schedule_result.get('save_success'):
                logger.info(f"æ‰¹æ¬¡ {batch_num} ç”Ÿæˆå¹¶ä¿å­˜æˆåŠŸ!")
                
                # æå–ç”Ÿæˆçš„æ•°æ®ç”¨äºCSVä¿å­˜
                schedule_data = schedule_result.get('schedule_result', {})
                daily_schedules = schedule_data.get('daily_schedules', [])
                
                # æ„å»ºæ‰¹æ¬¡ä¿¡æ¯
                batch_info = {
                    'batch_number': batch_num,
                    'schedule_id': schedule_result.get('schedule_id', ''),
                    'start_date': config['start_date'],
                    'end_date': config['end_date'],
                    'total_days': config['total_days'],
                    'characters': config['selected_characters'],
                    'locations': config['selected_locations'],
                    'daily_schedules': daily_schedules,
                    'schedule_summary': schedule_data.get('schedule_summary', {}),
                    'weekly_plan': schedule_data.get('weekly_plan', ''),
                    'key_events': self._extract_key_events(daily_schedules),
                    'emotional_progress': self._extract_emotional_progress(daily_schedules),
                    'pending_issues': self._extract_pending_issues(daily_schedules)
                }
                
                # ä¿å­˜åˆ°å†å²è®°å½•
                self.batch_history.append(batch_info)
                
                return batch_info
            else:
                logger.error(f"æ‰¹æ¬¡ {batch_num} ç”Ÿæˆå¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ {batch_num} ç”Ÿæˆå¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _extract_key_events(self, daily_schedules: List[Dict]) -> str:
        """ä»æ—¥ç¨‹ä¸­æå–å…³é”®äº‹ä»¶"""
        key_events = []
        for day in daily_schedules[:3]:  # åªå–å‰3å¤©çš„äº‹ä»¶ä½œä¸ºæ‘˜è¦
            for slot in day.get('time_slots', []):
                content = slot.get('story_content', '')
                if len(content) > 100:  # å†…å®¹è¾ƒä¸°å¯Œçš„äº‹ä»¶
                    key_events.append(f"{day.get('date', '')} {slot.get('slot_name', '')}: {content[:50]}...")
        return '; '.join(key_events[:3])  # æœ€å¤š3ä¸ªå…³é”®äº‹ä»¶
    
    def _extract_emotional_progress(self, daily_schedules: List[Dict]) -> str:
        """æå–æƒ…æ„Ÿå‘å±•çº¿"""
        # ç®€åŒ–æå–ï¼ŒæŸ¥æ‰¾åŒ…å«æƒ…æ„Ÿè¯æ±‡çš„å†…å®¹
        emotional_keywords = ['æ„ŸåŠ¨', 'å¼€å¿ƒ', 'æ‹…å¿ƒ', 'æœŸå¾…', 'æ»¡æ„', 'æ„Ÿè°¢', 'å‹è°Š', 'å…³ç³»', 'äº¤æµ']
        emotional_events = []
        
        for day in daily_schedules:
            for slot in day.get('time_slots', []):
                content = slot.get('story_content', '')
                for keyword in emotional_keywords:
                    if keyword in content:
                        emotional_events.append(f"ä¸{slot.get('assigned_character', '')}çš„{keyword}")
                        break
        
        return '; '.join(set(emotional_events[:3]))  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _extract_pending_issues(self, daily_schedules: List[Dict]) -> str:
        """æå–é—ç•™é—®é¢˜"""
        # ç®€åŒ–æå–ï¼ŒæŸ¥æ‰¾æœ€åä¸€å¤©çš„è®¡åˆ’æˆ–æœªå®Œæˆäº‹é¡¹
        if daily_schedules:
            last_day = daily_schedules[-1]
            daily_plan = last_day.get('daily_plan', '')
            if 'è®¡åˆ’' in daily_plan or 'å‡†å¤‡' in daily_plan:
                return daily_plan[:100] + "..." if len(daily_plan) > 100 else daily_plan
        return "æ— ç‰¹åˆ«é—ç•™é—®é¢˜"
    
    def _save_batch_to_csv(self, batch_info: Dict[str, Any]):
        """å°†æ‰¹æ¬¡æ•°æ®æŒ‰æ—¥æœŸè¡Œä¿å­˜åˆ°CSVæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œç¡®å®šæ˜¯å¦éœ€è¦å†™å…¥è¡¨å¤´
            file_exists = self.csv_file.exists()
            
            # éªŒè¯æ—¥æœŸæ˜¯å¦åŒ…å«èŠ‚å‡æ—¥
            holidays_in_batch = self._check_holidays_in_batch(batch_info)
            
            with open(self.csv_file, 'a', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = [
                    'æ‰¹æ¬¡ç¼–å·', 'æ—¥æœŸ', 'å¤©æ°”', 'åœ°ç‚¹', 'å­£èŠ‚', 'èŠ‚å‡æ—¥',
                    'å‘¨æœŸè®¡åˆ’', 'æ¯æ—¥è®¡åˆ’', 'å¤œé—´', 'ä¸Šåˆ', 'ä¸­åˆ', 'ä¸‹åˆ', 'æ™šä¸Š', 'æ¶‰åŠè§’è‰²'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                # å¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼Œå†™å…¥è¡¨å¤´
                if not file_exists:
                    writer.writeheader()
                
                # é€æ—¥å†™å…¥æ•°æ®
                daily_schedules = batch_info.get('daily_schedules', [])
                weekly_plan = batch_info.get('weekly_plan', '')
                
                for day_data in daily_schedules:
                    # æå–å½“æ—¥çš„5ä¸ªæ—¶é—´æ®µæ•…äº‹
                    time_slots = {slot['slot_name']: slot.get('story_content', '') 
                                for slot in day_data.get('time_slots', [])}
                    
                    # æå–å½“æ—¥æ¶‰åŠçš„è§’è‰²
                    daily_characters = set()
                    for slot in day_data.get('time_slots', []):
                        involved_chars = slot.get('involved_characters', [])
                        if isinstance(involved_chars, list):
                            daily_characters.update(involved_chars)
                    
                    # ç¡®å®šå­£èŠ‚
                    season = self._get_season_from_date(day_data.get('date', ''))
                    
                    # å†™å…¥è¯¥æ—¥æ•°æ®
                    writer.writerow({
                        'æ‰¹æ¬¡ç¼–å·': batch_info['batch_number'],
                        'æ—¥æœŸ': day_data.get('date', ''),
                        'å¤©æ°”': day_data.get('weather', ''),
                        'åœ°ç‚¹': self._extract_daily_locations(day_data),
                        'å­£èŠ‚': season,
                        'èŠ‚å‡æ—¥': day_data.get('holiday_name', '') if day_data.get('is_holiday', False) else '',
                        'å‘¨æœŸè®¡åˆ’': weekly_plan,
                        'æ¯æ—¥è®¡åˆ’': day_data.get('daily_plan', ''),
                        'å¤œé—´': time_slots.get('å¤œé—´', ''),
                        'ä¸Šåˆ': time_slots.get('ä¸Šåˆ', ''),
                        'ä¸­åˆ': time_slots.get('ä¸­åˆ', ''),
                        'ä¸‹åˆ': time_slots.get('ä¸‹åˆ', ''),
                        'æ™šä¸Š': time_slots.get('æ™šä¸Š', ''),
                        'æ¶‰åŠè§’è‰²': ', '.join(sorted(daily_characters))
                    })
            
            logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} æ•°æ®å·²æŒ‰æ—¥æœŸè¡Œä¿å­˜åˆ° CSV æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ‰¹æ¬¡æ•°æ®åˆ°CSVå¤±è´¥: {e}")
    
    def _check_holidays_in_batch(self, batch_info: Dict[str, Any]) -> Dict[str, str]:
        """éªŒè¯æ‰¹æ¬¡ä¸­çš„èŠ‚å‡æ—¥"""
        holidays = {}
        try:
            start_date = batch_info['start_date']
            end_date = batch_info['end_date']
            
            # ä½¿ç”¨å·¥ä½œæµçš„èŠ‚å‡æ—¥æ•°æ®
            holidays_data = self.workflow.get_holidays_in_range(start_date, end_date)
            
            if holidays_data:
                logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} åŒ…å«èŠ‚å‡æ—¥: {list(holidays_data.keys())}")
                for date, holiday_info in holidays_data.items():
                    holidays[date] = holiday_info.get('name', '')
            else:
                logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} æ— èŠ‚å‡æ—¥")
                
        except Exception as e:
            logger.warning(f"æ£€æŸ¥èŠ‚å‡æ—¥å¤±è´¥: {e}")
            
        return holidays
    
    def _get_season_from_date(self, date_str: str) -> str:
        """æ ¹æ®æ—¥æœŸç¡®å®šå­£èŠ‚"""
        try:
            from datetime import datetime
            date = datetime.strptime(date_str, '%Y-%m-%d')
            month = date.month
            
            if month in [12, 1, 2]:
                return 'å†¬å­£'
            elif month in [3, 4, 5]:
                return 'æ˜¥å­£'
            elif month in [6, 7, 8]:
                return 'å¤å­£'
            elif month in [9, 10, 11]:
                return 'ç§‹å­£'
            else:
                return 'æœªçŸ¥'
        except:
            return 'æœªçŸ¥'
    
    def _extract_daily_locations(self, day_data: Dict) -> str:
        """æå–å½“æ—¥çš„ä¸»è¦åœ°ç‚¹"""
        locations = set()
        for slot in day_data.get('time_slots', []):
            location = slot.get('location', '')
            if location:
                locations.add(location)
        return ', '.join(sorted(locations))
    
    def _extract_daily_plans(self, daily_schedules: List[Dict]) -> str:
        """æå–æ¯æ—¥è®¡åˆ’æ‘˜è¦"""
        plans = []
        for day in daily_schedules[:3]:  # åªå–å‰3å¤©ä½œä¸ºæ‘˜è¦
            date = day.get('date', '')
            plan = day.get('daily_plan', '')
            if plan:
                plans.append(f"{date}: {plan[:80]}...")
        return '; '.join(plans)
    
    def _extract_time_slot_stories(self, daily_schedules: List[Dict]) -> str:
        """æå–5ä¸ªæ—¶é—´æ®µçš„æ•…äº‹æ‘˜è¦"""
        stories = []
        time_slots = ['å¤œé—´', 'ä¸Šåˆ', 'ä¸­åˆ', 'ä¸‹åˆ', 'æ™šä¸Š']
        
        for day in daily_schedules[:2]:  # å–å‰2å¤©çš„æ•…äº‹
            date = day.get('date', '')
            for slot in day.get('time_slots', []):
                slot_name = slot.get('slot_name', '')
                story = slot.get('story_content', '')
                if story and slot_name in time_slots:
                    stories.append(f"{date}-{slot_name}: {story[:60]}...")
        
        return '; '.join(stories[:5])  # é™åˆ¶é•¿åº¦
    
    def _extract_character_interactions(self, daily_schedules: List[Dict]) -> str:
        """æå–è§’è‰²äº’åŠ¨è¯¦æƒ…ï¼ŒåªåŒ…å«è§’è‰²åç§°"""
        characters = set()
        
        for day in daily_schedules:
            for slot in day.get('time_slots', []):
                involved_chars = slot.get('involved_characters', [])
                if isinstance(involved_chars, list):
                    characters.update(involved_chars)
        
        return ', '.join(sorted(characters))
    
    def _save_detailed_json(self, batch_info: Dict[str, Any]):
        """ä¿å­˜è¯¦ç»†çš„JSONæ•°æ®ï¼ˆå¯é€‰ï¼‰"""
        try:
            json_file = self.output_dir / f"batch_{batch_info['batch_number']:03d}_{batch_info['start_date']}.json"
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(batch_info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ‰¹æ¬¡ {batch_info['batch_number']} è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ° {json_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è¯¦ç»†JSONæ•°æ®å¤±è´¥: {e}")
    
    async def generate_all_batches(self):
        """ç”Ÿæˆæ‰€æœ‰æ‰¹æ¬¡çš„æ—¥ç¨‹"""
        logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {self.batch_count} ä¸ªæ‰¹æ¬¡çš„æ—¥ç¨‹...")
        
        success_count = 0
        failed_count = 0
        
        for batch_num in range(1, self.batch_count + 1):
            try:
                logger.info(f"\n{'='*50}")
                logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{self.batch_count} æ‰¹æ¬¡")
                logger.info(f"{'='*50}")
                
                # ç”Ÿæˆå•ä¸ªæ‰¹æ¬¡
                batch_info = await self._generate_single_batch(batch_num)
                
                if batch_info:
                    # ç«‹å³ä¿å­˜åˆ°CSVï¼ˆå¢é‡ä¿å­˜ï¼‰
                    self._save_batch_to_csv(batch_info)
                    logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å·²å¢é‡ä¿å­˜åˆ°CSV")
                    
                    # ä¿å­˜è¯¦ç»†JSONï¼ˆå¯é€‰ï¼‰
                    self._save_detailed_json(batch_info)
                    
                    # æ›´æ–°å½“å‰æ—¥æœŸä¸ºä¸‹ä¸€æ‰¹æ¬¡çš„å¼€å§‹æ—¥æœŸï¼ˆç¡®ä¿æ—¥æœŸè¿ç»­ï¼‰
                    next_start_date = datetime.strptime(batch_info['end_date'], '%Y-%m-%d') + timedelta(days=1)
                    self.current_date = next_start_date
                    
                    success_count += 1
                    logger.info(f"æ‰¹æ¬¡ {batch_num} å®Œæˆï¼Œä¸‹æ¬¡å¼€å§‹æ—¥æœŸ: {self.current_date.strftime('%Y-%m-%d')}")
                    
                    # éªŒè¯æ—¥æœŸè¿ç»­æ€§
                    logger.info(f"ğŸ“… æ—¥æœŸè¿ç»­æ€§æ£€æŸ¥: å½“å‰æ‰¹æ¬¡ç»“æŸ {batch_info['end_date']}, ä¸‹æ‰¹æ¬¡å¼€å§‹ {self.current_date.strftime('%Y-%m-%d')}")
                else:
                    failed_count += 1
                    logger.error(f"æ‰¹æ¬¡ {batch_num} å¤±è´¥ï¼Œè·³è¿‡")
                    # å³ä½¿å¤±è´¥ä¹Ÿè¦æ¨è¿›æ—¥æœŸï¼Œé¿å…é‡å¤
                    self.current_date += timedelta(days=7)  # è·³è¿‡7å¤©
                
                # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…APIé™åˆ¶
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡ {batch_num} å¤„ç†å¼‚å¸¸: {e}")
                failed_count += 1
                continue
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(success_count, failed_count)
        
        logger.info(f"\næ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        logger.info(f"æˆåŠŸ: {success_count} æ‰¹æ¬¡")
        logger.info(f"å¤±è´¥: {failed_count} æ‰¹æ¬¡")
        logger.info(f"CSVæ–‡ä»¶: {self.csv_file}")
    
    def _generate_summary_report(self, success_count: int, failed_count: int):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        try:
            report_file = self.output_dir / f"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆæ€»ç»“æŠ¥å‘Š\n")
                f.write(f"{'='*50}\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å¼€å§‹æ—¥æœŸ: {self.start_date.strftime('%Y-%m-%d')}\n")
                f.write(f"è®¡åˆ’æ‰¹æ¬¡: {self.batch_count}\n")
                f.write(f"æˆåŠŸæ‰¹æ¬¡: {success_count}\n")
                f.write(f"å¤±è´¥æ‰¹æ¬¡: {failed_count}\n")
                f.write(f"æˆåŠŸç‡: {success_count/self.batch_count*100:.1f}%\n\n")
                
                f.write("æ‰¹æ¬¡è¯¦æƒ…:\n")
                f.write("-" * 30 + "\n")
                for batch in self.batch_history:
                    f.write(f"æ‰¹æ¬¡ {batch['batch_number']}: {batch['start_date']} - {batch['end_date']} "
                           f"({batch['total_days']}å¤©, {len(batch['characters'])}è§’è‰², {len(batch['locations'])}åœ°ç‚¹)\n")
                
                if self.batch_history:
                    total_days = sum(batch['total_days'] for batch in self.batch_history)
                    f.write(f"\næ€»è®¡ç”Ÿæˆå¤©æ•°: {total_days} å¤©\n")
                    f.write(f"å¹³å‡æ¯æ‰¹æ¬¡å¤©æ•°: {total_days/len(self.batch_history):.1f} å¤©\n")
            
            logger.info(f"æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨')
    parser.add_argument('--start-date', default='2025-07-02', help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--batch-count', type=int, default=3, help='æ‰¹æ¬¡æ•°é‡')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ æ‰¹é‡æ—¥ç¨‹ç”Ÿæˆå™¨å¯åŠ¨")
    print(f"ğŸ“… å¼€å§‹æ—¥æœŸ: {args.start_date}")
    print(f"ğŸ”¢ æ‰¹æ¬¡æ•°é‡: {args.batch_count}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: workspace/batch_schedule_output/")
    
    try:
        generator = BatchScheduleGenerator(
            start_date=args.start_date,
            batch_count=args.batch_count
        )
        
        await generator.generate_all_batches()
        
        print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š æŸ¥çœ‹ç»“æœ: {generator.csv_file}")
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®Windowså¼‚æ­¥äº‹ä»¶å¾ªç¯ç­–ç•¥
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(main()) 
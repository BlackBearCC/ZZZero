# DeepSeek R1 æ¨ç†åŠŸèƒ½é›†æˆè¯´æ˜

## æ¦‚è¿°

æœ¬é¡¹ç›®å·²æˆåŠŸé›†æˆ DeepSeek R1 æ¨ç†æ¨¡å‹ï¼Œä¸º ZZZero æ™ºèƒ½ä»£ç†ç³»ç»Ÿæ·»åŠ äº†å¼ºå¤§çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚DeepSeek R1 æ˜¯ä¸€ä¸ªä¸“é—¨çš„æ¨ç†æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¹‹å‰è¿›è¡Œæ·±åº¦çš„é“¾å¼æ€ç»´ï¼ˆChain of Thoughtï¼‰æ¨ç†ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### 1. æ¨ç†å¢å¼º
- **æ·±åº¦æ¨ç†**: æ¨¡å‹åœ¨å›ç­”å‰ä¼šè¿›è¡Œå†…éƒ¨é€»è¾‘æ¨ç†
- **é“¾å¼æ€ç»´**: æ”¯æŒå¤šæ­¥éª¤æ¨ç†è¿‡ç¨‹
- **è‡ªæˆ‘éªŒè¯**: å…·å¤‡åæ€å’ŒéªŒè¯èƒ½åŠ›
- **æ¨ç†å¯è§†åŒ–**: å¯é€‰æ‹©æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹

### 2. æµå¼è¾“å‡º
- **å®æ—¶æ¨ç†**: æ¨ç†è¿‡ç¨‹å®æ—¶æµå¼è¾“å‡º
- **åˆ†é˜¶æ®µæ˜¾ç¤º**: æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆåˆ†åˆ«è¾“å‡º
- **ä¸­æ–­æœºåˆ¶**: æ”¯æŒæ¨ç†è¿‡ç¨‹ä¸­çš„å·¥å…·è°ƒç”¨

### 3. ZZZero é£æ ¼é€‚é…
- **å¤å¤æœºå™¨äºº**: ä¿æŒ ZZZero çš„ç‹¬ç‰¹ä¸ªæ€§
- **æ¨ç†å±•ç¤º**: ä»¥æœºå™¨äººé£æ ¼å±•ç¤ºæ¨ç†è¿‡ç¨‹
- **æ™ºèƒ½åˆ†æ**: å¯¹å·¥å…·ç»“æœè¿›è¡Œæ·±åº¦åˆ†æ

## ğŸ› ï¸ ç¯å¢ƒé…ç½®

### å¿…éœ€ç¯å¢ƒå˜é‡

```bash
# API å¯†é’¥ï¼ˆä»»é€‰å…¶ä¸€ï¼‰
export ARK_API_KEY="your_api_key_here"
# æˆ–
export DOUBAO_API_KEY="your_api_key_here"

# DeepSeek R1 æ¨¡å‹åç§°
export DOUBAO_MODEL_DEEPSEEKR1="deepseek-reasoner"

# API åŸºç¡€URLï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
export DOUBAO_BASE_URL="https://ark.cn-beijing.volces.com/api/v3"
```

### æ¨èé…ç½®

```bash
# æ¨ç†æ¨¡å‹ä¸“ç”¨é…ç½®
export DOUBAO_MODEL_DEEPSEEKR1="deepseek-reasoner"
# æ¸©åº¦è®¾ç½®ï¼ˆæ¨è0.6ï¼‰
export DEEPSEEK_TEMPERATURE="0.6"
# æœ€å¤§è¾“å‡ºé•¿åº¦ï¼ˆæ”¯æŒ32Kï¼‰
export DEEPSEEK_MAX_TOKENS="32768"
```

## ğŸ“š API ä½¿ç”¨æ–¹æ³•

### 1. åŸºç¡€æ¨ç†æ¥å£

```python
from llm.doubao import DoubaoLLM
from core.types import LLMConfig, Message, MessageRole

# åˆ›å»ºé…ç½®
config = LLMConfig(
    provider="doubao",
    model_name="doubao-pro-4k",
    api_key="your_api_key",
    temperature=0.6,
    max_tokens=32768
)

# åˆ›å»ºLLMå®ä¾‹
llm = DoubaoLLM(config)
await llm.initialize()

# æ¨ç†è°ƒç”¨
messages = [Message(role=MessageRole.USER, content="ä½ çš„é—®é¢˜")]
result = await llm.think(messages)

print(f"æ¨ç†è¿‡ç¨‹: {result.reasoning_content}")
print(f"æœ€ç»ˆç­”æ¡ˆ: {result.content}")
```

### 2. æµå¼æ¨ç†æ¥å£

```python
async for chunk_data in llm.stream_think(messages):
    chunk_type = chunk_data.get("type")
    
    if chunk_type == "reasoning_chunk":
        # æ¨ç†è¿‡ç¨‹è¾“å‡º
        print(f"æ¨ç†: {chunk_data['content']}", end="")
        
    elif chunk_type == "content_chunk":
        # æœ€ç»ˆç­”æ¡ˆè¾“å‡º
        print(f"ç­”æ¡ˆ: {chunk_data['content']}", end="")
        
    elif chunk_type == "think_complete":
        # æ¨ç†å®Œæˆ
        print("\næ¨ç†å®Œæˆï¼")
        break
```

### 3. StreamReactAgentNode ä½¿ç”¨

```python
from nodes.stream_react_agent_node import StreamReactAgentNode

# åˆ›å»ºæµå¼ReActèŠ‚ç‚¹ï¼ˆè‡ªåŠ¨æ£€æµ‹æ¨ç†èƒ½åŠ›ï¼‰
agent_node = StreamReactAgentNode("agent", llm, tool_manager)

# æ‰§è¡Œæ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨æ¨ç†åŠŸèƒ½
async for chunk in agent_node._stream_react_generation(messages):
    if chunk["type"] == "reasoning_chunk":
        print(f"ZZZeroæ€è€ƒ: {chunk['content']}")
    elif chunk["type"] == "text_chunk":
        print(f"ZZZeroå›å¤: {chunk['content']}")
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡åè¿è¡Œæµ‹è¯•
python test_deepseek_r1_think.py
```

### æµ‹è¯•å†…å®¹
1. **åŸºç¡€æ¨ç†æµ‹è¯•**: éªŒè¯ `think()` æ–¹æ³•
2. **æµå¼æ¨ç†æµ‹è¯•**: éªŒè¯ `stream_think()` æ–¹æ³•
3. **ç¯å¢ƒå˜é‡æ£€æŸ¥**: ç¡®è®¤é…ç½®æ­£ç¡®æ€§
4. **é”™è¯¯å¤„ç†æµ‹è¯•**: éªŒè¯å¼‚å¸¸å¤„ç†æœºåˆ¶

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. å¤æ‚æ•°å­¦é—®é¢˜
```python
# æ•°å­¦æ¨ç†ç¤ºä¾‹
question = "å¦‚æœä¸€ä¸ªæ­£æ–¹å½¢çš„å‘¨é•¿æ˜¯20å˜ç±³ï¼Œé‚£ä¹ˆå®ƒçš„é¢ç§¯æ˜¯å¤šå°‘ï¼Ÿè¯·è¯¦ç»†æ¨ç†ã€‚"
result = await llm.think([Message(role=MessageRole.USER, content=question)])
```

### 2. é€»è¾‘æ¨ç†ä»»åŠ¡
```python
# é€»è¾‘æ¨ç†ç¤ºä¾‹
question = "ä¸ºä»€ä¹ˆ9.11æ¯”9.8å¤§ï¼Ÿè¯·é€æ­¥æ¨ç†ã€‚"
result = await llm.think([Message(role=MessageRole.USER, content=question)])
```

### 3. ä»£ç åˆ†æ
```python
# ä»£ç æ¨ç†ç¤ºä¾‹
question = "åˆ†æè¿™æ®µä»£ç çš„æ—¶é—´å¤æ‚åº¦ï¼Œå¹¶è§£é‡Šæ¨ç†è¿‡ç¨‹ã€‚"
result = await llm.think([Message(role=MessageRole.USER, content=question)])
```

## ğŸ”§ é…ç½®ä¼˜åŒ–

### DeepSeek R1 ä¸“ç”¨å‚æ•°

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| temperature | 0.6 | é˜²æ­¢æ— é™é‡å¤æˆ–ä¸è¿è´¯è¾“å‡º |
| max_tokens | 32768 | æ”¯æŒé•¿æ¨ç†è¿‡ç¨‹ |
| top_p | ä¸æ”¯æŒ | DeepSeek R1 ä¸æ”¯æŒæ­¤å‚æ•° |
| presence_penalty | ä¸æ”¯æŒ | DeepSeek R1 ä¸æ”¯æŒæ­¤å‚æ•° |
| frequency_penalty | ä¸æ”¯æŒ | DeepSeek R1 ä¸æ”¯æŒæ­¤å‚æ•° |

### æ¨ç†æ¨¡å¼å»ºè®®

1. **é¿å…ç³»ç»Ÿæç¤º**: æ‰€æœ‰æŒ‡ä»¤åº”åŒ…å«åœ¨ç”¨æˆ·æç¤ºä¸­
2. **æ•°å­¦é—®é¢˜**: å»ºè®®æ·»åŠ  "è¯·é€æ­¥æ¨ç†ï¼Œå¹¶å°†æœ€ç»ˆç­”æ¡ˆæ”¾åœ¨ \\boxed{} ä¸­"
3. **å¼ºåˆ¶æ¨ç†**: å»ºè®®è®©æ¨¡å‹ä»¥ "<think>\\n" å¼€å§‹å“åº”
4. **å¤šæ¬¡æµ‹è¯•**: æ¨èè¿›è¡Œå¤šæ¬¡æµ‹è¯•å¹¶å¹³å‡ç»“æœ

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. æ¨¡å‹é™åˆ¶
- ä¸æ”¯æŒæŸäº›ä¼ ç»Ÿå‚æ•°ï¼ˆtop_pã€presence_penaltyç­‰ï¼‰
- æ¨ç†å†…å®¹ä¸è®¡å…¥64Kä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
- å¤šè½®å¯¹è¯æ—¶éœ€è¦ç§»é™¤ `reasoning_content` å­—æ®µ

### 2. æ€§èƒ½è€ƒè™‘
- æ¨ç†è¿‡ç¨‹ä¼šå¢åŠ å“åº”æ—¶é—´
- æµå¼è¾“å‡ºå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒ
- å»ºè®®åˆç†è®¾ç½® max_tokens é™åˆ¶

### 3. å…¼å®¹æ€§
- è‡ªåŠ¨æ£€æµ‹LLMæ˜¯å¦æ”¯æŒæ¨ç†åŠŸèƒ½
- ä¸æ”¯æŒæ¨ç†æ—¶è‡ªåŠ¨å›é€€åˆ°æ ‡å‡†ç”Ÿæˆ
- ä¿æŒä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### æ¨ç†ç»“æœå…ƒæ•°æ®

```python
result = await llm.think(messages)
metadata = result.metadata

print(f"æ¨¡å‹: {metadata['model']}")
print(f"æœ‰æ¨ç†è¿‡ç¨‹: {metadata['has_reasoning']}")
print(f"æ¨ç†é•¿åº¦: {metadata['reasoning_length']} å­—ç¬¦")
print(f"ç­”æ¡ˆé•¿åº¦: {metadata['content_length']} å­—ç¬¦")
print(f"å®ŒæˆåŸå› : {metadata['finish_reason']}")
```

### æµå¼è¾“å‡ºç»Ÿè®¡

```python
reasoning_chars = 0
content_chars = 0

async for chunk_data in llm.stream_think(messages):
    if chunk_data["type"] == "reasoning_chunk":
        reasoning_chars += len(chunk_data["content"])
    elif chunk_data["type"] == "content_chunk":
        content_chars += len(chunk_data["content"])
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

å¦‚éœ€æ‰©å±•æ¨ç†åŠŸèƒ½ï¼š

1. **æ–°å¢æ¨ç†æ¨¡å¼**: åœ¨ `DoubaoLLM` ä¸­æ·»åŠ æ–°çš„æ¨ç†æ–¹æ³•
2. **ä¼˜åŒ–æç¤ºè¯**: åœ¨ `_build_system_prompt` ä¸­æ”¹è¿›æ¨ç†æŒ‡å¯¼
3. **å¢å¼ºå±•ç¤º**: åœ¨ `StreamReactAgentNode` ä¸­ä¼˜åŒ–æ¨ç†è¿‡ç¨‹å±•ç¤º
4. **æ·»åŠ æµ‹è¯•**: åœ¨æµ‹è¯•è„šæœ¬ä¸­å¢åŠ æ–°çš„æµ‹è¯•ç”¨ä¾‹

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚é‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼š

1. æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
2. æŸ¥çœ‹é”™è¯¯æ—¥å¿—å’Œå †æ ˆè·Ÿè¸ª
3. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½
4. æäº¤ Issue æˆ– Pull Request

---

**æ³¨æ„**: æœ¬é›†æˆåŸºäº DeepSeek R1 API æ–‡æ¡£å®ç°ï¼Œæ”¯æŒæœ€æ–°çš„æ¨ç†åŠŸèƒ½ç‰¹æ€§ã€‚ä½¿ç”¨å‰è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®ç›¸å…³ç¯å¢ƒå˜é‡å’ŒAPIè®¿é—®æƒé™ã€‚ 
"""
å¢å¼ºç‰ˆStateGraphæ¼”ç¤º - å±•ç¤ºæ‰€æœ‰æ–°åŠŸèƒ½
"""
import asyncio
import uuid
from datetime import datetime
from typing import Dict, Any

# å¯¼å…¥å¢å¼ºç‰ˆæ¨¡å—
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from core.graph import StateGraph, StateGraphExecutor, Command
from core.base import BaseNode
from core.types import NodeType, Message, MessageRole
from core.executor import (
    StateManager, add_reducer, priority_reducer, timestamp_reducer,
    CheckpointStorage
)
from core.error_handling import (
    ErrorHandler, RetryPolicy, CircuitBreakerConfig,
    ErrorAction, ErrorContext
)
from core.compiler import GraphCompiler, OptimizationLevel
from core.monitoring import (
    ExecutionMonitor, TraceContext, monitor_node,
    FileExporter, ConsoleExporter
)
from core.visualization import (
    GraphVisualizer, VisualizationConfig, VisualizationFormat
)

class DemoThinkNode(BaseNode):
    """æ¼”ç¤ºæ€è€ƒèŠ‚ç‚¹"""
    
    def __init__(self, name: str):
        super().__init__(name, NodeType.THINK, "åˆ†æé—®é¢˜å¹¶åˆ¶å®šç­–ç•¥")
    
    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ€è€ƒé€»è¾‘"""
        query = state.get("query", "")
        
        # æ¨¡æ‹Ÿæ€è€ƒè¿‡ç¨‹
        await asyncio.sleep(0.5)
        
        thought = f"åˆ†æé—®é¢˜: {query}. éœ€è¦æœç´¢å’Œå¤„ç†ä¿¡æ¯ã€‚"
        
        return {
            "thought": thought,
            "next_action": "search",
            "confidence": 0.8,
            "messages": [Message(
                role=MessageRole.ASSISTANT,
                content=f"ğŸ’­ æ€è€ƒ: {thought}"
            )]
        }

class DemoActionNode(BaseNode):
    """æ¼”ç¤ºè¡ŒåŠ¨èŠ‚ç‚¹"""
    
    def __init__(self, name: str):
        super().__init__(name, NodeType.ACT, "æ‰§è¡Œå…·ä½“è¡ŒåŠ¨")
    
    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè¡ŒåŠ¨é€»è¾‘"""
        action = state.get("next_action", "search")
        
        # æ¨¡æ‹Ÿè¡ŒåŠ¨è¿‡ç¨‹
        await asyncio.sleep(0.3)
        
        if action == "search":
            result = "æ‰¾åˆ°ç›¸å…³ä¿¡æ¯: AIæŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œåº”ç”¨å¹¿æ³›ã€‚"
        else:
            result = "æ‰§è¡Œäº†å…¶ä»–è¡ŒåŠ¨"
        
        return {
            "action_result": result,
            "status": "completed",
            "messages": [Message(
                role=MessageRole.ASSISTANT,
                content=f"ğŸ” è¡ŒåŠ¨: {result}"
            )]
        }

class DemoRouterNode(BaseNode):
    """æ¼”ç¤ºè·¯ç”±èŠ‚ç‚¹"""
    
    def __init__(self, name: str):
        super().__init__(name, NodeType.ROUTER, "å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨")
    
    async def execute(self, state: Dict[str, Any]) -> Command:
        """æ‰§è¡Œè·¯ç”±é€»è¾‘"""
        confidence = state.get("confidence", 0.5)
        iteration = state.get("iteration", 0)
        
        # è·¯ç”±å†³ç­–
        if confidence > 0.9 or iteration > 2:
            next_node = "finalize"
        elif confidence < 0.5:
            next_node = "think"
        else:
            next_node = "act"
        
        return Command(
            update={
                "iteration": iteration + 1,
                "router_decision": f"ç½®ä¿¡åº¦ {confidence:.2f}, è·¯ç”±åˆ° {next_node}"
            },
            goto=next_node
        )

class DemoFinalizeNode(BaseNode):
    """æ¼”ç¤ºæœ€ç»ˆåŒ–èŠ‚ç‚¹"""
    
    def __init__(self, name: str):
        super().__init__(name, NodeType.FINALIZE, "ç”Ÿæˆæœ€ç»ˆå›ç­”")
    
    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆå›ç­”"""
        thought = state.get("thought", "")
        action_result = state.get("action_result", "")
        
        final_answer = f"""
åŸºäºåˆ†æå’Œæœç´¢ï¼Œæˆ‘çš„å›ç­”æ˜¯ï¼š

æ€è€ƒè¿‡ç¨‹: {thought}
æœç´¢ç»“æœ: {action_result}

æ€»ç»“: è¿™æ˜¯ä¸€ä¸ªç»¼åˆè€ƒè™‘å¤šç§å› ç´ åå¾—å‡ºçš„ç­”æ¡ˆã€‚
        """.strip()
        
        return {
            "final_answer": final_answer,
            "completed": True,
            "messages": [Message(
                role=MessageRole.ASSISTANT,
                content=f"âœ… æœ€ç»ˆå›ç­”: {final_answer}"
            )]
        }

async def demonstrate_enhanced_stategraph():
    """æ¼”ç¤ºå¢å¼ºç‰ˆStateGraphçš„æ‰€æœ‰åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆStateGraphæ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆ›å»ºå¢å¼ºç‰ˆStateGraph
    print("\nğŸ“Š 1. åˆ›å»ºå¢å¼ºç‰ˆStateGraph")
    graph = StateGraph(name="enhanced_demo_graph")
    
    # æ·»åŠ èŠ‚ç‚¹
    think_node = DemoThinkNode("think")
    act_node = DemoActionNode("act") 
    router_node = DemoRouterNode("router")
    finalize_node = DemoFinalizeNode("finalize")
    
    graph.add_node("think", think_node)
    graph.add_node("act", act_node)
    graph.add_node("router", router_node)
    graph.add_node("finalize", finalize_node)
    
    # æ·»åŠ è¾¹
    graph.add_edge("think", "router")
    graph.add_edge("act", "router")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    def route_condition(state: Dict[str, Any]) -> str:
        """è·¯ç”±æ¡ä»¶å‡½æ•°"""
        # è¿™é‡ŒrouterèŠ‚ç‚¹ä¼šé€šè¿‡Commandæ§åˆ¶è·¯ç”±
        return "router"
    
    graph.add_conditional_edges("router", route_condition, {
        "think": "think",
        "act": "act", 
        "finalize": "finalize"
    })
    
    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("think")
    
    print(f"âœ… åˆ›å»ºäº†åŒ…å« {len(graph.nodes)} ä¸ªèŠ‚ç‚¹çš„å›¾")
    
    # 2. å›¾ç¼–è¯‘å’Œä¼˜åŒ–
    print("\nğŸ”§ 2. å›¾ç¼–è¯‘å’Œä¼˜åŒ–")
    from core.compiler import global_compiler
    
    compiler = GraphCompiler(
        optimization_level=OptimizationLevel.BASIC,
        enable_validation=True,
        enable_optimization=True
    )
    
    compilation_result = compiler.compile(graph)
    
    print(f"âœ… ç¼–è¯‘ç»“æœ: {'æˆåŠŸ' if compilation_result.validation_result.is_valid else 'å¤±è´¥'}")
    print(f"   ç¼–è¯‘æ—¶é—´: {compilation_result.compilation_time:.3f}s")
    
    if compilation_result.validation_result.warnings:
        print(f"   è­¦å‘Š: {compilation_result.validation_result.warnings}")
    
    if compilation_result.validation_result.suggestions:
        print(f"   å»ºè®®: {compilation_result.validation_result.suggestions}")
    
    # 3. é”™è¯¯å¤„ç†é…ç½®
    print("\nğŸ›¡ï¸ 3. é…ç½®é”™è¯¯å¤„ç†")
    
    error_handler = ErrorHandler()
    
    # ä¸ºthinkèŠ‚ç‚¹æ·»åŠ é‡è¯•ç­–ç•¥
    error_handler.add_retry_policy("think", RetryPolicy(
        max_retries=2,
        initial_delay=0.1,
        backoff_multiplier=2.0
    ))
    
    # ä¸ºactèŠ‚ç‚¹æ·»åŠ æ–­è·¯å™¨
    error_handler.add_circuit_breaker("act", CircuitBreakerConfig(
        failure_threshold=3,
        timeout=10.0
    ))
    
    # æ·»åŠ è‡ªå®šä¹‰é”™è¯¯å¤„ç†å™¨
    def handle_think_error(context: ErrorContext) -> ErrorAction:
        print(f"âš ï¸ å¤„ç†thinkèŠ‚ç‚¹é”™è¯¯: {context.error}")
        return ErrorAction.RETRY if context.attempt < 2 else ErrorAction.SKIP
    
    error_handler.add_error_handler(ValueError, handle_think_error)
    
    print("âœ… é”™è¯¯å¤„ç†é…ç½®å®Œæˆ")
    
    # 4. ç›‘æ§é…ç½®
    print("\nğŸ“ˆ 4. é…ç½®æ‰§è¡Œç›‘æ§")
    
    monitor = ExecutionMonitor(
        enable_metrics=True,
        enable_tracing=True,
        export_interval=30
    )
    
    # æ·»åŠ å¯¼å‡ºå™¨
    monitor.add_exporter(FileExporter("./workspace/monitoring"))
    monitor.add_exporter(ConsoleExporter())
    
    # æ·»åŠ äº‹ä»¶å›è°ƒ
    def log_important_events(event):
        if event.event_type.value in ["node_error", "graph_complete"]:
            print(f"ğŸ“ é‡è¦äº‹ä»¶: {event.event_type.value} - {event.node_name}")
    
    monitor.add_event_callback(log_important_events)
    
    await monitor.start()
    print("âœ… ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
    
    # 5. æ‰§è¡Œé…ç½®
    print("\nâš™ï¸ 5. é…ç½®å¢å¼ºç‰ˆæ‰§è¡Œå™¨")
    
    executor = StateGraphExecutor(
        max_iterations=10,
        enable_parallel=True,
        max_concurrent_nodes=3,
        enable_error_handling=True,
        enable_state_locking=True
    )
    
    # è®¾ç½®é”™è¯¯å¤„ç†å™¨
    executor.error_handler = error_handler
    
    print("âœ… æ‰§è¡Œå™¨é…ç½®å®Œæˆ")
    
    # 6. çŠ¶æ€ç®¡ç†é…ç½®
    print("\nğŸ—„ï¸ 6. é…ç½®å¢å¼ºç‰ˆçŠ¶æ€ç®¡ç†")
    
    # ä½¿ç”¨é«˜çº§çŠ¶æ€åˆå¹¶å™¨
    state_manager = StateManager(
        reducers={
            "messages": add_reducer,
            "priority_data": priority_reducer,
            "timestamped_data": timestamp_reducer
        },
        enable_versioning=True,
        enable_checkpoints=True,
        checkpoint_storage=CheckpointStorage.FILE,
        checkpoint_path="./workspace/checkpoints"
    )
    
    print("âœ… çŠ¶æ€ç®¡ç†é…ç½®å®Œæˆ")
    
    # 7. æ‰§è¡Œæ¼”ç¤º
    print("\nğŸƒ 7. æ‰§è¡Œå¢å¼ºç‰ˆStateGraph")
    
    # åˆ›å»ºæ‰§è¡Œè½¨è¿¹
    trace_id = str(uuid.uuid4())
    
    async with TraceContext(trace_id, graph.name, monitor):
        # åˆå§‹çŠ¶æ€
        initial_state = {
            "query": "AIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
            "iteration": 0,
            "confidence": 0.6,
            "messages": [Message(
                role=MessageRole.USER,
                content="AIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
            )]
        }
        
        # æ‰§è¡Œé…ç½®
        execution_config = {
            "enable_checkpoints": True,
            "enable_versioning": True,
            "checkpoint_storage": CheckpointStorage.FILE
        }
        
        print(f"ğŸ¯ å¼€å§‹æ‰§è¡Œ (è½¨è¿¹ID: {trace_id[:8]}...)")
        
        try:
            final_state = await executor.execute(
                graph=compilation_result.optimized_graph or graph,
                initial_state=initial_state,
                config=execution_config
            )
            
            print("\nâœ… æ‰§è¡ŒæˆåŠŸå®Œæˆ!")
            print(f"ğŸ”„ æ€»è¿­ä»£æ¬¡æ•°: {final_state.get('_execution_metadata', {}).get('total_iterations', 'N/A')}")
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {final_state.get('_execution_metadata', {}).get('execution_time', 'N/A'):.2f}s")
            print(f"ğŸ“ è®¿é—®èŠ‚ç‚¹: {final_state.get('_execution_metadata', {}).get('visited_nodes', [])}")
            
            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
            if "final_answer" in final_state:
                print(f"\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:\n{final_state['final_answer']}")
            
            # æ˜¾ç¤ºæ¶ˆæ¯å†å²
            messages = final_state.get("messages", [])
            print(f"\nğŸ’¬ æ¶ˆæ¯å†å² ({len(messages)} æ¡):")
            for i, msg in enumerate(messages[-3:], 1):  # æ˜¾ç¤ºæœ€å3æ¡
                print(f"   {i}. [{msg.role.value}] {msg.content}")
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
    
    # 8. å¯è§†åŒ–æ¼”ç¤º
    print("\nğŸ¨ 8. ç”Ÿæˆå¯è§†åŒ–")
    
    from core.visualization import global_visualizer
    
    # è·å–æ‰§è¡Œè½¨è¿¹
    trace = monitor.get_trace(trace_id)
    
    # ç”Ÿæˆå¤šç§æ ¼å¼çš„å¯è§†åŒ–
    formats = [
        (VisualizationFormat.MERMAID, "mermaid"),
        (VisualizationFormat.HTML, "html")
    ]
    
    for viz_format, file_ext in formats:
        try:
            config = VisualizationConfig(
                format=viz_format,
                include_metadata=True,
                include_performance=True,
                theme="default",
                width=1000,
                height=600
            )
            
            visualization = global_visualizer.visualize_graph(
                graph, config, trace
            )
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            output_path = f"./workspace/visualizations/enhanced_demo.{file_ext}"
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(visualization)
            
            print(f"âœ… {viz_format.value} å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆ {viz_format.value} å¯è§†åŒ–å¤±è´¥: {e}")
    
    # 9. ç›‘æ§æ•°æ®å±•ç¤º
    print("\nğŸ“Š 9. ç›‘æ§æ•°æ®æ‘˜è¦")
    
    # è·å–ç›‘æ§æ‘˜è¦
    metrics_summary = monitor.get_metrics_summary()
    
    print(f"   æ´»è·ƒè½¨è¿¹: {metrics_summary.get('active_traces', 0)}")
    print(f"   å†å²è½¨è¿¹: {metrics_summary.get('total_traces', 0)}")
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    metrics = metrics_summary.get('metrics', {})
    for metric_name, metric_data in metrics.items():
        if 'duration' in metric_name and 'avg' in metric_data:
            print(f"   {metric_name}: å¹³å‡ {metric_data['avg']:.2f}s")
    
    # 10. æ¸…ç†
    print("\nğŸ§¹ 10. æ¸…ç†èµ„æº")
    
    await monitor.stop()
    error_handler.reset_error_stats()
    
    print("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å¢å¼ºç‰ˆStateGraphæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“š æ–°åŠŸèƒ½æ€»ç»“:")
    print("   âœ“ æŒä¹…åŒ–æ£€æŸ¥ç‚¹å’ŒçŠ¶æ€ç‰ˆæœ¬æ§åˆ¶")
    print("   âœ“ é«˜çº§çŠ¶æ€åˆå¹¶å™¨ (priority, timestamp)")
    print("   âœ“ çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œå’ŒçŠ¶æ€åŒæ­¥")
    print("   âœ“ åˆ†çº§é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
    print("   âœ“ å›¾ç¼–è¯‘ä¼˜åŒ–å’ŒéªŒè¯")
    print("   âœ“ æ‰§è¡Œç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡")
    print("   âœ“ å¤šæ ¼å¼å¯è§†åŒ–æ”¯æŒ")
    print("   âœ“ äº¤äº’å¼HTMLå¯è§†åŒ–")

async def demonstrate_advanced_features():
    """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
    print("\nğŸ”¬ æ¼”ç¤ºé«˜çº§åŠŸèƒ½")
    print("-" * 40)
    
    # 1. çŠ¶æ€åˆå¹¶å™¨æ¼”ç¤º
    print("\n1. é«˜çº§çŠ¶æ€åˆå¹¶å™¨æ¼”ç¤º")
    
    from core.executor import priority_reducer, timestamp_reducer, strategy_reducer
    
    # priority_reduceræ¼”ç¤º
    old_data = {
        "task1": {"priority": 1, "data": "ä½ä¼˜å…ˆçº§ä»»åŠ¡"},
        "task2": {"priority": 5, "data": "ä¸­ä¼˜å…ˆçº§ä»»åŠ¡"}
    }
    new_data = {
        "task1": {"priority": 8, "data": "é«˜ä¼˜å…ˆçº§ä»»åŠ¡"},
        "task3": {"priority": 3, "data": "æ–°ä»»åŠ¡"}
    }
    
    merged = priority_reducer(old_data, new_data)
    print(f"   ä¼˜å…ˆçº§åˆå¹¶ç»“æœ: {merged}")
    
    # timestamp_reduceræ¼”ç¤º
    old_time_data = {
        "event1": {"timestamp": datetime(2024, 1, 1), "data": "æ—§äº‹ä»¶"},
        "event2": {"timestamp": datetime(2024, 1, 2), "data": "è¾ƒæ–°äº‹ä»¶"}
    }
    new_time_data = {
        "event1": {"timestamp": datetime(2024, 1, 3), "data": "æœ€æ–°äº‹ä»¶"},
        "event3": {"timestamp": datetime(2024, 1, 1), "data": "å¦ä¸€ä¸ªäº‹ä»¶"}
    }
    
    time_merged = timestamp_reducer(old_time_data, new_time_data)
    print(f"   æ—¶é—´æˆ³åˆå¹¶ç»“æœ: {list(time_merged.keys())}")
    
    # 2. æ–­è·¯å™¨æ¼”ç¤º
    print("\n2. æ–­è·¯å™¨æœºåˆ¶æ¼”ç¤º")
    
    from core.error_handling import CircuitBreaker, CircuitBreakerConfig
    
    breaker = CircuitBreaker(CircuitBreakerConfig(
        failure_threshold=2,
        timeout=1.0
    ))
    
    async def unreliable_function():
        """ä¸å¯é çš„å‡½æ•°"""
        import random
        if random.random() < 0.7:  # 70%å¤±è´¥ç‡
            raise Exception("æ¨¡æ‹Ÿå¤±è´¥")
        return "æˆåŠŸ"
    
    # æµ‹è¯•æ–­è·¯å™¨
    for i in range(5):
        try:
            result = await breaker.call(unreliable_function)
            print(f"   è°ƒç”¨ {i+1}: {result}")
        except Exception as e:
            print(f"   è°ƒç”¨ {i+1}: å¤±è´¥ - {e}")
    
    # 3. æ£€æŸ¥ç‚¹ç³»ç»Ÿæ¼”ç¤º
    print("\n3. æ£€æŸ¥ç‚¹ç³»ç»Ÿæ¼”ç¤º")
    
    from core.executor import CheckpointManager, CheckpointStorage
    
    checkpoint_mgr = CheckpointManager(
        storage_type=CheckpointStorage.MEMORY,
        max_checkpoints=5
    )
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹
    test_state = {"step": 1, "data": "æµ‹è¯•æ•°æ®", "counter": 100}
    cp_id = checkpoint_mgr.save_checkpoint(test_state, "test_node")
    print(f"   åˆ›å»ºæ£€æŸ¥ç‚¹: {cp_id}")
    
    # ä¿®æ”¹çŠ¶æ€
    test_state["step"] = 2
    test_state["counter"] = 200
    
    # æ¢å¤æ£€æŸ¥ç‚¹
    restored_state = checkpoint_mgr.load_checkpoint(cp_id)
    print(f"   æ¢å¤çŠ¶æ€: step={restored_state.get('step')}, counter={restored_state.get('counter')}")
    
    print("\nâœ… é«˜çº§åŠŸèƒ½æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("./workspace/monitoring", exist_ok=True)
    os.makedirs("./workspace/checkpoints", exist_ok=True)
    os.makedirs("./workspace/visualizations", exist_ok=True)
    
    # è¿è¡Œä¸»æ¼”ç¤º
    asyncio.run(demonstrate_enhanced_stategraph())
    
    # è¿è¡Œé«˜çº§åŠŸèƒ½æ¼”ç¤º
    asyncio.run(demonstrate_advanced_features())
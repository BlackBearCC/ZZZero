"""
ReAct Agent - åŸºäºReasoning and ActingèŒƒå¼çš„æ™ºèƒ½ä»£ç†
"""
import uuid
from typing import Dict, Any, Optional, List, AsyncIterator, Union
from datetime import datetime

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.base import BaseAgent, BaseNode, Command
from core.types import AgentType, TaskResult, Message, MessageRole, NodeType
from core.graph import StateGraph, GraphBuilder, StateGraphExecutor
from core.memory import MemoryManager, SQLiteMemoryStore
  
from llm.base import BaseLLMProvider
from tools.base import ToolManager

# æ·»åŠ MCPToolManagerçš„å¯¼å…¥ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from tools.mcp_tools import MCPToolManager

import json
import asyncio
import time


class ReactAgent(BaseAgent):
    """ReActæ™ºèƒ½ä»£ç† - å¾ªç¯è¿›è¡Œæ¨ç†å’Œè¡ŒåŠ¨"""
    
    # ==================== å†…ç½®èŠ‚ç‚¹ç±» ====================
    
    class ThoughtNode(BaseNode):
        """æ€è€ƒèŠ‚ç‚¹ - åˆ†æé—®é¢˜å¹¶åˆ¶å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’"""
        
        def __init__(self, name: str, llm: BaseLLMProvider, use_think_mode: bool = True, **kwargs):
            super().__init__(name, NodeType.THINK, "æ€è€ƒåˆ†æèŠ‚ç‚¹", llm=llm, **kwargs)
            self.use_think_mode = use_think_mode
            
        async def execute(self, state: Dict[str, Any]) -> Union[Dict[str, Any], Command]:
            """æ‰§è¡Œæ€è€ƒåˆ†æ"""
            messages = self.get_messages(state)
            available_tools = state.get("available_tools", [])
            memory_context = state.get("memory_context", "")
            
            thought_count = state.get("thought_count", 0) + 1
            
            print(f"[ThoughtNode] å¼€å§‹æ€è€ƒï¼Œè¿­ä»£: {thought_count}")
            print(f"[ThoughtNode] æ¶ˆæ¯æ•°é‡: {len(messages)}")
            print(f"[ThoughtNode] å¯ç”¨å·¥å…·: {available_tools}")
            print(f"[ThoughtNode] ä½¿ç”¨Thinkæ¨¡å¼: {self.use_think_mode}")
            
            # ä½¿ç”¨é›†æˆçš„build_promptæ–¹æ³•
            system_prompt = self.build_prompt("thought", 
                                             query=messages[-1].content if messages else "",
                                             tools=", ".join(available_tools) if available_tools else "æ— ",
                                             context=memory_context)
            
            print(f"[ThoughtNode] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}")
            
            try:
                reasoning_content = ""
                
                # æ ¹æ®é…ç½®é€‰æ‹©è°ƒç”¨æ–¹å¼
                mode = "think" if self.use_think_mode else "normal"
                print(f"[ThoughtNode] ä½¿ç”¨æ¨¡å¼: {mode}")
                
                response = await self.generate(messages, system_prompt=system_prompt, mode=mode)
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¨ç†è¿‡ç¨‹
                reasoning_content = ""
                if hasattr(response, 'metadata') and response.metadata.get("reasoning_content"):
                    reasoning_content = response.metadata["reasoning_content"]
                    print(f"[ThoughtNode] æ¨ç†è¿‡ç¨‹é•¿åº¦: {len(reasoning_content)}")
                    print(f"[ThoughtNode] æ¨ç†è¿‡ç¨‹é¢„è§ˆ: {reasoning_content[:200]}...")
                
                print(f"[ThoughtNode] å“åº”é•¿åº¦: {len(response_text)}")
                print(f"[ThoughtNode] æœ‰æ¨ç†è¿‡ç¨‹: {bool(reasoning_content)}")
                
                print(f"[ThoughtNode] LLMå“åº”é¢„è§ˆ: {response_text[:300]}...")
                
                # ä½¿ç”¨é›†æˆçš„parseæ–¹æ³•
                thought_analysis = self.parse(response_text, format_type="structured")
                
                # å¤„ç†è§£æç»“æœ
                analysis_text = thought_analysis.get("åˆ†æ", thought_analysis.get("analysis", response_text))
                strategy_text = thought_analysis.get("ç­–ç•¥", thought_analysis.get("strategy", ""))
                tools_text = thought_analysis.get("å·¥å…·éœ€æ±‚", thought_analysis.get("tools", ""))
                confidence_text = thought_analysis.get("ä¿¡å¿ƒè¯„ä¼°", thought_analysis.get("confidence", "5"))
                
                # åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
                needs_tools = ("éœ€è¦" in tools_text or "ä½¿ç”¨" in tools_text) and available_tools
                
                # æå–ä¿¡å¿ƒåˆ†æ•°
                try:
                    confidence = int(''.join(filter(str.isdigit, str(confidence_text))))
                    confidence = max(1, min(10, confidence))
                except (ValueError, TypeError):
                    confidence = 5
                
                print(f"[ThoughtNode] åˆ†æç»“æœ - éœ€è¦å·¥å…·: {needs_tools}, ç½®ä¿¡åº¦: {confidence}")
                
                # åˆ›å»ºæ€è€ƒæ¶ˆæ¯
                thought_content = f"ğŸ’­ æ€è€ƒ {thought_count}:\n\n"
                
                # å¦‚æœæœ‰æ¨ç†è¿‡ç¨‹ï¼Œå…ˆæ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
                if reasoning_content:
                    thought_content += f"**ğŸ§  æ¨ç†è¿‡ç¨‹ï¼š**\n{reasoning_content}\n\n"
                
                thought_content += f"**åˆ†æ**: {analysis_text}"
                if strategy_text:
                    thought_content += f"\n\n**ç­–ç•¥**: {strategy_text}"
                if tools_text:
                    thought_content += f"\n\n**å·¥å…·éœ€æ±‚**: {tools_text}"
                thought_content += f"\n\n**ä¿¡å¿ƒè¯„ä¼°**: {confidence}/10"
                
                thought_message = self.create_ai_message(thought_content)
                thought_message.metadata = {
                    "node_type": "thought",
                    "thought_count": thought_count,
                    "needs_tools": needs_tools,
                    "confidence": confidence,
                    "has_reasoning": bool(reasoning_content),
                    "reasoning_length": len(reasoning_content) if reasoning_content else 0
                }
                
                # åˆ›å»ºçŠ¶æ€æ›´æ–°
                state_update = {
                    "messages": [thought_message],
                    "thought_count": thought_count,
                    "last_thought": analysis_text,
                    "reasoning_content": reasoning_content,
                    "needs_tools": needs_tools,
                    "confidence": confidence
                }
                
                # å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
                next_node = "action" if needs_tools else "final_answer"
                print(f"[ThoughtNode] å†³å®šè·³è½¬åˆ°: {next_node}")
                
                return Command(update=state_update, goto=next_node)
                    
            except Exception as e:
                error_msg = str(e)
                print(f"[ThoughtNode] LLMè°ƒç”¨å¤±è´¥: {error_msg}")
                import traceback
                print(f"[ThoughtNode] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                
                error_message = self.create_ai_message(
                    f"æ€è€ƒè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜: {error_msg}ï¼Œæˆ‘å°†åŸºäºç°æœ‰ä¿¡æ¯å°½åŠ›å›ç­”ã€‚"
                )
                
                return Command(
                    update={"messages": [error_message], "has_error": True},
                    goto="final_answer"
                )
    
    class ActionNode(BaseNode):
        """è¡ŒåŠ¨èŠ‚ç‚¹ - æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶æ”¶é›†ç»“æœ"""
        
        def __init__(self, name: str, llm: BaseLLMProvider, tool_manager=None, **kwargs):
            super().__init__(name, NodeType.ACT, "å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹", llm=llm, **kwargs)
            self.tool_manager = tool_manager
            
        async def execute(self, state: Dict[str, Any]) -> Union[Dict[str, Any], Command]:
            """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
            messages = self.get_messages(state)
            available_tools = state.get("available_tools", [])
            
            if not self.tool_manager or not available_tools:
                error_message = self.create_ai_message("æ²¡æœ‰å¯ç”¨çš„å·¥å…·ç®¡ç†å™¨æˆ–å·¥å…·")
                return Command(
                    update={"messages": [error_message], "error": "No tools available"},
                    goto="final_answer"
                )
            
            # æ„å»ºå·¥å…·é€‰æ‹©æç¤ºè¯
            tools_desc = self.tool_manager.get_tools_description() if self.tool_manager else ""
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®å‰é¢çš„æ€è€ƒåˆ†æé€‰æ‹©åˆé€‚çš„å·¥å…·æ¥è§£å†³é—®é¢˜ã€‚

å¯ç”¨å·¥å…·ï¼š
{tools_desc}

è¯·æ ¹æ®å‰é¢çš„åˆ†æï¼Œé€‰æ‹©éœ€è¦æ‰§è¡Œçš„å·¥å…·ã€‚å›å¤æ ¼å¼ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
```json
{{
    "actions": [
        {{
            "tool_name": "å·¥å…·åç§°",
            "parameters": {{
                "å‚æ•°å": "å‚æ•°å€¼"
            }},
            "reason": "ä½¿ç”¨æ­¤å·¥å…·çš„åŸå› "
        }}
    ]
}}
```

æ³¨æ„ï¼šå·¥å…·åå¿…é¡»æ˜¯å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­çš„ä¸€ä¸ªï¼š{', '.join(available_tools)}"""
            
            try:
                # ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’
                response = await self.generate(messages, system_prompt=system_prompt)
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # è§£æå·¥å…·è°ƒç”¨
                planned_actions = self._parse_action_response(response_text, available_tools)
                
                if not planned_actions:
                    error_message = self.create_ai_message("æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨")
                    return Command(
                        update={"messages": [error_message], "error": "No valid actions parsed"},
                        goto="observation"
                    )
                
                # å¹¶è¡Œæ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = await self._execute_tools_parallel(planned_actions)
                
                # åˆ›å»ºè¡ŒåŠ¨æ¶ˆæ¯
                action_content = self._format_action_summary(planned_actions, tool_results)
                action_message = self.create_ai_message(action_content)
                action_message.metadata = {
                    "node_type": "action",
                    "actions_executed": len(planned_actions),
                    "tool_results": tool_results
                }
                
                return Command(
                    update={
                        "messages": [action_message],
                        "planned_actions": planned_actions,
                        "tool_results": tool_results,
                        "actions_executed": len(planned_actions)
                    },
                    goto="observation"
                )
                
            except Exception as e:
                error_msg = str(e)
                print(f"[ActionNode] æ‰§è¡Œå¤±è´¥: {error_msg}")
                
                error_message = self.create_ai_message(f"è¡ŒåŠ¨èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {error_msg}")
                return Command(
                    update={"messages": [error_message], "error": error_msg},
                    goto="final_answer" if "InvalidEndpointOrModel" in error_msg else "observation"
                )
        
        def _parse_action_response(self, response: str, available_tools: List[str]) -> List[Dict[str, Any]]:
            """è§£æå·¥å…·è°ƒç”¨å“åº”"""
            try:
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_str = response.strip()
                
                data = json.loads(json_str)
                actions = data.get("actions", [])
                
                valid_actions = []
                for action in actions:
                    tool_name = action.get("tool_name", "")
                    if tool_name in available_tools:
                        valid_actions.append({
                            "tool_name": tool_name,
                            "parameters": action.get("parameters", {}),
                            "reason": action.get("reason", "")
                        })
                
                return valid_actions
                
            except Exception as e:
                print(f"è§£æå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                return []
        
        async def _execute_tools_parallel(self, planned_actions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
            """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨"""
            if not planned_actions:
                return []
            
            tasks = []
            for i, action in enumerate(planned_actions):
                task = self._execute_single_tool(action, i)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            tool_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    tool_results.append({
                        "action_index": i,
                        "tool_name": planned_actions[i]["tool_name"],
                        "success": False,
                        "result": f"æ‰§è¡Œå¤±è´¥: {str(result)}",
                        "error": str(result),
                        "execution_time": 0
                    })
                else:
                    tool_results.append(result)
            
            return tool_results
        
        async def _execute_single_tool(self, action: Dict[str, Any], action_index: int) -> Dict[str, Any]:
            """æ‰§è¡Œå•ä¸ªå·¥å…·"""
            start_time = time.time()
            
            tool_name = action["tool_name"]
            parameters = action["parameters"]
            
            try:
                result = await self.tool_manager.execute_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                return {
                    "action_index": action_index,
                    "tool_name": tool_name,
                    "parameters": parameters,
                    "success": True,
                    "result": result,
                    "execution_time": execution_time,
                    "reason": action.get("reason", "")
                }
                
            except Exception as e:
                execution_time = time.time() - start_time
                return {
                    "action_index": action_index,
                    "tool_name": tool_name,
                    "parameters": parameters,
                    "success": False,
                    "result": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}",
                    "error": str(e),
                    "execution_time": execution_time,
                    "reason": action.get("reason", "")
                }
        
        def _format_action_summary(self, planned_actions: List[Dict[str, Any]], tool_results: List[Dict[str, Any]]) -> str:
            """æ ¼å¼åŒ–è¡ŒåŠ¨æ‘˜è¦"""
            if not planned_actions:
                return "è¡ŒåŠ¨ï¼šæœªæ‰§è¡Œä»»ä½•å·¥å…·"
            
            summary_parts = [f"è¡ŒåŠ¨ï¼šæ‰§è¡Œäº† {len(planned_actions)} ä¸ªå·¥å…·"]
            
            for i, action in enumerate(planned_actions):
                tool_name = action["tool_name"]
                reason = action.get("reason", "")
                
                result_info = next((r for r in tool_results if r["action_index"] == i), None)
                if result_info:
                    status = "âœ… æˆåŠŸ" if result_info["success"] else "âŒ å¤±è´¥"
                    summary_parts.append(f"{i+1}. {tool_name} - {status}")
                    if reason:
                        summary_parts.append(f"   åŸå› ï¼š{reason}")
                else:
                    summary_parts.append(f"{i+1}. {tool_name} - â³ æ‰§è¡Œä¸­")
            
            return "\n".join(summary_parts)
    
    class ObservationNode(BaseNode):
        """è§‚å¯ŸèŠ‚ç‚¹ - åˆ†æå·¥å…·æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        
        def __init__(self, name: str, llm: BaseLLMProvider, max_iterations: int = 5, **kwargs):
            super().__init__(name, NodeType.OBSERVE, "ç»“æœè§‚å¯Ÿåˆ†æèŠ‚ç‚¹", llm=llm, **kwargs)
            self.max_iterations = max_iterations
            
        async def execute(self, state: Dict[str, Any]) -> Union[Dict[str, Any], Command]:
            """æ‰§è¡Œè§‚å¯Ÿåˆ†æ"""
            messages = self.get_messages(state)
            tool_results = state.get("tool_results", [])
            
            # æ„å»ºè§‚å¯Ÿåˆ†ææç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œéœ€è¦åˆ†æå·¥å…·æ‰§è¡Œçš„ç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚

è¯·ä»”ç»†åˆ†æåˆšæ‰æ‰§è¡Œçš„å·¥å…·ç»“æœï¼Œè¯„ä¼°ï¼š
1. **ç»“æœè´¨é‡**ï¼šå·¥å…·æ‰§è¡Œæ˜¯å¦æˆåŠŸï¼Œè¿”å›çš„æ•°æ®æ˜¯å¦æœ‰ç”¨
2. **é—®é¢˜è§£å†³ç¨‹åº¦**ï¼šå½“å‰ç»“æœæ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
3. **ä¿¡æ¯å®Œæ•´æ€§**ï¼šæ˜¯å¦è¿˜éœ€è¦è·å–æ›´å¤šä¿¡æ¯
4. **ä¸‹ä¸€æ­¥å»ºè®®**ï¼šåº”è¯¥ç»§ç»­æ€è€ƒã€æ‰§è¡Œæ›´å¤šå·¥å…·ï¼Œè¿˜æ˜¯ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š

ç»“æœè´¨é‡è¯„åˆ†ï¼š[1-10åˆ†ï¼Œè¯„ä¼°å·¥å…·æ‰§è¡Œç»“æœçš„è´¨é‡]
é—®é¢˜è§£å†³çŠ¶æ€ï¼š[å·²è§£å†³/éƒ¨åˆ†è§£å†³/æœªè§£å†³]
ä¿¡æ¯å®Œæ•´æ€§ï¼š[å®Œæ•´/åŸºæœ¬å®Œæ•´/ä¸å®Œæ•´]
ç»§ç»­æ¨ç†ï¼š[æ˜¯/å¦ï¼Œæ˜¯å¦éœ€è¦ç»§ç»­æ€è€ƒå’Œè¡ŒåŠ¨]
å»ºè®®è¡ŒåŠ¨ï¼š[ç»§ç»­æ€è€ƒ/ç›´æ¥å›ç­”/éœ€è¦æ›´å¤šå·¥å…·]
åˆ†ææ€»ç»“ï¼š[å¯¹å½“å‰ç»“æœçš„è¯¦ç»†åˆ†æ]"""
            
            iteration_count = state.get("iteration_count", 0)
            thought_count = state.get("thought_count", 0)
            
            try:
                response = await self.generate(messages, system_prompt=system_prompt)
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # è§£æè§‚å¯Ÿç»“æœ
                observation_analysis = self._parse_observation_response(response_text, tool_results)
                
                # åˆ›å»ºè§‚å¯Ÿæ¶ˆæ¯
                observation_content = self._format_observation_content(tool_results, observation_analysis, thought_count)
                observation_message = self.create_ai_message(observation_content)
                observation_message.metadata = {
                    "node_type": "observation",
                    "iteration_count": iteration_count,
                    "tool_results_count": len(tool_results),
                    "analysis": observation_analysis
                }
                
                # å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
                next_node = self._decide_next_action(observation_analysis, iteration_count, thought_count)
                
                # æ›´æ–°è¿­ä»£è®¡æ•°
                new_iteration_count = iteration_count + 1 if next_node == "thought" else iteration_count
                
                return Command(
                    update={
                        "messages": [observation_message],
                        "observation": observation_analysis["summary"],
                        "quality_score": observation_analysis["quality_score"],
                        "problem_solved": observation_analysis["problem_solved"],
                        "continue_reasoning": observation_analysis["continue_reasoning"],
                        "iteration_count": new_iteration_count
                    },
                    goto=next_node
                )
                
            except Exception as e:
                error_message = self.create_ai_message("åˆ†æè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼Œå°†åŸºäºç°æœ‰ä¿¡æ¯ç»™å‡ºå›ç­”")
                return Command(
                    update={"messages": [error_message], "error": str(e)},
                    goto="final_answer"
                )
        
        def _parse_observation_response(self, response: str, tool_results: List[Dict[str, Any]]) -> Dict[str, Any]:
            """è§£æè§‚å¯Ÿåˆ†æå“åº”"""
            analysis = {
                "quality_score": 5,
                "problem_solved": False,
                "needs_more_info": True,
                "continue_reasoning": True,
                "summary": response,
                "tool_analysis": self._analyze_tool_results(tool_results)
            }
            
            try:
                lines = response.split('\n')
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('ç»“æœè´¨é‡è¯„åˆ†ï¼š'):
                        try:
                            import re
                            score_match = re.search(r'(\d+)', line)
                            if score_match:
                                analysis['quality_score'] = int(score_match.group(1))
                        except:
                            pass
                            
                    elif line.startswith('é—®é¢˜è§£å†³çŠ¶æ€ï¼š'):
                        status = line[7:].strip()
                        if 'å·²è§£å†³' in status:
                            analysis['problem_solved'] = True
                            analysis['needs_more_info'] = False
                        elif 'éƒ¨åˆ†è§£å†³' in status:
                            analysis['problem_solved'] = False
                            analysis['needs_more_info'] = True
                        else:
                            analysis['problem_solved'] = False
                            analysis['needs_more_info'] = True
                            
                    elif line.startswith('ç»§ç»­æ¨ç†ï¼š'):
                        continue_text = line[5:].strip()
                        analysis['continue_reasoning'] = 'æ˜¯' in continue_text
                        
                    elif line.startswith('åˆ†ææ€»ç»“ï¼š'):
                        analysis['summary'] = line[5:].strip()
                
                # ç»¼åˆåˆ¤æ–­
                if analysis['quality_score'] >= 8 and analysis['problem_solved']:
                    analysis['continue_reasoning'] = False
                elif analysis['quality_score'] <= 3:
                    analysis['continue_reasoning'] = True
                    analysis['needs_more_info'] = True
                    
            except Exception as e:
                print(f"è§£æè§‚å¯Ÿå“åº”å¤±è´¥: {e}")
            
            return analysis
        
        def _analyze_tool_results(self, tool_results: List[Dict[str, Any]]) -> Dict[str, Any]:
            """åˆ†æå·¥å…·æ‰§è¡Œç»“æœ"""
            if not tool_results:
                return {
                    "total_tools": 0,
                    "success_count": 0,
                    "failed_count": 0,
                    "success_rate": 0.0,
                    "has_useful_data": False,
                    "error_summary": "æ²¡æœ‰å·¥å…·æ‰§è¡Œç»“æœ"
                }
            
            success_count = sum(1 for result in tool_results if result.get("success", False))
            failed_count = len(tool_results) - success_count
            success_rate = success_count / len(tool_results) if tool_results else 0
            
            has_useful_data = False
            for result in tool_results:
                if result.get("success", False):
                    result_content = str(result.get("result", ""))
                    if len(result_content) > 10 and "å¤±è´¥" not in result_content:
                        has_useful_data = True
                        break
            
            errors = [result.get("error", "") for result in tool_results if not result.get("success", False)]
            error_summary = "; ".join(filter(None, errors)) if errors else ""
            
            return {
                "total_tools": len(tool_results),
                "success_count": success_count,
                "failed_count": failed_count,
                "success_rate": success_rate,
                "has_useful_data": has_useful_data,
                "error_summary": error_summary
            }
        
        def _format_observation_content(self, tool_results: List[Dict[str, Any]], 
                                      analysis: Dict[str, Any], thought_count: int) -> str:
            """æ ¼å¼åŒ–è§‚å¯Ÿå†…å®¹"""
            content_parts = [f"è§‚å¯Ÿ {thought_count}ï¼š"]
            
            if tool_results:
                tool_analysis = analysis["tool_analysis"]
                content_parts.append(
                    f"å·¥å…·æ‰§è¡Œç»“æœï¼š{tool_analysis['success_count']}/{tool_analysis['total_tools']} æˆåŠŸ "
                    f"(æˆåŠŸç‡: {tool_analysis['success_rate']:.1%})"
                )
                
                for i, result in enumerate(tool_results):
                    tool_name = result.get("tool_name", f"å·¥å…·{i+1}")
                    status = "âœ…" if result.get("success", False) else "âŒ"
                    content_parts.append(f"  {status} {tool_name}")
                    
                    if result.get("success", False):
                        result_str = str(result.get("result", ""))
                        if len(result_str) > 200:
                            result_str = result_str[:200] + "..."
                        content_parts.append(f"     ç»“æœï¼š{result_str}")
                    else:
                        error = result.get("error", "æœªçŸ¥é”™è¯¯")
                        content_parts.append(f"     é”™è¯¯ï¼š{error}")
            
            content_parts.append(f"\nåˆ†æï¼š{analysis['summary']}")
            content_parts.append(f"è´¨é‡è¯„åˆ†ï¼š{analysis['quality_score']}/10")
            
            return "\n".join(content_parts)
        
        def _decide_next_action(self, analysis: Dict[str, Any], iteration_count: int, thought_count: int) -> str:
            """å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
            if iteration_count >= self.max_iterations:
                return "final_answer"
            
            if analysis["problem_solved"] and analysis["quality_score"] >= 7:
                return "final_answer"
            
            if analysis["quality_score"] <= 4 and analysis["needs_more_info"]:
                if thought_count >= 8:
                    return "final_answer"
                return "thought"
            
            if analysis["continue_reasoning"] and thought_count < 6:
                return "thought"
            else:
                return "final_answer"
    
    class FinalAnswerNode(BaseNode):
        """æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹ - æ•´åˆæ‰€æœ‰æ¨ç†è¿‡ç¨‹å¹¶ç”Ÿæˆæœ€ç»ˆå›ç­”"""
        
        def __init__(self, name: str, llm: BaseLLMProvider, **kwargs):
            super().__init__(name, NodeType.FINALIZE, "æœ€ç»ˆç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹", llm=llm, **kwargs)
            
        async def execute(self, state: Dict[str, Any]) -> Union[Dict[str, Any], Command]:
            """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
            messages = self.get_messages(state)
            
            # ä½¿ç”¨é›†æˆçš„build_promptæ–¹æ³•
            system_prompt = self.build_prompt("final_answer",
                                             query=messages[0].content if messages else "",
                                             thought="åŸºäºå‰é¢çš„å®Œæ•´æ¨ç†è¿‡ç¨‹",
                                             observations="å·²å®Œæˆæ‰€æœ‰å¿…è¦çš„åˆ†æå’Œå·¥å…·è°ƒç”¨")
            
            thought_count = state.get("thought_count", 0)
            iteration_count = state.get("iteration_count", 0)
            
            try:
                response = await self.generate(messages, system_prompt=system_prompt)
                response_text = response.content if hasattr(response, 'content') else str(response)
                
                # æ¸…ç†å’Œæ ¼å¼åŒ–å“åº”
                final_answer = self._format_final_answer(response_text)
                
                final_message = self.create_ai_message(final_answer)
                final_message.metadata = {
                    "node_type": "final_answer",
                    "thought_count": thought_count,
                    "iteration_count": iteration_count,
                    "is_final_answer": True
                }
                
                return {
                    "messages": [final_message],
                    "final_answer": final_answer,
                    "thought_count": thought_count,
                    "iteration_count": iteration_count,
                    "is_complete": True
                }
                
            except Exception as e:
                fallback_answer = self._generate_fallback_answer(messages, str(e))
                
                fallback_message = self.create_ai_message(fallback_answer)
                fallback_message.metadata = {
                    "node_type": "final_answer",
                    "is_fallback": True,
                    "error": str(e)
                }
                
                return {
                    "messages": [fallback_message],
                    "final_answer": fallback_answer,
                    "error": f"æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}",
                    "is_fallback": True,
                    "is_complete": True
                }
        
        def _format_final_answer(self, response: str) -> str:
            """æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆ"""
            cleaned_response = response.strip()
            
            prefixes_to_remove = [
                "æœ€ç»ˆç­”æ¡ˆï¼š", "Final Answer:", "ç­”æ¡ˆï¼š", "å›ç­”ï¼š", "ç»“è®ºï¼š", "æ€»ç»“ï¼š"
            ]
            
            for prefix in prefixes_to_remove:
                if cleaned_response.startswith(prefix):
                    cleaned_response = cleaned_response[len(prefix):].strip()
            
            if not cleaned_response:
                cleaned_response = "æŠ±æ­‰ï¼Œæ— æ³•åŸºäºå½“å‰ä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„å›ç­”ã€‚"
            
            return cleaned_response
        
        def _generate_fallback_answer(self, messages: List[Message], error_msg: str) -> str:
            """ç”Ÿæˆå¤‡ç”¨å›ç­”"""
            user_query = ""
            for message in messages:
                if message.role == MessageRole.USER:
                    user_query = message.content
                    break
            
            fallback_parts = []
            if user_query:
                fallback_parts.append(f"é’ˆå¯¹æ‚¨çš„é—®é¢˜ï¼š{user_query}")
            
            fallback_parts.append(f"ç”±äºæŠ€æœ¯åŸå› ï¼ˆ{error_msg}ï¼‰ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´çš„åˆ†æç»“æœã€‚")
            fallback_parts.append("è¯·æ‚¨é‡æ–°æè¿°é—®é¢˜ï¼Œæˆ‘å°†é‡æ–°ä¸ºæ‚¨åˆ†æã€‚")
            
            return "\n".join(fallback_parts)
    
    # ==================== ReactAgent ä¸»ä½“ ====================
    
    def __init__(self,
                 llm: BaseLLMProvider,
                 tool_manager: Optional[Union[ToolManager, 'MCPToolManager']] = None,
                 max_iterations: int = 5,
                 name: Optional[str] = None,
                 memory_enabled: bool = True,
                 memory_store: Optional[SQLiteMemoryStore] = None,
                 short_term_limit: int = 30000,
                 session_id: Optional[str] = None,
                 use_think_mode: bool = True,
                 **kwargs):
        """
        åˆå§‹åŒ–ReAct Agent
        
        Args:
            llm: LLMæä¾›è€…
            tool_manager: å·¥å…·ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œæ”¯æŒToolManageræˆ–MCPToolManagerï¼‰
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            name: Agentåç§°
            memory_enabled: æ˜¯å¦å¯ç”¨è®°å¿†åŠŸèƒ½
            memory_store: è®°å¿†å­˜å‚¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            short_term_limit: çŸ­æœŸè®°å¿†å­—ç¬¦é™åˆ¶
            session_id: ä¼šè¯IDï¼ˆç”¨äºè®°å¿†éš”ç¦»ï¼‰
            **kwargs: å…¶ä»–é…ç½®
        """
        super().__init__(
            agent_type=AgentType.REACT,
            name=name or "react_agent",
            description="åŸºäºReActèŒƒå¼çš„æ™ºèƒ½ä»£ç†ï¼ˆæ”¯æŒè®°å¿†ï¼‰",
            **kwargs
        )
        self.llm = llm
        self.tool_manager = tool_manager
        self.max_iterations = max_iterations
        self.use_think_mode = use_think_mode
        self.executor = StateGraphExecutor(max_iterations=max_iterations)
        
        # è®°å¿†ç®¡ç†
        self.memory_enabled = memory_enabled
        self.memory_manager = None
        if memory_enabled:
            self.memory_manager = MemoryManager(
                llm=llm,
                store=memory_store or SQLiteMemoryStore("./workspace/memory.db"),
                short_term_limit=short_term_limit,
                session_id=session_id
            )
        
    def build_graph(self, use_stream: bool = False) -> StateGraph:
        """æ„å»ºReActæ‰§è¡Œå›¾
        
        Args:
            use_stream: æ˜¯å¦ä½¿ç”¨æµå¼èŠ‚ç‚¹
        """
        builder = GraphBuilder("react_graph")
        
        # åˆ¤æ–­æ˜¯å¦æœ‰å·¥å…·å¯ç”¨
        if self.tool_manager and self.tool_manager.list_tools():
            if use_stream:
                # ä½¿ç”¨æµå¼èŠ‚ç‚¹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                from nodes.stream_react_agent_node import StreamReactAgentNode
                agent_node = StreamReactAgentNode("agent", self.llm, self.tool_manager)
                
                # æµå¼èŠ‚ç‚¹ä¸éœ€è¦å·¥å…·èŠ‚ç‚¹ï¼Œå†…éƒ¨å¤„ç†å·¥å…·è°ƒç”¨
                graph = (builder
                    .add_node(agent_node)
                    .entry("agent")
                    .build()
                )
            else:
                # ä½¿ç”¨å†…ç½®çš„åˆ†ç¦»å¼ReActèŠ‚ç‚¹æ¶æ„
                thought_node = self.ThoughtNode("thought", self.llm, use_think_mode=self.use_think_mode)
                action_node = self.ActionNode("action", self.llm, self.tool_manager)
                observation_node = self.ObservationNode("observation", self.llm, self.max_iterations)
                final_answer_node = self.FinalAnswerNode("final_answer", self.llm)
                
                # æ„å»ºåˆ†ç¦»å¼ReActå›¾
                graph = (builder
                    .add_node(thought_node)
                    .add_node(action_node)
                    .add_node(observation_node)
                    .add_node(final_answer_node)
                    .entry("thought")
                    .build()
                )
        else:
            # æ²¡æœ‰å·¥å…·æ—¶çš„ç®€å•å¯¹è¯æ¨¡å¼
            from nodes.simple_chat_node import SimpleChatNode
            chat_node = SimpleChatNode("chat", self.llm)
            
            graph = (builder
                .add_node(chat_node)
                .entry("chat")
                .build()
            )
        
        return graph
    
    def _should_continue(self, state: Dict[str, Any]) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­ä½¿ç”¨å·¥å…·"""
        messages = state.get("messages", [])
        if not messages:
            return "end"
            
        last_message = messages[-1]
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "continue"
        return "end"
        
    async def run(self, query: str, context: Optional[Dict[str, Any]] = None) -> TaskResult:
        """è¿è¡ŒReAct Agentï¼ˆåŸºäºStateGraphï¼‰"""
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # åˆ›å»ºä»»åŠ¡ç»“æœ
        result = TaskResult(
            task_id=task_id,
            query=query,
            agent_type=self.agent_type
        )
        
        # åˆå§‹åŒ–
        await self.initialize()
        
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        available_tools = []
        if self.tool_manager:
            available_tools = self.tool_manager.list_tools()
        
        # æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡
        memory_context = ""
        if self.memory_enabled and self.memory_manager:
            try:
                memory_context = await self.memory_manager.get_context_for_query(query, max_entries=5)
            except Exception as e:
                print(f"è·å–è®°å¿†ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        
        # å¤„ç†å¯¹è¯å†å²
        messages = []
        if context and context.get("conversation_history") and context.get("preserve_history"):
            messages = context["conversation_history"].copy()
            print(f"[ReactAgent.run] ä½¿ç”¨å®Œæ•´å¯¹è¯å†å²ï¼Œæ¶ˆæ¯æ•°: {len(messages)}")
        else:
            messages = [Message(role=MessageRole.USER, content=query)]
            print(f"[ReactAgent.run] ä»…ä½¿ç”¨å½“å‰æ¶ˆæ¯")
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = {
            "task_id": task_id,
            "agent_type": self.agent_type.value,
            "available_tools": available_tools,
            "messages": messages,
            "memory_context": memory_context,
            "memory_manager": self.memory_manager,
            **(context or {})
        }
        
        print(f"[ReactAgent.run] åˆå§‹çŠ¶æ€æ¶ˆæ¯æ•°: {len(initial_state['messages'])}")
        
        # æ„å»ºå¹¶æ‰§è¡ŒStateGraph
        graph = self.build_graph(use_stream=False)
        final_state = await self.executor.execute(graph, initial_state, {})
        
        # ä»æœ€ç»ˆçŠ¶æ€æå–ç»“æœ
        if final_state:
            # ä¼˜å…ˆä»final_answerå­—æ®µè·å–
            if "final_answer" in final_state:
                result.result = final_state["final_answer"]
                result.success = True
            # ä»æ¶ˆæ¯ä¸­æå–æœ€ç»ˆå›ç­”
            elif "messages" in final_state and final_state["messages"]:
                last_message = final_state["messages"][-1]
                if hasattr(last_message, 'content'):
                    result.result = last_message.content
                    result.success = True
                else:
                    result.result = str(last_message)
                    result.success = True
            # ä»å…¶ä»–å“åº”å­—æ®µè·å–
            elif "agent_response" in final_state:
                result.result = final_state["agent_response"]
                result.success = True
            elif "chat_response" in final_state:
                result.result = final_state["chat_response"]
                result.success = True
            else:
                result.result = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›å¤"
        
        # ä¿å­˜è®°å¿†
        if self.memory_enabled and self.memory_manager and result.success:
            try:
                has_history = context and context.get("conversation_history") and len(context["conversation_history"]) > 1
                if not has_history:
                    await self.memory_manager.add_conversation(query, result.result)
                    print(f"å¯¹è¯å·²ä¿å­˜åˆ°è®°å¿†ï¼Œä¼šè¯ID: {self.memory_manager.session_id}")
            except Exception as e:
                print(f"ä¿å­˜å¯¹è¯è®°å¿†å¤±è´¥: {e}")
        
        # æ„å»ºç®€åŒ–çš„æ‰§è¡Œè½¨è¿¹
        result.execution_trace = [
            {
                "graph_name": graph.name,
                "final_state_keys": list(final_state.keys()) if final_state else [],
                "success": result.success
            }
        ]
        
        # è®¡ç®—æŒ‡æ ‡
        result.metrics = {
            "state_keys": list(final_state.keys()) if final_state else [],
            "has_memory": self.memory_enabled
        }
        
        # æ·»åŠ è®°å¿†ç»Ÿè®¡ä¿¡æ¯
        if self.memory_enabled and self.memory_manager:
            try:
                memory_stats = await self.memory_manager.get_stats()
                result.metrics.update({
                    "memory_stats": memory_stats
                })
            except Exception as e:
                print(f"è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {e}")

        return result
    
    async def stream_run(self, query: str, context: Optional[Dict[str, Any]] = None) -> AsyncIterator[Dict[str, Any]]:
        """æµå¼è¿è¡ŒReAct Agent - ç®€åŒ–ç‰ˆæœ¬"""
        # æš‚æ—¶å›é€€åˆ°æ ‡å‡†æ‰§è¡Œ
        result = await self.run(query, context)
        yield {
            "type": "final_result",
            "content": result.result,
            "task_id": result.task_id,
            "metadata": {"success": result.success}
        }
        
    # _build_system_prompt æ–¹æ³•å·²ç§»åˆ°åŸºç±» BaseAgent ä¸­
        
    async def initialize(self):
        """åˆå§‹åŒ–Agent"""
        await self.llm.initialize()
        if self.tool_manager:
            await self.tool_manager.initialize()
        
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.llm.cleanup()
        if self.tool_manager:
            await self.tool_manager.cleanup() 
    
    async def get_memory_stats(self) -> Optional[Dict[str, Any]]:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        if self.memory_enabled and self.memory_manager:
            return await self.memory_manager.get_stats()
        return None
    
    async def clear_memory(self):
        """æ¸…ç©ºå½“å‰ä¼šè¯è®°å¿†"""
        if self.memory_enabled and self.memory_manager:
            await self.memory_manager.clear_all()
            print(f"å·²æ¸…ç©ºä¼šè¯è®°å¿†: {self.memory_manager.session_id}")
    
    async def export_memory(self) -> Optional[Dict[str, Any]]:
        """å¯¼å‡ºè®°å¿†æ•°æ®"""
        if self.memory_enabled and self.memory_manager:
            return await self.memory_manager.export_data()
        return None
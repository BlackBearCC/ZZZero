"""æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµ - åŸºäºGraph+Nodeçš„æ—¥ç¨‹åˆ›ä½œç³»ç»Ÿ
é›†æˆè§’è‰²åº“ã€åœ°ç‚¹åº“ã€å‰§æƒ…åº“ç­‰åŠŸèƒ½ï¼Œä¸ºä¸»è§’ç”Ÿæˆæ¯å‘¨å’Œæ¯å¤©çš„è¯¦ç»†æ—¥ç¨‹å®‰æ’
"""

import json
import asyncio
import csv
import random
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import calendar

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole

logger = logging.getLogger(__name__)

class ScheduleWorkflow:
    """æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None
        self.characters_data = {}
        self.locations_data = {}
        self.stories_data = {}  # å‰§æƒ…åº“æ•°æ®
        self.protagonist_data = ""  # ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾
        self.holidays_data = {}  # èŠ‚å‡æ—¥æ•°æ®
        self.current_config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',  # å›ºå®šä¸»è§’
            'schedule_type': 'weekly',  # weekly, daily, monthly
            'start_date': '',
            'end_date': '',
            'total_days': 7,
            'selected_characters': [],
            'selected_locations': [],
            'selected_stories': [],  # é€‰æ‹©çš„å‰§æƒ…
            'time_slots_config': {
                'å¤œé—´': {'start': '23:00', 'end': '06:00'},
                'ä¸Šåˆ': {'start': '06:00', 'end': '11:00'},
                'ä¸­åˆ': {'start': '11:00', 'end': '14:00'},
                'ä¸‹åˆ': {'start': '14:00', 'end': '18:00'},
                'æ™šä¸Š': {'start': '18:00', 'end': '23:00'}
            },
            'character_distribution': 'balanced',  # balanced, random, weighted
            'story_integration': 'moderate',  # minimal, moderate, intensive
            'include_holidays': True,
            'include_lunar': True,
            'mood_variety': True,
            'location_variety': True,
            'enable_cycle_summary': False,  # æ˜¯å¦å¯ç”¨å‘¨æœŸæ€»ç»“åŠŸèƒ½ï¼Œé»˜è®¤å…³é—­
            'cycle_summary': ''  # å½“å‰å‘¨æœŸæ€»ç»“å†…å®¹
        }
        
        # é¢„å…ˆåˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ï¼Œé˜²æ­¢æ‰§è¡Œæ—¶æ‰åˆ›å»ºå¯¼è‡´é”™è¯¯
        try:
            from database.managers import schedule_manager
            schedule_manager.ScheduleManager()  # åˆå§‹åŒ–ä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ç»“æ„
            logger.info("æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.warning(f"é¢„åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„å¤±è´¥ï¼Œç¨åå°†é‡è¯•: {e}")
        
        # åŠ è½½å„ç§æ•°æ®
        self._load_game_data()
        self._load_protagonist_data()
        self._load_stories_data()
        self._load_holidays_data()
    
    def _load_game_data(self):
        """åŠ è½½æ¸¸æˆè§’è‰²å’Œåœ°ç‚¹æ•°æ®"""
        try:
            # åŠ è½½è§’è‰²æ•°æ®
            char_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_characters.json')
            if os.path.exists(char_path):
                with open(char_path, 'r', encoding='utf-8') as f:
                    self.characters_data = json.load(f)
                    logger.info(f"æˆåŠŸåŠ è½½è§’è‰²æ•°æ®ï¼ŒåŒ…å« {len(self.characters_data.get('è§’è‰²åˆ—è¡¨', {}))} ä¸ªè§’è‰²")
            
            # åŠ è½½åœ°ç‚¹æ•°æ®
            loc_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_locations.json')
            if os.path.exists(loc_path):
                with open(loc_path, 'r', encoding='utf-8') as f:
                    self.locations_data = json.load(f)
                    district_count = len(self.locations_data.get("districts", {}))
                    logger.info(f"æˆåŠŸåŠ è½½åœ°ç‚¹æ•°æ®ï¼ŒåŒ…å« {district_count} ä¸ªåŒºåŸŸ")
                    
        except Exception as e:
            logger.error(f"åŠ è½½æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
    
    def _load_protagonist_data(self):
        """åŠ è½½ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾"""
        try:
            protagonist_path = os.path.join(os.path.dirname(__file__), '../../config/åŸºç¡€äººè®¾.txt')
            if os.path.exists(protagonist_path):
                with open(protagonist_path, 'r', encoding='utf-8') as f:
                    self.protagonist_data = f.read()
                    logger.info(f"æˆåŠŸåŠ è½½ä¸»è§’äººè®¾ï¼Œå†…å®¹é•¿åº¦: {len(self.protagonist_data)} å­—ç¬¦")
            else:
                logger.warning("ä¸»è§’äººè®¾æ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            logger.error(f"åŠ è½½ä¸»è§’äººè®¾å¤±è´¥: {e}")
    
    def _load_stories_data(self):
        """åŠ è½½å·²æœ‰å‰§æƒ…æ•°æ®ä½œä¸ºå‚è€ƒ"""
        try:
            from database import story_manager
            
            # è·å–æ‰€æœ‰å‰§æƒ…ä½œä¸ºå‚è€ƒ
            all_stories = story_manager.get_stories_by_filter({}, limit=100)
            
            # æŒ‰è§’è‰²åˆ†ç»„å‰§æƒ…
            self.stories_data = {
                'all_stories': all_stories,
                'by_character': {},
                'by_location': {},
                'by_type': {}
            }
            
            for story in all_stories:
                # æŒ‰è§’è‰²åˆ†ç»„
                characters = json.loads(story.get('selected_characters', '[]'))
                for char in characters:
                    if char not in self.stories_data['by_character']:
                        self.stories_data['by_character'][char] = []
                    self.stories_data['by_character'][char].append(story)
                
                # æŒ‰åœ°ç‚¹åˆ†ç»„
                locations = json.loads(story.get('selected_locations', '[]'))
                for loc in locations:
                    if loc not in self.stories_data['by_location']:
                        self.stories_data['by_location'][loc] = []
                    self.stories_data['by_location'][loc].append(story)
                
                # æŒ‰ç±»å‹åˆ†ç»„
                story_type = story.get('story_type', 'daily_life')
                if story_type not in self.stories_data['by_type']:
                    self.stories_data['by_type'][story_type] = []
                self.stories_data['by_type'][story_type].append(story)
            
            logger.info(f"æˆåŠŸåŠ è½½å‰§æƒ…æ•°æ®ï¼ŒåŒ…å« {len(all_stories)} ä¸ªå‰§æƒ…")
            
        except Exception as e:
            logger.error(f"åŠ è½½å‰§æƒ…æ•°æ®å¤±è´¥: {e}")
            self.stories_data = {'all_stories': [], 'by_character': {}, 'by_location': {}, 'by_type': {}}
    
    def _load_holidays_data(self):
        """åŠ è½½èŠ‚å‡æ—¥æ•°æ®"""
        try:
            # ä»CSVæ–‡ä»¶åŠ è½½èŠ‚å‡æ—¥æ•°æ®
            holidays_csv_path = os.path.join(os.path.dirname(__file__), '../../config/holidays.csv')
            
            if os.path.exists(holidays_csv_path):
                with open(holidays_csv_path, 'r', encoding='utf-8') as f:
                    csv_reader = csv.DictReader(f)
                    for row in csv_reader:
                        date_str = row['date']
                        self.holidays_data[date_str] = {
                            'name': row['name'],
                            'type': row['type'],
                            'lunar': row['lunar'].lower() == 'true',
                            'description': row.get('description', '')
                        }
                
                logger.info(f"ä»CSVæ–‡ä»¶åŠ è½½èŠ‚å‡æ—¥æ•°æ®ï¼ŒåŒ…å« {len(self.holidays_data)} ä¸ªèŠ‚å‡æ—¥")

            
        except Exception as e:
            logger.error(f"åŠ è½½èŠ‚å‡æ—¥æ•°æ®å¤±è´¥: {e}")
            # ä½¿ç”¨ç©ºå­—å…¸ä½œä¸ºæœ€åçš„åå¤‡
            self.holidays_data = {}
    
    def get_protagonist_info(self) -> Dict[str, Any]:
        """è·å–ä¸»è§’ä¿¡æ¯"""
        protagonist_name = self.current_config.get('protagonist', 'æ–¹çŸ¥è¡¡')
        return {
            'name': protagonist_name,
            'type': 'protagonist',
            'description': self.protagonist_data.split('\n')[0] if self.protagonist_data else 'ä¸»è§’ä¿¡æ¯',
            'full_profile': self.protagonist_data
        }
    
    def get_characters_list(self) -> List[Dict[str, Any]]:
        """è·å–è§’è‰²åˆ—è¡¨ï¼ˆä¸åŒ…å«ä¸»è§’ï¼‰"""
        characters = []
        char_list = self.characters_data.get("è§’è‰²åˆ—è¡¨", {})
        
        for name, info in char_list.items():
            # è·³è¿‡ä¸»è§’ï¼Œä¸»è§’å•ç‹¬å¤„ç†
            if name == 'æ–¹çŸ¥è¡¡':
                continue
                
            characters.append({
                'name': name,
                'age': info.get('å¹´é¾„', 'æœªçŸ¥'),
                'personality': info.get('æ€§æ ¼', ''),
                'description': info.get('ç®€ä»‹', ''),
                'locations': info.get('æ´»åŠ¨åœ°ç‚¹', []),
                'plots': info.get('å¯è§¦å‘å‰§æƒ…', []),
                'backstory': info.get('èƒŒæ™¯æ•…äº‹', ''),
                'relationships': info.get('äººé™…å…³ç³»', {}),
                'habits': info.get('ç”Ÿæ´»ä¹ æƒ¯', []),
                'appearance': info.get('å¤–è²Œç‰¹å¾', ''),
                'skills': info.get('ç‰¹é•¿æŠ€èƒ½', [])
            })
        
        return characters
    
    def get_locations_list(self) -> List[Dict[str, Any]]:
        """è·å–åœ°ç‚¹åˆ—è¡¨"""
        locations = []
        districts = self.locations_data.get("districts", {})
        
        for district_name, district_info in districts.items():
            district_locations = district_info.get("locations", {})
            for loc_name, loc_info in district_locations.items():
                locations.append({
                    'name': loc_info.get('name', loc_name),
                    'type': loc_info.get('type', ''),
                    'district': district_info.get('name', district_name),
                    'description': loc_info.get('description', ''),
                    'atmosphere': loc_info.get('atmosphere', ''),
                    'keywords': loc_info.get('keywords', [])
                })
        
        return locations
    
    def get_stories_list(self) -> List[Dict[str, Any]]:
        """è·å–å‰§æƒ…åˆ—è¡¨"""
        stories = []
        for story in self.stories_data.get('all_stories', []):
            stories.append({
                'story_id': story.get('story_id', ''),
                'story_name': story.get('story_name', ''),
                'story_overview': story.get('story_overview', ''),
                'story_type': story.get('story_type', ''),
                'characters': json.loads(story.get('selected_characters', '[]')),
                'locations': json.loads(story.get('selected_locations', '[]')),
                'main_conflict': story.get('main_conflict', ''),
                'emotional_development': story.get('emotional_development', '')
            })
        
        return stories
    
    def get_holidays_in_range(self, start_date: str, end_date: str) -> Dict[str, Dict[str, Any]]:
        """è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„èŠ‚å‡æ—¥"""
        holidays = {}
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        for date_str, holiday_info in self.holidays_data.items():
            holiday_date = datetime.strptime(date_str, '%Y-%m-%d')
            if start <= holiday_date <= end:
                holidays[date_str] = holiday_info
        
        return holidays
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def prepare_cycle_summary(self, config: Dict[str, Any]) -> str:
        """å‡†å¤‡å‘¨æœŸæ€»ç»“ï¼Œè·å–å†å²æ•°æ®"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å‘¨æœŸæ€»ç»“
            if not config.get('enable_cycle_summary', False):
                logger.info("å‘¨æœŸæ€»ç»“åŠŸèƒ½æœªå¯ç”¨")
                return ""
            
            # ç­‰å¾…1ç§’ï¼Œç¡®ä¿æ•°æ®åº“å†™å…¥å®Œæˆ
            import time
            time.sleep(1)
            
            # ä»æ•°æ®åº“è·å–æœ€æ–°çš„å‘¨æœŸæ€»ç»“
            from database.managers.schedule_manager import ScheduleManager
            schedule_manager = ScheduleManager()
            
            # ä¼ é€’å¼€å§‹æ—¥æœŸï¼Œç¡®ä¿è·å–æ—©äºå¼€å§‹æ—¥æœŸä¸”æ—¶é—´ä¸è¶…è¿‡ä¸‰å¤©çš„æ€»ç»“
            start_date = config.get('start_date', '')
            previous_summary = schedule_manager.get_latest_cycle_summary(before_date=start_date)
            
            if previous_summary:
                logger.info(f"è·å–åˆ°é€‚å½“çš„å†å²å‘¨æœŸæ€»ç»“ï¼Œé•¿åº¦: {len(previous_summary)} å­—ç¬¦")
                return previous_summary
            else:
                logger.info(f"æœªæ‰¾åˆ°{start_date}å‰ä¸‰å¤©å†…çš„å‘¨æœŸæ€»ç»“ï¼Œè¿™å¯èƒ½æ˜¯ç¬¬ä¸€ä¸ªå‘¨æœŸæˆ–æ—¶é—´é—´éš”è¾ƒé•¿")
                return ""
                
        except Exception as e:
            logger.error(f"å‡†å¤‡å‘¨æœŸæ€»ç»“å¤±è´¥: {e}")
            return ""
    
    async def create_schedule_graph(self) -> StateGraph:
        """åˆ›å»ºæ—¥ç¨‹ç”Ÿæˆå›¾å·¥ä½œæµ - æ–°ç‰ˆæœ¬ï¼šå…ˆè§„åˆ’å‘¨æœŸï¼Œå†åˆ†æ‰¹ç”Ÿæˆ"""
        self.graph = StateGraph(name="schedule_generation_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹
        cycle_planning_node = CyclePlanningNode()  # æ–°å¢ï¼šå‘¨æœŸè§„åˆ’èŠ‚ç‚¹
        schedule_generate_node = ScheduleGenerateNode()  # ä¿®æ”¹ï¼šåˆ†æ‰¹ç”ŸæˆèŠ‚ç‚¹
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("cycle_planning", cycle_planning_node)
        self.graph.add_node("schedule_generate", schedule_generate_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.graph.add_edge("cycle_planning", "schedule_generate")
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("cycle_planning")
        
        return self.graph
    
    async def execute_workflow_stream(self, config: Dict[str, Any], workflow):
        """æµå¼æ‰§è¡Œå·¥ä½œæµ - ä½¿ç”¨StateGraphè‡ªåŠ¨ç¼–æ’"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'characters_data': self.characters_data,
                'locations_data': self.locations_data,
                'stories_data': self.stories_data,
                'protagonist_data': self.protagonist_data,
                'holidays_data': self.holidays_data,
                'config': config,
                'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
                'schedule_type': config.get('schedule_type', 'weekly'),
                'start_date': config.get('start_date', ''),
                'end_date': config.get('end_date', ''),
                'total_days': config.get('total_days', 7),
                'selected_characters': config.get('selected_characters', []),
                'selected_locations': config.get('selected_locations', []),
                'selected_stories': config.get('selected_stories', []),
                'time_slots_config': config.get('time_slots_config', self.current_config['time_slots_config']),
                'character_distribution': config.get('character_distribution', 'balanced'),
                'story_integration': config.get('story_integration', 'moderate'),
                'include_holidays': config.get('include_holidays', True),
                'include_lunar': config.get('include_lunar', True),
                'workflow_chat': workflow,  # ä¼ é€’UIæ›´æ–°å™¨
                'llm': self.llm  # ä¼ é€’LLMå®ä¾‹
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_schedule_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ - ä½¿ç”¨async foræ­£ç¡®å¤„ç†å¼‚æ­¥ç”Ÿæˆå™¨
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    # å·¥ä½œæµå¼€å§‹
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        "æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    # èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
                    node_display_name = self._get_node_display_name(node_name)
                    workflow.current_node = self._get_node_id(node_name)
                    
                    # æ›´æ–°UI - èŠ‚ç‚¹å¼€å§‹çŠ¶æ€
                    await workflow.add_node_message(
                        node_display_name,
                        "å¼€å§‹æ‰§è¡Œ...",
                        "progress"
                    )
                    
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    # èŠ‚ç‚¹æµå¼æ‰§è¡Œä¸­
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        # è·å–å½“å‰ç”Ÿæˆçš„å†…å®¹é•¿åº¦
                        content_length = 0
                        for key in ['schedule_content', 'daily_schedules', 'schedule_result']:
                            if key in intermediate_result.state_update:
                                if isinstance(intermediate_result.state_update[key], str):
                                    content_length = len(intermediate_result.state_update[key])
                                elif isinstance(intermediate_result.state_update[key], (list, dict)):
                                    content_length = len(str(intermediate_result.state_update[key]))
                                break
                        
                        # å®æ—¶æ›´æ–°è¿›åº¦ä¿¡æ¯ - è·å–æœ€æ–°çš„è¿›åº¦HTMLï¼Œä¸story_workflowä¿æŒä¸€è‡´
                        if content_length > 0:
                            node_display_name = self._get_node_display_name(node_name)
                            await workflow.add_node_message(
                                node_display_name,
                                f"æ­£åœ¨ç”Ÿæˆæ—¥ç¨‹å†…å®¹... å½“å‰ç”Ÿæˆ{content_length}å­—ç¬¦",
                                "streaming"
                            )
                            
                            yield (
                                workflow._create_workflow_progress(),
                                "",
                                f"æ­£åœ¨ç”Ÿæˆæ—¥ç¨‹å†…å®¹... å½“å‰é•¿åº¦: {content_length} å­—ç¬¦",
                                False
                            )
                
                elif event_type == 'node_complete':
                    # èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
                    node_display_name = self._get_node_display_name(node_name)
                    node_id = self._get_node_id(node_name)
                    
                    # ä¸ºèŠ‚ç‚¹æ·»åŠ å®Œæˆæ¶ˆæ¯ï¼Œç¡®ä¿UIæ­£ç¡®æ›´æ–°
                    if node_name == 'schedule_generate':
                        result_content = "âœ… æ—¥ç¨‹ç”Ÿæˆå®Œæˆ"
                        if 'schedule_result' in stream_event.get('output', {}):
                            schedule_data = stream_event['output']['schedule_result']
                            if isinstance(schedule_data, (dict, list)):
                                result_content = f"âœ… å·²æˆåŠŸç”Ÿæˆ{config['total_days']}å¤©çš„æ—¥ç¨‹å®‰æ’"
                    else:
                        result_content = "âœ… æ‰§è¡Œå®Œæˆ"
                        
                    # æ›´æ–°èŠ‚ç‚¹æ¶ˆæ¯
                    await workflow.add_node_message(
                        node_display_name,
                        result_content,
                        "completed"
                    )
                    
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    # èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    node_display_name = self._get_node_display_name(node_name)
                    
                    await workflow.add_node_message(
                        node_display_name,
                        f"æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    # å·¥ä½œæµå®Œæˆ
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        "æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                # å…¶ä»–äº‹ä»¶ç±»å‹å¯ä»¥å¿½ç•¥æˆ–è®°å½•æ—¥å¿—
                else:
                    # æŒç»­æ›´æ–°UIä»¥ä¿æŒæµç•…æ€§
                    yield (
                        workflow._create_workflow_progress(),
                        "",
                        "æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"æ—¥ç¨‹ç”Ÿæˆå·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow._create_workflow_progress(),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'cycle_planning': 'å‘¨æœŸè§„åˆ’',
            'schedule_generate': 'æ—¥ç¨‹ç”Ÿæˆ'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'cycle_planning': 'planning',
            'schedule_generate': 'generate'
        }
        return id_mapping.get(node_name, node_name)


class CyclePlanningNode(BaseNode):
    """å‘¨æœŸè§„åˆ’èŠ‚ç‚¹ - é¢„å…ˆè§„åˆ’æ‰€æœ‰æ‰¹æ¬¡çš„å‘¨æœŸè®¡åˆ’"""
    
    def __init__(self):
        super().__init__(name="cycle_planning", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå‘¨æœŸè§„åˆ’èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå‘¨æœŸè§„åˆ’èŠ‚ç‚¹"""
        print("ğŸ“‹ å¼€å§‹å‘¨æœŸè§„åˆ’...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–é…ç½®å‚æ•°
        start_date = input_data.get('start_date', '')
        end_date = input_data.get('end_date', '')
        total_days = input_data.get('total_days', 7)
        protagonist = input_data.get('protagonist', 'æ–¹çŸ¥è¡¡')
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        config = input_data.get('config', {})
        
        # æ›´æ–°UI
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å‘¨æœŸè§„åˆ’",
                f"æ­£åœ¨ä¸º{total_days}å¤©æ—¶é—´èŒƒå›´åˆ¶å®šå‘¨æœŸè§„åˆ’...",
                "progress"
            )
        
        try:
            from datetime import datetime, timedelta
            import math
            
            # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªå‘¨æœŸï¼ˆæ¯ä¸ªå‘¨æœŸ7-15å¤©ï¼‰
            min_cycle_days = 7
            max_cycle_days = 15
            
            # æ™ºèƒ½åˆ†é…å‘¨æœŸé•¿åº¦
            cycles = []
            remaining_days = total_days
            current_date = datetime.strptime(start_date, '%Y-%m-%d')
            
            cycle_num = 1
            while remaining_days > 0:
                # æ ¹æ®å‰©ä½™å¤©æ•°æ™ºèƒ½å†³å®šå‘¨æœŸé•¿åº¦
                if remaining_days <= max_cycle_days:
                    cycle_days = remaining_days
                else:
                    # ä¼˜å…ˆé€‰æ‹©è¾ƒé•¿çš„å‘¨æœŸï¼Œä½†ä¿è¯æœ€åä¸€ä¸ªå‘¨æœŸä¸ä¼šå¤ªçŸ­
                    if remaining_days <= max_cycle_days + min_cycle_days:
                        cycle_days = remaining_days // 2
                    else:
                        cycle_days = random.randint(min_cycle_days, max_cycle_days)
                
                cycle_end_date = current_date + timedelta(days=cycle_days - 1)
                
                cycles.append({
                    'cycle_number': cycle_num,
                    'start_date': current_date.strftime('%Y-%m-%d'),
                    'end_date': cycle_end_date.strftime('%Y-%m-%d'),
                    'total_days': cycle_days,
                    'status': 'planned'
                })
                
                current_date = cycle_end_date + timedelta(days=1)
                remaining_days -= cycle_days
                cycle_num += 1
            
            logger.info(f"æ™ºèƒ½åˆ†é…äº† {len(cycles)} ä¸ªå‘¨æœŸï¼Œæ€»è®¡ {total_days} å¤©")
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å‘¨æœŸè§„åˆ’",
                    f"å·²æ™ºèƒ½åˆ†é… {len(cycles)} ä¸ªå‘¨æœŸï¼Œæ¯ä¸ªå‘¨æœŸ {min_cycle_days}-{max_cycle_days} å¤©",
                    "progress"
                )
            
            # å‡†å¤‡å†å²ä¸Šä¸‹æ–‡
            protagonist_data = input_data.get('protagonist_data', '')
            
            # æŒ‡å®šçš„é‡è¦è§’è‰²åˆ—è¡¨
            important_characters = ['ç‘Ÿç³å¨œ', 'éƒèªæ˜', 'æ—å®‰äºˆ', 'å…ƒé€¸', 'å…ƒå—', 'ç½—æ’', 'æ˜“å¥¶å¥¶', 'é‡‘å–œ']
            
            # è·å–é‡è¦è§’è‰²çš„è¯¦ç»†ä¿¡æ¯
            important_characters_info = []
            char_list = input_data.get('characters_data', {}).get("è§’è‰²åˆ—è¡¨", {})
            for char_name in important_characters:
                if char_name in char_list:
                    char_info = char_list[char_name]
                    char_desc = f"{char_name}ï¼ˆé‡è¦è§’è‰²ï¼‰ï¼š{char_info.get('ç®€ä»‹', '')}"
                    if char_info.get('æ€§æ ¼'):
                        char_desc += f"ï¼Œæ€§æ ¼{char_info.get('æ€§æ ¼')}"
                    if char_info.get('å¹´é¾„'):
                        char_desc += f"ï¼Œå¹´é¾„{char_info.get('å¹´é¾„')}"
                    if char_info.get('æ´»åŠ¨åœ°ç‚¹'):
                        char_desc += f"ï¼Œä¸»è¦æ´»åŠ¨åœ°ç‚¹ï¼š{', '.join(char_info.get('æ´»åŠ¨åœ°ç‚¹', []))}"
                    important_characters_info.append(char_desc)
                else:
                    important_characters_info.append(f"{char_name}ï¼ˆé‡è¦è§’è‰²ï¼Œå¾…é…ç½®ï¼‰")
            
            # è·å–ä¸Šä¸€æ‰¹æ¬¡æ€»ç»“ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            previous_summary = config.get('previous_batch_summary', '')
            
            # è·å–æ•´ä¸ªæ—¶é—´æ®µå†…çš„èŠ‚å‡æ—¥ä¿¡æ¯
            holidays_data = input_data.get('holidays_data', {})
            cycle_holidays = []
            if holidays_data:
                from datetime import datetime
                period_start_dt = datetime.strptime(start_date, '%Y-%m-%d')
                period_end_dt = datetime.strptime(end_date, '%Y-%m-%d')
                
                for date_str, holiday_info in holidays_data.items():
                    try:
                        holiday_dt = datetime.strptime(date_str, '%Y-%m-%d')
                        if period_start_dt <= holiday_dt <= period_end_dt:
                            cycle_holidays.append(f"{date_str}: {holiday_info['name']} ({holiday_info['type']})")
                    except:
                        continue
            
            # æ„å»ºå‘¨æœŸè§„åˆ’æç¤ºè¯
            planning_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„é•¿æœŸè§„åˆ’å¸ˆï¼Œéœ€è¦ä¸ºä¸»è§’{protagonist}åˆ¶å®šä»{start_date}åˆ°{end_date}ï¼ˆå…±{total_days}å¤©ï¼‰çš„æ•´ä½“å‘¨æœŸè§„åˆ’ã€‚

# ä¸»è§’ä¿¡æ¯
{protagonist_data}

{f"# å†å²èƒŒæ™¯ä¿¡æ¯\\n{previous_summary}\\n" if previous_summary else ''}

# é‡è¦è§’è‰²ï¼ˆä¸»è¦äº’åŠ¨è§’è‰²ï¼‰
{chr(10).join(important_characters_info)}

# æ´»åŠ¨åœ°ç‚¹
{', '.join(selected_locations)}

# å‘¨æœŸåˆ†é…
å·²æ™ºèƒ½åˆ†é…ä¸º{len(cycles)}ä¸ªå‘¨æœŸï¼š
{json.dumps(cycles, ensure_ascii=False, indent=2)}

# èŠ‚å‡æ—¥ä¿¡æ¯
å½“å‰å‘¨æœŸå†…çš„èŠ‚å‡æ—¥ï¼š
{chr(10).join(cycle_holidays) if cycle_holidays else 'æ— ç‰¹æ®ŠèŠ‚å‡æ—¥'}

# è§„åˆ’è¦æ±‚

## æ•´ä½“æ•…äº‹å¼§çº¿
1. **æ—¶é—´è·¨åº¦æ„Ÿ**ï¼š{total_days}å¤©æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒé•¿çš„æ—¶é—´æ®µï¼Œéœ€è¦ä½“ç°æ—¶é—´çš„æ¨ç§»å’Œå˜åŒ–
2. **è§’è‰²å…³ç³»å‘å±•**ï¼šæ¯ä¸ªè§’è‰²çš„å…³ç³»åº”è¯¥æœ‰æ˜æ˜¾çš„å‘å±•è½¨è¿¹ï¼Œä¸æ˜¯é™æ€çš„
3. **äº‹ä»¶å±‚æ¬¡æ€§**ï¼šåŒ…å«æ—¥å¸¸äº‹ä»¶ã€é‡è¦äº‹ä»¶ã€è½¬æŠ˜äº‹ä»¶ç­‰ä¸åŒå±‚æ¬¡
4. **å­£èŠ‚å˜åŒ–**ï¼šä½“ç°å­£èŠ‚å¯¹æ´»åŠ¨å’Œå¿ƒæƒ…çš„å½±å“
5. **å·¥ä½œç”Ÿæ´»å¹³è¡¡**ï¼š{protagonist}çš„å­¦æœ¯å·¥ä½œä¸ä¸ªäººç”Ÿæ´»çš„å¹³è¡¡å‘å±•
6. **èŠ‚å‡æ—¥èå…¥**ï¼šåˆç†å®‰æ’èŠ‚å‡æ—¥æœŸé—´çš„ç‰¹æ®Šæ´»åŠ¨å’Œæ°›å›´ï¼Œä½“ç°ä¼ ç»Ÿæ–‡åŒ–å’Œç°ä»£ç”Ÿæ´»

## å‘¨æœŸç‰¹è‰²å·®å¼‚
1. **å‰æœŸå‘¨æœŸ**ï¼šå»ºç«‹æ—¥å¸¸èŠ‚å¥ã€åˆæ­¥å¼€å±•
2. **ä¸­æœŸå‘¨æœŸ**ï¼šæ·±å…¥å·¥ä½œã€å…³ç³»æ·±åŒ–ã€é¢ä¸´æŒ‘æˆ˜
3. **åæœŸå‘¨æœŸ**ï¼šæˆæœæ˜¾ç°ã€å…³ç³»ç¨³å®šã€æ–°çš„è§„åˆ’

## æ¯ä¸ªå‘¨æœŸè§„åˆ’å†…å®¹
ä¸ºæ¯ä¸ªå‘¨æœŸåˆ¶å®šï¼š
- **å‘¨æœŸä¸»é¢˜**ï¼šè¿™ä¸ªå‘¨æœŸçš„æ ¸å¿ƒä¸»é¢˜å’Œé‡ç‚¹
- **ä¸»è¦ç›®æ ‡**ï¼š{protagonist}åœ¨è¿™ä¸ªå‘¨æœŸæƒ³è¦è¾¾æˆçš„å…·ä½“ç›®æ ‡
- **é‡ç‚¹è§’è‰²**ï¼šä»æ‰€æœ‰å¯ç”¨è§’è‰²ä¸­é€‰æ‹©è¿™ä¸ªå‘¨æœŸä¼šé‡ç‚¹äº’åŠ¨çš„è§’è‰²ï¼ˆ2-4ä¸ªï¼‰ï¼Œå¯ä»¥è°ƒæ•´é¢„é€‰è§’è‰²
- **æ¬¡è¦è§’è‰²**ï¼šè¿™ä¸ªå‘¨æœŸä¸­ä¼šå¶å°”å‡ºç°çš„è§’è‰²ï¼ˆ1-3ä¸ªï¼‰
- **æ ¸å¿ƒåœ°ç‚¹**ï¼šä¸»è¦æ´»åŠ¨åœºæ‰€
- **å…³é”®äº‹ä»¶**ï¼šé¢„è®¡ä¼šå‘ç”Ÿçš„é‡è¦äº‹ä»¶
- **æƒ…æ„ŸåŸºè°ƒ**ï¼šæ•´ä¸ªå‘¨æœŸçš„æƒ…æ„Ÿå‘å±•æ–¹å‘
- **è¡”æ¥è¦ç‚¹**ï¼šä¸å‰åå‘¨æœŸçš„è¿æ¥ç‚¹

## è§’è‰²åˆ†é…åŸåˆ™
1. **é‡è¦è§’è‰²ä¼˜å…ˆ**ï¼šä»ä¸Šè¿°é‡è¦è§’è‰²ä¸­é€‰æ‹©2-4ä¸ªä½œä¸ºæœ¬å‘¨æœŸçš„é‡ç‚¹è§’è‰²
2. **å¹³è¡¡å‘å±•**ï¼šç¡®ä¿ä¸åŒå‘¨æœŸä¸­å„é‡è¦è§’è‰²éƒ½æœ‰æœºä¼šæˆä¸ºé‡ç‚¹
3. **å…³ç³»å‘å±•**ï¼šè€ƒè™‘è§’è‰²é—´çš„å…³ç³»å‘å±•éœ€è¦æ—¶é—´å’Œè¿ç»­æ€§
4. **ç”Ÿæ´»åŒ–è®¾å®š**ï¼šé¿å…å¤©æ–‡ã€æ˜Ÿç©ºç­‰ä¸»é¢˜ï¼Œé‡ç‚¹ä½“ç°äº‘æ¢å¸‚çš„æ—¥å¸¸ç”Ÿæ´»æ°”æ¯

# è¾“å‡ºæ ¼å¼
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºå‘¨æœŸè§„åˆ’ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼š

```json
{{
  "overall_plan": {{
    "total_days": {total_days},
    "total_cycles": {len(cycles)},
    "story_theme": "æ•´ä¸ªæ—¶é—´æ®µçš„æ•…äº‹ä¸»é¢˜",
    "character_arcs": {{
      "è§’è‰²å1": "è¯¥è§’è‰²çš„å‘å±•è½¨è¿¹",
      "è§’è‰²å2": "è¯¥è§’è‰²çš„å‘å±•è½¨è¿¹"
    }},
    "major_milestones": [
      "é‡è¦èŠ‚ç‚¹1",
      "é‡è¦èŠ‚ç‚¹2"
    ]
  }},
  "cycle_plans": [
    {{
      "cycle_number": 1,
      "start_date": "YYYY-MM-DD",
      "end_date": "YYYY-MM-DD", 
      "total_days": 7,
      "cycle_theme": "å‘¨æœŸä¸»é¢˜",
      "main_objectives": [
        "ç›®æ ‡1",
        "ç›®æ ‡2"
      ],
      "focus_characters": ["è§’è‰²å1", "è§’è‰²å2"],
      "secondary_characters": ["è§’è‰²å3", "è§’è‰²å4"],
      "core_locations": ["åœ°ç‚¹1", "åœ°ç‚¹2"],
      "key_events": [
        "äº‹ä»¶1",
        "äº‹ä»¶2"
      ],
      "emotional_tone": "æƒ…æ„ŸåŸºè°ƒæè¿°",
      "connection_points": {{
        "from_previous": "ä¸å‰å‘¨æœŸçš„è¡”æ¥",
        "to_next": "ä¸åå‘¨æœŸçš„è¡”æ¥"
      }}
    }},
    // ... å…¶ä»–å‘¨æœŸ
  ]
}}
```

# é‡è¦è¦æ±‚
1. **è¿è´¯æ€§**ï¼šç¡®ä¿å„å‘¨æœŸä¹‹é—´æœ‰è‡ªç„¶çš„è¿‡æ¸¡å’Œå‘å±•
2. **å¹³è¡¡æ€§**ï¼šè§’è‰²å’Œåœ°ç‚¹çš„åˆ†é…è¦ç›¸å¯¹å‡è¡¡
3. **ç°å®æ€§**ï¼šè§„åˆ’è¦ç¬¦åˆ{protagonist}çš„èº«ä»½å’Œäº‘æ¢å¸‚çš„è®¾å®š
4. **å‘å±•æ€§**ï¼šæ¯ä¸ªå‘¨æœŸéƒ½è¦æœ‰æ˜ç¡®çš„è¿›å±•ï¼Œé¿å…é‡å¤
5. **å®Œæ•´æ€§**ï¼šä¸ºæ‰€æœ‰{len(cycles)}ä¸ªå‘¨æœŸéƒ½åˆ¶å®šè¯¦ç»†è§„åˆ’

è¯·å¼€å§‹åˆ¶å®šè¿™ä¸ªå…¨é¢è€Œè¯¦ç»†çš„å‘¨æœŸè§„åˆ’ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚
"""
            
            # è°ƒç”¨LLMç”Ÿæˆå‘¨æœŸè§„åˆ’
            logger.info(f"å‘¨æœŸè§„åˆ’: å¼€å§‹LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(planning_prompt)}")
            
            if llm:
                # æ„å»ºæ¶ˆæ¯
                from core.types import Message, MessageRole
                message = Message(role=MessageRole.USER, content=planning_prompt)
                messages = [message]
                
                # æµå¼è°ƒç”¨LLMï¼ˆè±†åŒ…è‡ªå¸¦æ‰“å°ï¼‰
                final_content = ""
                
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True
                ):
                    content_part = chunk_data.get("content", "")
                    final_content += content_part
                
                logger.info(f"å‘¨æœŸè§„åˆ’ç”Ÿæˆå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
            else:
                raise Exception("LLMæœªåˆå§‹åŒ–")
            
            # è§£æJSONç»“æœ
            cycle_planning_data = None
            try:
                from parsers.json_parser import JSONParser
                parser = JSONParser()
                
                json_content = self._extract_json_from_content(final_content)
                parsed_result = parser.parse(json_content)
                
                if parsed_result and 'cycle_plans' in parsed_result:
                    cycle_planning_data = parsed_result
                    logger.info(f"æˆåŠŸè§£æå‘¨æœŸè§„åˆ’ï¼ŒåŒ…å« {len(cycle_planning_data['cycle_plans'])} ä¸ªå‘¨æœŸ")
                    
                    if workflow_chat:
                        await workflow_chat.add_node_message(
                            "å‘¨æœŸè§„åˆ’",
                            f"âœ… æˆåŠŸç”Ÿæˆ {len(cycle_planning_data['cycle_plans'])} ä¸ªå‘¨æœŸçš„è¯¦ç»†è§„åˆ’",
                            "success"
                        )
                else:
                    raise Exception("è§£æç»“æœä¸­ç¼ºå°‘cycle_planså­—æ®µ")
                    
            except Exception as parse_error:
                logger.error(f"å‘¨æœŸè§„åˆ’JSONè§£æå¤±è´¥: {parse_error}")
                # ä½¿ç”¨åŸå§‹åˆ†é…çš„å‘¨æœŸä½œä¸ºåå¤‡æ–¹æ¡ˆ
                cycle_planning_data = {
                    'overall_plan': {
                        'total_days': total_days,
                        'total_cycles': len(cycles),
                        'story_theme': f"{protagonist}çš„{total_days}å¤©ç”Ÿæ´»è§„åˆ’",
                        'character_arcs': {},
                        'major_milestones': []
                    },
                    'cycle_plans': cycles
                }
                
                if workflow_chat:
                    await workflow_chat.add_node_message(
                        "å‘¨æœŸè§„åˆ’",
                        f"âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å‘¨æœŸåˆ†é…ï¼ˆ{len(cycles)}ä¸ªå‘¨æœŸï¼‰",
                        "warning"
                    )
            
            # è¾“å‡ºæœ€ç»ˆç»“æœ
            output_data = input_data.copy()
            output_data['cycle_planning_result'] = cycle_planning_data
            output_data['cycles'] = cycle_planning_data['cycle_plans']
            output_data['current_cycle_index'] = 0  # å½“å‰å¤„ç†çš„å‘¨æœŸç´¢å¼•
            
            logger.info(f"âœ… å‘¨æœŸè§„åˆ’å®Œæˆï¼Œç”Ÿæˆäº† {len(cycle_planning_data['cycle_plans'])} ä¸ªå‘¨æœŸ")
            yield output_data
            
        except Exception as e:
            logger.error(f"å‘¨æœŸè§„åˆ’å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å‘¨æœŸè§„åˆ’",
                    f"âŒ è§„åˆ’å¤±è´¥: {str(e)}",
                    "error"
                )
            raise Exception(f"å‘¨æœŸè§„åˆ’å¤±è´¥: {str(e)}")
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()


class ScheduleGenerateNode(BaseNode):
    """æ—¥ç¨‹ç”ŸæˆèŠ‚ç‚¹ - åˆ†æ‰¹æ¸è¿›å¼ç”Ÿæˆï¼Œä¸€æ¬¡ç”Ÿæˆ3å¤©æ—¥ç¨‹"""
    
    def __init__(self):
        super().__init__(name="schedule_generate", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ—¥ç¨‹ç”ŸæˆèŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        # ä½¿ç”¨æµå¼æ‰§è¡Œå¹¶è¿”å›æœ€ç»ˆç»“æœ
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œæ—¥ç¨‹ç”ŸæˆèŠ‚ç‚¹ - åˆ†æ‰¹æ¸è¿›å¼ç”Ÿæˆ"""
        print("ğŸ“… å¼€å§‹åˆ†æ‰¹æ—¥ç¨‹ç”Ÿæˆ...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–å‘¨æœŸè§„åˆ’æ•°æ®
        cycles = input_data.get('cycles', [])
        current_cycle_index = input_data.get('current_cycle_index', 0)
        cycle_planning_result = input_data.get('cycle_planning_result', {})
        
        if not cycles:
            raise Exception("ç¼ºå°‘å‘¨æœŸè§„åˆ’æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œå‘¨æœŸè§„åˆ’èŠ‚ç‚¹")
        
        # è·å–å½“å‰å‘¨æœŸä¿¡æ¯
        if current_cycle_index >= len(cycles):
            # æ‰€æœ‰å‘¨æœŸéƒ½å·²å®Œæˆ
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    "âœ… æ‰€æœ‰å‘¨æœŸçš„æ—¥ç¨‹ç”Ÿæˆå·²å®Œæˆï¼",
                    "success"
                )
            
            output_data = input_data.copy()
            output_data['generation_complete'] = True
            yield output_data
            return
        
        current_cycle = cycles[current_cycle_index]
        cycle_start_date = current_cycle['start_date']
        cycle_end_date = current_cycle['end_date']
        cycle_total_days = current_cycle['total_days']
        
        # è·å–é…ç½®å‚æ•°
        protagonist = input_data.get('protagonist', 'æ–¹çŸ¥è¡¡')
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        holidays_data = input_data.get('holidays_data', {})
        include_holidays = input_data.get('include_holidays', True)
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "æ—¥ç¨‹ç”Ÿæˆ",
                f"æ­£åœ¨ç”Ÿæˆç¬¬ {current_cycle_index + 1}/{len(cycles)} ä¸ªå‘¨æœŸçš„æ—¥ç¨‹ ({cycle_start_date} - {cycle_end_date}, {cycle_total_days}å¤©)...",
                "progress"
            )
                    
        # è·å–å½“å‰å‘¨æœŸçš„è§„åˆ’ä¿¡æ¯
        current_cycle_plan = current_cycle.get('cycle_theme', '')
        current_cycle_objectives = current_cycle.get('main_objectives', [])
        focus_characters = current_cycle.get('focus_characters', [])
        core_locations = current_cycle.get('core_locations', [])
        key_events = current_cycle.get('key_events', [])
        emotional_tone = current_cycle.get('emotional_tone', '')
        
        # è·å–æœ€è¿‘4ä¸ª3å¤©æ‰¹æ¬¡çš„summaryä½œä¸ºå†å²è®°å½•
        recent_batch_summaries = await self._get_recent_batch_summaries(4, cycle_start_date)
        batch_history_context = ""
        if recent_batch_summaries:
            batch_history_context = f"## æœ€è¿‘æ‰¹æ¬¡å†å²è®°å½•\n{chr(10).join(recent_batch_summaries)}\n"
            logger.info(f"è·å–åˆ°æœ€è¿‘ {len(recent_batch_summaries)} ä¸ªæ‰¹æ¬¡çš„å†å²è®°å½•")
        
        # åˆ†æ‰¹ç”Ÿæˆï¼šå°†å‘¨æœŸåˆ†æˆ3å¤©ä¸€æ‰¹
        batch_size = 3  # æ¯æ¬¡ç”Ÿæˆ3å¤©
        cycle_daily_schedules = []  # å­˜å‚¨æ•´ä¸ªå‘¨æœŸçš„æ—¥ç¨‹
        current_batch_start = 0

        # å‡†å¤‡å½“å‰å‘¨æœŸçš„æ‰€æœ‰æ—¥æœŸä¿¡æ¯
        cycle_dates_info = []
        try:
            from datetime import datetime, timedelta
            
            # è§£æå‘¨æœŸæ—¥æœŸèŒƒå›´
            cycle_start = datetime.strptime(cycle_start_date, '%Y-%m-%d')
            cycle_end = datetime.strptime(cycle_end_date, '%Y-%m-%d')
            
            # è·å–å‘¨æœŸå†…çš„æ‰€æœ‰æ—¥æœŸä¿¡æ¯
            current_date = cycle_start
            day_number = 1
            while current_date <= cycle_end:
                date_str = current_date.strftime('%Y-%m-%d')
                weekday = current_date.weekday()
                weekday_name = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][weekday]
            
                # æ£€æŸ¥æ˜¯å¦èŠ‚å‡æ—¥
                is_holiday = False
                holiday_name = ""
                if include_holidays and date_str in holidays_data:
                    is_holiday = True
                    holiday_name = holidays_data[date_str]['name']
            
                # æ·»åŠ æ—¥æœŸä¿¡æ¯
                cycle_dates_info.append({
                    'date': date_str,
                    'weekday': weekday,
                    'weekday_name': weekday_name,
                    'is_holiday': is_holiday,
                    'holiday_name': holiday_name,
                    'day_number': day_number,  # å‘¨æœŸå†…çš„å¤©æ•°
                    'cycle_day_number': day_number
                })
                
                current_date += timedelta(days=1)
                day_number += 1
                
        except Exception as e:
            logger.error(f"å‘¨æœŸæ—¥æœŸå¤„ç†å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    f"å‘¨æœŸæ—¥æœŸå¤„ç†å¤±è´¥: {str(e)}",
                    "error"
                )
            raise Exception(f"å‘¨æœŸæ—¥æœŸå¤„ç†å¤±è´¥: {str(e)}")
            
        # åˆ†æ‰¹ç”Ÿæˆå½“å‰å‘¨æœŸçš„æ—¥ç¨‹
        while current_batch_start < len(cycle_dates_info):
            # ç¡®å®šå½“å‰æ‰¹æ¬¡çš„æ—¥æœŸèŒƒå›´
            batch_end = min(current_batch_start + batch_size, len(cycle_dates_info))
            batch_dates = cycle_dates_info[current_batch_start:batch_end]
            batch_days_count = len(batch_dates)
            
            batch_start_date = batch_dates[0]['date']
            batch_end_date = batch_dates[-1]['date']
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    f"æ­£åœ¨ç”Ÿæˆç¬¬ {current_batch_start//batch_size + 1} æ‰¹æ¬¡ï¼š{batch_start_date} - {batch_end_date} ({batch_days_count}å¤©)",
                    "progress"
                )
        
            # æ”¶é›†æ‰€æœ‰å¯ç”¨è§’è‰²ä¿¡æ¯ï¼ˆå®Œæ•´ä¿¡æ¯ï¼Œä¸çœç•¥ï¼‰
            char_list = input_data.get('characters_data', {}).get("è§’è‰²åˆ—è¡¨", {})
            
            # æ”¶é›†å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ç›¸å…³è§’è‰²
            all_batch_characters = []
            
            # 1. é‡ç‚¹è§’è‰²
            for char_name in focus_characters:
                if char_name in char_list:
                    all_batch_characters.append(char_name)
            
            # 2. æ¬¡è¦è§’è‰²
            secondary_characters = current_cycle.get('secondary_characters', [])
            for char_name in secondary_characters:
                if char_name in char_list and char_name not in all_batch_characters:
                    all_batch_characters.append(char_name)
            
            # 3. éšæœºæ·»åŠ ä¸€äº›å…¶ä»–è§’è‰²ä½œä¸ºæ”¯çº¿
            import random
            all_available_chars = list(char_list.keys())
            # ç§»é™¤ä¸»è§’å’Œå·²æ·»åŠ çš„è§’è‰²
            for remove_char in ['æ–¹çŸ¥è¡¡'] + all_batch_characters:
                if remove_char in all_available_chars:
                    all_available_chars.remove(remove_char)
            
            # éšæœºé€‰æ‹©ä¸€äº›å…¶ä»–è§’è‰²
            additional_chars = random.sample(all_available_chars, min(5, len(all_available_chars)))
            all_batch_characters.extend(additional_chars)
            
            # ç”Ÿæˆå®Œæ•´çš„è§’è‰²ä¿¡æ¯æè¿°
            all_characters_info = []
            for char_name in all_batch_characters:
                char_info = char_list[char_name]
                char_desc = f"{char_name}ï¼š{char_info.get('ç®€ä»‹', '')}"
                if char_info.get('æ€§æ ¼'):
                    char_desc += f"ï¼Œæ€§æ ¼{char_info.get('æ€§æ ¼')}"
                if char_info.get('å¹´é¾„'):
                    char_desc += f"ï¼Œå¹´é¾„{char_info.get('å¹´é¾„')}"
                if char_info.get('æ´»åŠ¨åœ°ç‚¹'):
                    char_desc += f"ï¼Œæ´»åŠ¨åœ°ç‚¹ï¼š{', '.join(char_info.get('æ´»åŠ¨åœ°ç‚¹', []))}"
                if char_info.get('èƒŒæ™¯æ•…äº‹'):
                    char_desc += f"ï¼ŒèƒŒæ™¯ï¼š{char_info.get('èƒŒæ™¯æ•…äº‹', '')[:100]}"
                all_characters_info.append(char_desc)
            
            # è·å–ä¸»è§’ä¿¡æ¯
            protagonist_data = input_data.get('protagonist_data', '')
            
            # æ„å»ºæ‰¹æ¬¡ç”Ÿæˆæç¤ºè¯
            generation_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ—¥ç¨‹è§„åˆ’å¸ˆå’Œæ•…äº‹ç¼–å‰§ï¼Œéœ€è¦ä¸ºä¸»è§’{protagonist}ç”Ÿæˆ{batch_start_date}åˆ°{batch_end_date}çš„è¯¦ç»†æ—¥ç¨‹å®‰æ’ï¼ˆå…±{batch_days_count}å¤©ï¼‰ã€‚

è¿™æ˜¯ä¸€ä¸ªåˆ†æ‰¹æ¸è¿›å¼ç”Ÿæˆä»»åŠ¡ï¼Œå½“å‰ç”Ÿæˆçš„æ˜¯ä¸€ä¸ªæ›´å¤§å‘¨æœŸä¸­çš„ä¸€éƒ¨åˆ†ã€‚

# ä¸»è§’ä¿¡æ¯
{protagonist_data}

{batch_history_context if batch_history_context else ''}

# å½“å‰å‘¨æœŸè§„åˆ’èƒŒæ™¯
## å‘¨æœŸä¿¡æ¯
- å‘¨æœŸæ—¥æœŸï¼š{cycle_start_date} è‡³ {cycle_end_date}ï¼ˆç¬¬{current_cycle_index + 1}ä¸ªå‘¨æœŸï¼Œå…±{len(cycles)}ä¸ªå‘¨æœŸï¼‰
- å‘¨æœŸä¸»é¢˜ï¼š{current_cycle_plan}
- æƒ…æ„ŸåŸºè°ƒï¼š{emotional_tone}

## å‘¨æœŸç›®æ ‡
{chr(10).join([f"- {obj}" for obj in current_cycle_objectives])}

## é‡ç‚¹è§’è‰²ï¼ˆæœ¬å‘¨æœŸï¼‰
{chr(10).join([f"- {char}" for char in focus_characters])}

## æ ¸å¿ƒåœ°ç‚¹ï¼ˆæœ¬å‘¨æœŸï¼‰
{chr(10).join([f"- {loc}" for loc in core_locations])}

## å…³é”®äº‹ä»¶ï¼ˆæœ¬å‘¨æœŸé¢„æœŸï¼‰
{chr(10).join([f"- {event}" for event in key_events])}

# å½“å‰æ‰¹æ¬¡ä»»åŠ¡
- æ‰¹æ¬¡æ—¥æœŸï¼š{batch_start_date} è‡³ {batch_end_date}
- æ‰¹æ¬¡å¤©æ•°ï¼š{batch_days_count}å¤©
- è¿™æ˜¯å½“å‰å‘¨æœŸçš„ç¬¬ {current_batch_start//batch_size + 1} ä¸ªæ‰¹æ¬¡
- æ¯å¤©åˆ’åˆ†ä¸º5ä¸ªæ—¶é—´æ®µï¼šå¤œé—´(23:00-06:00)ã€ä¸Šåˆ(06:00-11:00)ã€ä¸­åˆ(11:00-14:00)ã€ä¸‹åˆ(14:00-18:00)ã€æ™šä¸Š(18:00-23:00)

# å¯ç”¨è§’è‰²ä¿¡æ¯
{chr(10).join(all_characters_info)}

# å¯ç”¨åœ°ç‚¹
{', '.join(selected_locations)}

# æ‰¹æ¬¡æ—¥æœŸä¿¡æ¯
{json.dumps(batch_dates, ensure_ascii=False, indent=2)}

# æ ¸å¿ƒç”Ÿæˆè¦æ±‚

## åˆ†æ‰¹ç”Ÿæˆè¿è´¯æ€§
1. **æ‰¹æ¬¡è¡”æ¥**ï¼šè™½ç„¶åªç”Ÿæˆ{batch_days_count}å¤©ï¼Œä½†è¦ä¸å‰åæ‰¹æ¬¡è‡ªç„¶è¡”æ¥
2. **å‘¨æœŸç›®æ ‡æ¨è¿›**ï¼šåœ¨è¿™{batch_days_count}å¤©ä¸­æ¨è¿›å½“å‰å‘¨æœŸçš„ç›®æ ‡å’Œä¸»é¢˜
3. **é‡ç‚¹è§’è‰²ä¼˜å…ˆ**ï¼šä¼˜å…ˆå®‰æ’é‡ç‚¹è§’è‰²çš„äº’åŠ¨ï¼Œå…¶ä»–è§’è‰²æ ¹æ®æƒ…å†µç©¿æ’

## äº‘æ¢å¸‚çœŸå®ç”Ÿæ´»æ„Ÿ
1. **æ—¥å¸¸éšæœºäº‹ä»¶**ï¼šå¶é‡ç†Ÿäººã€å‘ç°æ–°åº—é“ºã€å°æ„å¤–ã€å¤©æ°”å˜åŒ–ç­‰ç”Ÿæ´»åŒ–å…ƒç´ 
2. **åŸå¸‚ç”Ÿæ´»ç»†èŠ‚**ï¼šè¡—è¾¹å°åº—ã€å’–å•¡é¦†ã€å…¬å›­æ•£æ­¥ã€èœå¸‚åœºã€å…¬äº¤åœ°é“ã€ç¤¾åŒºæ´»åŠ¨ç­‰
3. **å­£èŠ‚èŠ‚æ—¥æ°›å›´**ï¼šæ ¹æ®å­£èŠ‚å’ŒèŠ‚å‡æ—¥å®‰æ’åº”æ™¯çš„æ´»åŠ¨å’Œæ°›å›´
4. **ç”Ÿæ´»åŒ–äº’åŠ¨**ï¼šè´­ç‰©ã€ç”¨é¤ã€ä¼‘é—²å¨±ä¹ã€è¿åŠ¨å¥èº«ã€è¯»ä¹¦å­¦ä¹ ç­‰æ—¥å¸¸æ´»åŠ¨
5. **é¿å…è®¾å®š**ï¼šä¸¥ç¦æ¶‰åŠå¤©æ–‡ã€æ˜Ÿç©ºã€å®‡å®™ç­‰ä¸»é¢˜ï¼Œé‡ç‚¹çªå‡ºéƒ½å¸‚ç”Ÿæ´»çš„çƒŸç«æ°”

## æ•…äº‹æ€§è¦æ±‚
1. **æƒ…æ„Ÿæ¨è¿›**ï¼šæ¯ä¸ªè§’è‰²çš„å‡ºç°éƒ½åº”è¯¥æœ‰å…³ç³»å‘å±•ï¼Œæ¨è¿›å‘¨æœŸä¸»é¢˜
2. **ç»†èŠ‚ä¸°å¯Œåº¦**ï¼šæ¯ä¸ªæ—¶é—´æ®µçš„æè¿°åŒ…å«å…·ä½“çš„å¯¹è¯ç‰‡æ®µã€å†…å¿ƒæ´»åŠ¨ã€ç¯å¢ƒæå†™
3. **äº‹ä»¶è¿è´¯æ€§**ï¼šå½“å‰æ‰¹æ¬¡å†…çš„äº‹ä»¶è¦ç›¸äº’å‘¼åº”ï¼Œå½¢æˆå®Œæ•´çš„æ•…äº‹ç‰‡æ®µ
4. **ç”Ÿæ´»çœŸå®æ„Ÿ**ï¼šåŒ…å«å·¥ä½œå‹åŠ›ã€æƒ…ç»ªæ³¢åŠ¨ã€å°ç¡®å¹¸ã€æ„å¤–æƒŠå–œç­‰çœŸå®å…ƒç´ 

## è®¡åˆ’ä¸æ€»ç»“çš„åŒºåˆ«
- **æ¯æ—¥è®¡åˆ’(daily_plan)**ï¼š{protagonist}å¯¹è¿™ä¸€å¤©çš„é¢„æœŸå’Œå®‰æ’ï¼ŒåŸºäºä»–ç°æœ‰çš„ä¿¡æ¯å’Œç»éªŒ
- **æ¯æ—¥æ€»ç»“(daily_summary)**ï¼šä¸€å¤©ç»“æŸåå¯¹å®é™…å‘ç”Ÿäº‹ä»¶çš„å›é¡¾ï¼Œå¯èƒ½ä¸è®¡åˆ’æœ‰å‡ºå…¥ï¼ŒåŒ…å«æ„å¤–å’ŒæƒŠå–œ
- **æ‰¹æ¬¡æ€»ç»“(batch_summary)**ï¼š{batch_days_count}å¤©ç»“æŸåçš„é˜¶æ®µæ€§æ€»ç»“ï¼Œå…³æ³¨è¿™å‡ å¤©çš„é‡è¦å‘å±•

## æ—¶é—´æ®µå†…å®¹è¦æ±‚
1. **å¤œé—´(23:00-06:00)**ï¼šä¼‘æ¯ã€æ¢¦å¢ƒã€æ·±å¤œæ€è€ƒï¼Œå¶å°”æœ‰ç‰¹æ®Šæƒ…å†µ
2. **ä¸Šåˆ(06:00-11:00)**ï¼šå·¥ä½œã€ç ”ç©¶ã€é‡è¦ä¼šè®®ï¼Œç²¾ç¥çŠ¶æ€æœ€ä½³çš„æ—¶æ®µ
3. **ä¸­åˆ(11:00-14:00)**ï¼šç”¨é¤ã€è½»æ¾ç¤¾äº¤ã€çŸ­æš‚ä¼‘æ¯
4. **ä¸‹åˆ(14:00-18:00)**ï¼šç»§ç»­å·¥ä½œã€å®åœ°è€ƒå¯Ÿã€å­¦æœ¯æ´»åŠ¨
5. **æ™šä¸Š(18:00-23:00)**ï¼šç¤¾äº¤æ´»åŠ¨ã€å¨±ä¹ã€ä¸ªäººæ—¶é—´ã€æ·±åº¦äº¤æµ

## è§’è‰²å®‰æ’åŸåˆ™
1. **è‡ªç„¶åˆ†å¸ƒ**ï¼šæ ¹æ®ç”Ÿæ´»é€»è¾‘å’Œæ•…äº‹éœ€è¦å®‰æ’è§’è‰²å‡ºç°ï¼Œä¸å¼ºåˆ¶ç‰¹å®šé¢‘ç‡
2. **ç”Ÿæ´»åŒ–äº’åŠ¨**ï¼šæ‰€æœ‰è§’è‰²äº’åŠ¨éƒ½è¦è´´è¿‘æ—¥å¸¸ç”Ÿæ´»ï¼Œé¿å…ä¸åˆ‡å®é™…çš„æƒ…èŠ‚
3. **äº’åŠ¨æ·±åº¦**ï¼šæ¯æ¬¡äº’åŠ¨éƒ½è¦æœ‰å…·ä½“çš„å¯¹è¯å†…å®¹å’Œæƒ…æ„Ÿå˜åŒ–
4. **å…³ç³»å‘å±•**ï¼šè§’è‰²é—´çš„å…³ç³»åº”è¯¥éšæ—¶é—´æ¨è¿›è€Œå‘å±•å˜åŒ–
5. **éšæœºå¶é‡**ï¼šå¢åŠ æ„å¤–ç¢°é¢ã€å·§åˆäº‹ä»¶ç­‰çœŸå®ç”Ÿæ´»å…ƒç´ 
6. **å†å²è¿è´¯**ï¼šå‚è€ƒæ‰¹æ¬¡å†å²ï¼Œç¡®ä¿è§’è‰²å…³ç³»å’Œæ•…äº‹å‘å±•çš„è¿è´¯æ€§

## ç‹¬ç«‹æ•…äº‹è¦æ±‚
1. **æ—¶é—´æ®µæ•…äº‹ç‹¬ç«‹æ€§**ï¼šæ¯ä¸ªæ—¶é—´æ®µçš„æ•…äº‹å†…å®¹å¿…é¡»æ˜¯ç‹¬ç«‹å®Œæ•´çš„ï¼Œèƒ½å¤Ÿå•ç‹¬é˜…è¯»ç†è§£
2. **å‰å› åæœæ¸…æ™°**ï¼šå³ä½¿æ˜¯ç‹¬ç«‹çš„æ—¶é—´æ®µæ•…äº‹ï¼Œä¹Ÿè¦æè¿°æ¸…æ¥šäº‹ä»¶çš„å‰å› åæœ
3. **æƒ…å¢ƒå®Œæ•´æ€§**ï¼šåŒ…å«æ˜ç¡®çš„åœºæ™¯ã€äººç‰©ã€å¯¹è¯å’Œæƒ…æ„Ÿæè¿°ï¼Œä¿è¯å†…å®¹çš„å®Œæ•´æ€§
4. **ç‹¬ç«‹å™äº‹**ï¼šæ¯ä¸ªæ—¶é—´æ®µå†…å®¹å¯èƒ½è¢«å•ç‹¬æå–ä½¿ç”¨ï¼Œå› æ­¤å¿…é¡»æ˜¯è‡ªåŒ…å«çš„å®Œæ•´æ•…äº‹
5. **ä¸Šä¸‹æ–‡è¿è´¯**ï¼šè™½ç„¶æ˜¯ç‹¬ç«‹çš„ï¼Œä½†å„æ—¶é—´æ®µä¹‹é—´åº”è¯¥æœ‰è¿è´¯çš„å…³ç³»ï¼Œå½¢æˆæ—¥å¸¸ç”Ÿæ´»çš„å®Œæ•´ç”»é¢

# è¾“å‡ºæ ¼å¼
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºæ‰¹æ¬¡æ—¥ç¨‹å®‰æ’ï¼š

```json
{{
  "batch_info": {{
    "æ‰¹æ¬¡å¤©æ•°": {batch_days_count},
    "æ‰¹æ¬¡å¼€å§‹æ—¥æœŸ": "{batch_start_date}",
    "æ‰¹æ¬¡ç»“æŸæ—¥æœŸ": "{batch_end_date}",
    "æ‰€å±å‘¨æœŸ": {current_cycle_index + 1},
    "å‘¨æœŸä¸»é¢˜": "{current_cycle_plan}",
    "æ‰¹æ¬¡ç‰¹ç‚¹": "æè¿°è¿™{batch_days_count}å¤©çš„ä¸»è¦ç‰¹è‰²å’Œæ•…äº‹å‘å±•",
    "é‡ç‚¹è§’è‰²": {focus_characters},
    "ä¸»è¦åœ°ç‚¹": {core_locations}
  }},

  "daily_schedules": [
    {{
      "date": "YYYY-MM-DD",
      "day_number": 1,
      "weekday_name": "å‘¨å‡ ",
      "is_holiday": true/false,
      "holiday_name": "èŠ‚æ—¥åç§°ï¼ˆå¦‚æœæ˜¯èŠ‚å‡æ—¥ï¼‰",
      "weather": "å¤©æ°”æƒ…å†µ",
      "daily_plan": "{protagonist}æ—©æ™¨å¯¹è¿™ä¸€å¤©çš„è®¡åˆ’å’ŒæœŸæœ›ï¼ŒåŸºäºä»–ç°æœ‰çš„è®¤çŸ¥ï¼Œç¬¬ä¸‰äººç§°æè¿°ï¼Œ250å­—ä»¥å†…",
      "daily_involved_characters": ["è§’è‰²å1", "è§’è‰²å2", "è§’è‰²å3"],
      "time_slots": [
        {{
          "slot_name": "å¤œé—´",
          "location": "å…·ä½“åœ°ç‚¹",
          "story_content": "è¯¦ç»†çš„ç¬¬ä¸‰äººç§°æ•…äº‹æè¿°ï¼Œæ–¹çŸ¥è¡¡ä¸ºä¸»ä½“ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨ï¼Œç¯å¢ƒï¼Œäº‹ä»¶ï¼Œå‰§æƒ…æè¿°ä¸ºä¸»ï¼Œå°‘é‡å¯¹è¯ï¼Œ200-300å­—ã€‚å†…å®¹å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œæè¿°æ¸…æ¥šå‰å› åæœï¼Œå³ä½¿å•ç‹¬é˜…è¯»ä¹Ÿèƒ½ç†è§£ã€‚",
          "involved_characters": ["è§’è‰²å1", "è§’è‰²å2"]
        }},
        {{
          "slot_name": "ä¸Šåˆ",
          "location": "å…·ä½“åœ°ç‚¹",
          "story_content": "è¯¦ç»†çš„ç¬¬ä¸‰äººç§°æ•…äº‹æè¿°ï¼Œæ–¹çŸ¥è¡¡ä¸ºä¸»ä½“ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨ï¼Œç¯å¢ƒï¼Œäº‹ä»¶ï¼Œå‰§æƒ…æè¿°ä¸ºä¸»ï¼Œå°‘é‡å¯¹è¯ï¼Œ200-300å­—ã€‚å†…å®¹å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œæè¿°æ¸…æ¥šå‰å› åæœï¼Œå³ä½¿å•ç‹¬é˜…è¯»ä¹Ÿèƒ½ç†è§£ã€‚",
          "involved_characters": ["è§’è‰²å1", "è§’è‰²å2"]
        }},
        {{
          "slot_name": "ä¸­åˆ",
          "location": "å…·ä½“åœ°ç‚¹",
          "story_content": "è¯¦ç»†çš„ç¬¬ä¸‰äººç§°æ•…äº‹æè¿°ï¼Œæ–¹çŸ¥è¡¡ä¸ºä¸»ä½“ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨ï¼Œç¯å¢ƒï¼Œäº‹ä»¶ï¼Œå‰§æƒ…æè¿°ä¸ºä¸»ï¼Œå°‘é‡å¯¹è¯ï¼Œ200-300å­—ã€‚å†…å®¹å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œæè¿°æ¸…æ¥šå‰å› åæœï¼Œå³ä½¿å•ç‹¬é˜…è¯»ä¹Ÿèƒ½ç†è§£ã€‚",
          "involved_characters": ["è§’è‰²å1", "å°åŠ¨ç‰©åç­‰"]
        }},
        {{
          "slot_name": "ä¸‹åˆ",
          "location": "å…·ä½“åœ°ç‚¹",
          "story_content": "è¯¦ç»†çš„ç¬¬ä¸‰äººç§°æ•…äº‹æè¿°ï¼Œæ–¹çŸ¥è¡¡ä¸ºä¸»ä½“ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨ï¼Œç¯å¢ƒï¼Œäº‹ä»¶ï¼Œå‰§æƒ…æè¿°ä¸ºä¸»ï¼Œå°‘é‡å¯¹è¯ï¼Œ200-300å­—ã€‚å†…å®¹å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œæè¿°æ¸…æ¥šå‰å› åæœï¼Œå³ä½¿å•ç‹¬é˜…è¯»ä¹Ÿèƒ½ç†è§£ã€‚",
          "involved_characters": ["è§’è‰²å1", "è§’è‰²å2"]
        }},
        {{
          "slot_name": "æ™šä¸Š",
          "location": "å…·ä½“åœ°ç‚¹",
          "story_content": "è¯¦ç»†çš„ç¬¬ä¸‰äººç§°æ•…äº‹æè¿°ï¼Œæ–¹çŸ¥è¡¡ä¸ºä¸»ä½“ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨ï¼Œç¯å¢ƒï¼Œäº‹ä»¶ï¼Œå‰§æƒ…æè¿°ä¸ºä¸»ï¼Œå°‘é‡å¯¹è¯ï¼Œ200-300å­—ã€‚å†…å®¹å¿…é¡»ç‹¬ç«‹å®Œæ•´ï¼Œæè¿°æ¸…æ¥šå‰å› åæœï¼Œå³ä½¿å•ç‹¬é˜…è¯»ä¹Ÿèƒ½ç†è§£ã€‚",
          "involved_characters": ["è§’è‰²å1", "è§’è‰²å2"]
        }}
      ],
      "daily_summary": "ç¬¬ä¸‰äººç§°ï¼Œè§’è‰²ä½œä¸ºä¸»ä½“ï¼Œä¸€å¤©ç»“æŸæ—¶å¯¹å®é™…å‘ç”Ÿäº‹ä»¶çš„æ€»ç»“ï¼Œ200-300å­—",

    }},
    // ... å…¶ä»–æ—¥æœŸ
  ],
  "batch_summary": "æ‰¹æ¬¡æ€»ç»“ï¼šè¿™{batch_days_count}å¤©çš„é‡è¦å‘å±•å’Œå˜åŒ–ï¼Œç¬¬ä¸‰äººç§°ä»¥ä¸»è§’ä¸ºä¸»ä½“ï¼Œ200-300å­—ï¼Œé‡ç‚¹å…³æ³¨ï¼š1. å‘¨æœŸç›®æ ‡çš„æ¨è¿›æƒ…å†µ 2. é‡ç‚¹è§’è‰²å…³ç³»çš„å‘å±• 3. å…³é”®äº‹ä»¶çš„è¿›å±• 4. æƒ…æ„ŸçŠ¶æ€çš„å˜åŒ– 5. ä¸ºä¸‹ä¸ªæ‰¹æ¬¡çš„é“ºå«",
}}
```

# é‡è¦æé†’
1. **åˆ†æ‰¹ç”Ÿæˆè¦æ±‚**ï¼š
   - åªç”Ÿæˆ{batch_days_count}å¤©çš„æ—¥ç¨‹ï¼Œä¸è¦ç”Ÿæˆæ•´ä¸ªå‘¨æœŸ
   - è¦ä½“ç°å‘¨æœŸè§„åˆ’çš„ä¸»é¢˜å’Œç›®æ ‡ï¼Œä½†é‡ç‚¹æ˜¯å½“å‰æ‰¹æ¬¡
   - è¦ä¸ºåç»­æ‰¹æ¬¡ç•™ä¸‹è‡ªç„¶çš„è¡”æ¥ç‚¹

2. **æ•°æ®å®Œæ•´æ€§è¦æ±‚**ï¼š
   - daily_planï¼šæ¯å¤©éƒ½è¦æœ‰å…·ä½“çš„æ—©æ™¨è®¡åˆ’
   - daily_involved_charactersï¼šå¿…é¡»åˆ—å‡ºå½“å¤©æ‰€æœ‰å‡ºç°çš„æœ‰é…ç½®çš„è§’è‰²åç§°
   - æ¯å¤©å¿…é¡»æœ‰5ä¸ªå®Œæ•´çš„æ—¶é—´æ®µï¼ˆå¤œé—´ã€ä¸Šåˆã€ä¸­åˆã€ä¸‹åˆã€æ™šä¸Šï¼‰
   - involved_charactersï¼šæ¯ä¸ªæ—¶é—´æ®µéƒ½è¦æ˜ç¡®åˆ—å‡ºæ¶‰åŠçš„è§’è‰²åç§°åˆ—è¡¨
   - batch_summaryï¼šå¿…é¡»åŒ…å«è¿™{batch_days_count}å¤©çš„é˜¶æ®µæ€§æ€»ç»“

3. **æ•…äº‹è´¨é‡è¦æ±‚**ï¼š
   - æ¯ä¸ªæ—¶é—´æ®µçš„story_contentå¿…é¡»ä¸°å¯Œè¯¦å®ï¼Œåƒå°è¯´ç‰‡æ®µä¸€æ ·ç”ŸåŠ¨
   - å„æ—¶é—´æ®µçš„æ•…äº‹å¿…é¡»æ˜¯ç‹¬ç«‹å®Œæ•´çš„ï¼Œèƒ½å¤Ÿè¢«å•ç‹¬æå–å’Œç†è§£
   - è§’è‰²å¯¹è¯è¦ç¬¦åˆå„è‡ªçš„æ€§æ ¼ç‰¹ç‚¹ï¼Œæœ‰çœŸå®æ„Ÿ
   - å¢åŠ éšæœºäº‹ä»¶ï¼šæ„å¤–å‘ç°ã€å·§é‡ç­‰äº‘æ¢å¸‚ç”Ÿæ´»ç»†èŠ‚
   - æƒ…èŠ‚è¦æœ‰èµ·ä¼ï¼ŒåŒ…å«å·¥ä½œå‹åŠ›ã€å°ç¡®å¹¸ã€æ„å¤–æƒŠå–œç­‰çœŸå®å…ƒç´ 
   - ç¦æ­¢æœ‰ä»»ä½•ç”·å¥³æ‹çˆ±å…ƒç´ 
   - ä¸¥ç¦æ¶‰åŠå¤©æ–‡ã€æ˜Ÿç©ºã€å®‡å®™ç­‰ä¸»é¢˜ï¼Œä¸»è§’æ˜¯æ™®é€šäººï¼Œè¿‡æ™®é€šçš„éƒ½å¸‚ç”Ÿæ´»
   - é‡ç‚¹ä½“ç°äº‘æ¢å¸‚çš„ç”Ÿæ´»æ°”æ¯ï¼šç¾é£Ÿã€è´­ç‰©ã€å¨±ä¹ã€ç¤¾äº¤ã€æ–‡åŒ–ç­‰

4. **è§’è‰²å¤„ç†è¦æ±‚**ï¼š
   - é‡ç‚¹è§’è‰²è¦å¤šå®‰æ’ï¼Œä½“ç°å‘¨æœŸä¸»é¢˜
   - å…¶ä»–è§’è‰²æ ¹æ®ç”Ÿæ´»é€»è¾‘è‡ªç„¶å‡ºç°
   - å¯ä»¥åˆ›é€ ä¸´æ—¶è§’è‰²ï¼ˆå¦‚åº—ä¸»ã€è·¯äººã€å°åŠ¨ç‰©ï¼‰å¢åŠ çœŸå®æ„Ÿ
   - involved_charactersä¸­åªéœ€åˆ—å‡ºè§’è‰²åç§°ï¼Œä¸éœ€è¦æè¿°

5. **æŠ€æœ¯è¦æ±‚**ï¼š
   - ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ï¼Œå¯ä»¥è¢«ç¨‹åºè§£æ
   - æ¯ä¸ªå­—æ®µéƒ½è¦å¡«å†™å®Œæ•´ï¼Œä¸èƒ½ä¸ºç©º
   - å…³æ³¨batch_summaryå­—æ®µï¼Œå®ƒæ˜¯æœ¬æ‰¹æ¬¡çš„é‡è¦æ€»ç»“

è¯·å¼€å§‹ç”Ÿæˆè¿™{batch_days_count}å¤©å……æ»¡äº‘æ¢å¸‚ç”Ÿæ´»çœŸå®æ„Ÿçš„è¯¦ç»†æ—¥ç¨‹å®‰æ’ã€‚
"""
        
            # è°ƒç”¨LLMç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„æ—¥ç¨‹
            if llm:
                try:
                    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                    from core.types import Message, MessageRole
                    message = Message(role=MessageRole.USER, content=generation_prompt)
                    messages = [message]
                    
                    logger.info(f"æ—¥ç¨‹ç”Ÿæˆæ‰¹æ¬¡ {current_batch_start//batch_size + 1}: å¼€å§‹LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(generation_prompt)}")
                    
                    # æµå¼è°ƒç”¨LLMï¼ˆè±†åŒ…è‡ªå¸¦æ‰“å°ï¼‰
                    final_content = ""
                    
                    async for chunk_data in llm.stream_generate(
                        messages, 
                        mode="think",
                        return_dict=True
                    ):
                        content_part = chunk_data.get("content", "")
                        final_content += content_part
                        
                    logger.info(f"æ‰¹æ¬¡ {current_batch_start//batch_size + 1} LLMç”Ÿæˆå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                            
                except Exception as e:
                    error_msg = f"æ‰¹æ¬¡ {current_batch_start//batch_size + 1} LLMè°ƒç”¨å¤±è´¥: {str(e)}"
                    logger.error(error_msg, exc_info=True)
                    raise Exception(error_msg)
            else:
                raise Exception("LLMæœªåˆå§‹åŒ–")
                
            # è§£æå½“å‰æ‰¹æ¬¡çš„JSONç»“æœ
            batch_data = None
            try:
                json_content = self._extract_json_from_content(final_content)
                from parsers.json_parser import JSONParser
                parser = JSONParser()
                parsed_result = parser.parse(json_content)
                
                if parsed_result and 'daily_schedules' in parsed_result:
                    batch_data = parsed_result
                    batch_daily_schedules = batch_data.get('daily_schedules', [])
                    logger.info(f"æ‰¹æ¬¡ {current_batch_start//batch_size + 1} æˆåŠŸè§£æï¼ŒåŒ…å« {len(batch_daily_schedules)} å¤©")
                    
                    # åˆå¹¶åˆ°å‘¨æœŸæ—¥ç¨‹ä¸­
                    cycle_daily_schedules.extend(batch_daily_schedules)
                    
                    if workflow_chat:
                        await workflow_chat.add_node_message(
                            "æ—¥ç¨‹ç”Ÿæˆ",
                            f"âœ… æ‰¹æ¬¡ {current_batch_start//batch_size + 1} ç”Ÿæˆå®Œæˆï¼ˆ{len(batch_daily_schedules)}å¤©ï¼‰",
                            "success"
                        )
                else:
                    raise Exception(f"æ‰¹æ¬¡è§£æå¤±è´¥ï¼šç¼ºå°‘daily_scheduleså­—æ®µ")
                    
            except Exception as parse_error:
                logger.error(f"æ‰¹æ¬¡ {current_batch_start//batch_size + 1} JSONè§£æå¤±è´¥: {parse_error}")
                if workflow_chat:
                    await workflow_chat.add_node_message(
                        "æ—¥ç¨‹ç”Ÿæˆ",
                        f"âš ï¸ æ‰¹æ¬¡ {current_batch_start//batch_size + 1} è§£æå¤±è´¥ï¼Œè·³è¿‡",
                        "warning"
                    )
            
            # æ›´æ–°æ‰¹æ¬¡è¿›åº¦
            current_batch_start += batch_size
            
            # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯
            await asyncio.sleep(1)
                
        # å½“å‰å‘¨æœŸæ‰€æœ‰æ‰¹æ¬¡ç”Ÿæˆå®Œæˆï¼Œæ„å»ºå‘¨æœŸç»“æœ
        if cycle_daily_schedules:
            # ç”Ÿæˆå‘¨æœŸæ€»ç»“
            cycle_summary = await self._generate_cycle_summary(
                current_cycle, cycle_daily_schedules, llm, workflow_chat
            )
            
            # æ„å»ºå‘¨æœŸå®Œæ•´æ•°æ®
            schedule_data = {
                'cycle_info': {
                    'cycle_number': current_cycle_index + 1,
                    'start_date': cycle_start_date,
                    'end_date': cycle_end_date,
                    'total_days': cycle_total_days,
                    'cycle_theme': current_cycle_plan,
                    'focus_characters': focus_characters,
                    'core_locations': core_locations
                },
                'daily_schedules': cycle_daily_schedules,
                'cycle_summary': cycle_summary
            }
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    f"âœ… ç¬¬ {current_cycle_index + 1} ä¸ªå‘¨æœŸç”Ÿæˆå®Œæˆï¼å…± {len(cycle_daily_schedules)} å¤©ï¼Œ{len(cycle_daily_schedules)//batch_size + (1 if len(cycle_daily_schedules)%batch_size else 0)} ä¸ªæ‰¹æ¬¡",
                    "success"
                )
        else:
            # æ²¡æœ‰ç”Ÿæˆä»»ä½•æ—¥ç¨‹
            schedule_data = {"error": "å‘¨æœŸå†…æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•æ—¥ç¨‹"}
            logger.error("å‘¨æœŸå†…æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•æ—¥ç¨‹")
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    "âŒ å½“å‰å‘¨æœŸç”Ÿæˆå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸçš„æ‰¹æ¬¡",
                    "error"
                )
        
        # æ›´æ–°è¾“å‡ºæ•°æ®
        output_data = input_data.copy()
        output_data['schedule_result'] = schedule_data
        output_data['daily_schedules'] = cycle_daily_schedules
        output_data['current_cycle_index'] = current_cycle_index + 1  # æŒ‡å‘ä¸‹ä¸€ä¸ªå‘¨æœŸ
        
        print(f"âœ… å‘¨æœŸ {current_cycle_index + 1} æ—¥ç¨‹ç”Ÿæˆå®Œæˆ")
        yield output_data
        
    async def _get_recent_batch_summaries(self, count: int, before_date: str) -> List[str]:
        """è·å–æœ€è¿‘countä¸ªæ‰¹æ¬¡çš„summaryä½œä¸ºå†å²è®°å½•"""
        try:
            from database.managers.schedule_manager import ScheduleManager
            from datetime import datetime, timedelta
            
            schedule_manager = ScheduleManager()
            summaries = []
            
            # è·å–æœ€è¿‘çš„æ—¥ç¨‹è®°å½•
            recent_schedules = schedule_manager.get_schedules_by_filter({}, limit=20)
            
            # ç­›é€‰åœ¨before_dateä¹‹å‰çš„è®°å½•ï¼Œå¹¶æŒ‰æ—¥æœŸæ’åº
            valid_schedules = []
            before_dt = datetime.strptime(before_date, '%Y-%m-%d')
            
            for schedule in recent_schedules:
                try:
                    schedule_end_date = schedule.get('end_date', '')
                    if schedule_end_date:
                        schedule_end_dt = datetime.strptime(schedule_end_date, '%Y-%m-%d')
                        if schedule_end_dt < before_dt:
                            valid_schedules.append(schedule)
                except:
                    continue
            
            # æŒ‰ç»“æŸæ—¥æœŸå€’åºæ’åºï¼Œè·å–æœ€æ–°çš„è®°å½•
            valid_schedules.sort(key=lambda x: x.get('end_date', ''), reverse=True)
            
            # æå–æœ€è¿‘countä¸ªæ‰¹æ¬¡çš„summary
            for schedule in valid_schedules[:count]:
                daily_schedules = schedule.get('daily_schedules', [])
                if daily_schedules:
                    # æŒ‰3å¤©ä¸€ç»„åˆ›å»ºæ‰¹æ¬¡summary
                    batch_size = 3
                    batch_summaries = []
                    
                    for i in range(0, len(daily_schedules), batch_size):
                        batch_days = daily_schedules[i:i + batch_size]
                        if batch_days:
                            batch_start = batch_days[0].get('date', '')
                            batch_end = batch_days[-1].get('date', '')
                            
                            # æå–æ‰¹æ¬¡å…³é”®ä¿¡æ¯
                            key_events = []
                            involved_chars = set()
                            
                            for day in batch_days:
                                # æ£€æŸ¥æ˜¯å¦æœ‰batch_summaryå­—æ®µ
                                daily_summary = day.get('daily_summary', '')
                                if daily_summary:
                                    key_events.append(f"{day.get('date', '')}: {daily_summary[:100]}")
                                
                                # æ”¶é›†æ¶‰åŠçš„è§’è‰²
                                daily_chars = day.get('daily_involved_characters', [])
                                involved_chars.update(daily_chars)
                                
                                # ä»æ—¶é—´æ®µä¸­æå–äº‹ä»¶
                                for slot in day.get('time_slots', []):
                                    content = slot.get('story_content', '')
                                    if len(content) > 150:  # é€‰æ‹©å†…å®¹ä¸°å¯Œçš„äº‹ä»¶
                                        key_events.append(f"{day.get('date', '')} {slot.get('slot_name', '')}: {content[:80]}...")
                                    slot_chars = slot.get('involved_characters', [])
                                    involved_chars.update(slot_chars)
                            
                            # æ„å»ºæ‰¹æ¬¡æ‘˜è¦
                            char_summary = ', '.join(list(involved_chars)[:4]) if involved_chars else 'æ— ç‰¹å®šè§’è‰²'
                            event_summary = '; '.join(key_events[:2]) if key_events else 'æ—¥å¸¸æ´»åŠ¨'
                            
                            batch_summary = f"**{batch_start}è‡³{batch_end}ï¼ˆ{len(batch_days)}å¤©ï¼‰**ï¼šä¸»è¦è§’è‰²{char_summary}ï¼Œå…³é”®äº‹ä»¶ï¼š{event_summary}"
                            batch_summaries.append(batch_summary)
                    
                    # åªå–æœ€è¿‘çš„å‡ ä¸ªæ‰¹æ¬¡
                    summaries.extend(batch_summaries[-2:])  # æ¯ä¸ªå‘¨æœŸå–æœ€å2ä¸ªæ‰¹æ¬¡
                    
                    if len(summaries) >= count:
                        break
            
            # è¿”å›æœ€è¿‘çš„countä¸ªsummary
            return summaries[-count:] if summaries else []
            
        except Exception as e:
            logger.warning(f"è·å–å†å²æ‰¹æ¬¡æ‘˜è¦å¤±è´¥: {e}")
            return []
        
    async def _generate_cycle_summary(self, cycle_info: Dict, daily_schedules: List[Dict], llm, workflow_chat) -> str:
        """ç”Ÿæˆå‘¨æœŸæ€»ç»“"""
        try:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ—¥ç¨‹ç”Ÿæˆ",
                    "æ­£åœ¨ç”Ÿæˆå‘¨æœŸæ€»ç»“...",
                    "progress"
                )
            
            # æå–å‘¨æœŸå…³é”®ä¿¡æ¯
            cycle_theme = cycle_info.get('cycle_theme', '')
            objectives = cycle_info.get('main_objectives', [])
            focus_characters = cycle_info.get('focus_characters', [])
            
            # ç»Ÿè®¡å„è§’è‰²å‡ºç°æ¬¡æ•°
            character_stats = {}
            location_stats = {}
            
            for day in daily_schedules:
                for slot in day.get('time_slots', []):
                    # ç»Ÿè®¡è§’è‰²
                    chars = slot.get('involved_characters', [])
                    for char in chars:
                        character_stats[char] = character_stats.get(char, 0) + 1
                    
                    # ç»Ÿè®¡åœ°ç‚¹
                    location = slot.get('location', '')
                    if location:
                        location_stats[location] = location_stats.get(location, 0) + 1
            
            # æ„å»ºæ€»ç»“æç¤ºè¯
            summary_prompt = f"""
æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºè¿™ä¸ªå‘¨æœŸç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ€»ç»“ï¼ˆ300å­—ä»¥å†…ï¼‰ï¼š

## å‘¨æœŸä¿¡æ¯
- ä¸»é¢˜ï¼š{cycle_theme}
- ç›®æ ‡ï¼š{', '.join(objectives)}
- é‡ç‚¹è§’è‰²ï¼š{', '.join(focus_characters)}
- å®é™…å¤©æ•°ï¼š{len(daily_schedules)}å¤©

## è§’è‰²äº’åŠ¨ç»Ÿè®¡
{chr(10).join([f"- {char}: {count}æ¬¡äº’åŠ¨" for char, count in sorted(character_stats.items(), key=lambda x: x[1], reverse=True)[:5]])}

## åœ°ç‚¹æ´»åŠ¨ç»Ÿè®¡  
{chr(10).join([f"- {loc}: {count}æ¬¡" for loc, count in sorted(location_stats.items(), key=lambda x: x[1], reverse=True)[:5]])}

è¯·ç”Ÿæˆä¸€ä¸ªç¬¬ä¸‰äººç§°çš„å‘¨æœŸæ€»ç»“ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. å‘¨æœŸä¸»é¢˜çš„ä½“ç°å’Œç›®æ ‡è¾¾æˆæƒ…å†µ
2. é‡ç‚¹è§’è‰²å…³ç³»çš„å‘å±•å˜åŒ–
3. ä¸»è¦æ´»åŠ¨å’Œé‡è¦äº‹ä»¶
4. æ–¹çŸ¥è¡¡çš„æˆé•¿å’Œå˜åŒ–
5. ä¸ºä¸‹ä¸ªå‘¨æœŸçš„é“ºå«

è¦æ±‚ï¼šç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹ï¼Œ300å­—ä»¥å†…ã€‚
"""
            
            # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“ï¼ˆè±†åŒ…è‡ªå¸¦æ‰“å°ï¼‰
            from core.types import Message, MessageRole
            message = Message(role=MessageRole.USER, content=summary_prompt)
            messages = [message]
            
            summary_content = ""
            async for chunk_data in llm.stream_generate(messages, mode="normal", return_dict=True):
                summary_content += chunk_data.get("content", "")
            
            # æ¸…ç†æ€»ç»“å†…å®¹
            summary_content = summary_content.strip()
            if len(summary_content) > 500:
                summary_content = summary_content[:500] + "..."
            
            logger.info(f"å‘¨æœŸæ€»ç»“ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary_content)} å­—ç¬¦")
            return summary_content
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå‘¨æœŸæ€»ç»“å¤±è´¥: {e}")
            return f"å‘¨æœŸ{cycle_info.get('cycle_number', '')}å®Œæˆï¼Œå…±{len(daily_schedules)}å¤©ï¼Œä¸»é¢˜ï¼š{cycle_info.get('cycle_theme', '')}ã€‚"
        
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()

# æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹å·²åˆ é™¤ï¼Œæ”¹ä¸ºåœ¨batch_schedule_generator.pyä¸­ç›´æ¥ä¿å­˜CSV
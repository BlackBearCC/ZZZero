"""å›¾ç‰‡è¯†åˆ«å·¥ä½œæµ - åŸºäºè±†åŒ…/DoubaoLLMçš„å›¾ç‰‡è¯†åˆ«ç³»ç»Ÿ
æä¾›å¯¹å›¾ç‰‡çš„å†…å®¹è¯†åˆ«ã€æ ‡é¢˜ç”Ÿæˆå’Œè¯¦ç»†æè¿°åŠŸèƒ½
"""

import json
import asyncio
import base64
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import csv

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole
from workflow.story_generator import StoryGenerationNode

logger = logging.getLogger(__name__)

class ImageRecognitionWorkflow:
    """å›¾ç‰‡è¯†åˆ«å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None

        self.current_config = {
            'batch_size': 5,  # æ¯æ‰¹å¤„ç†çš„å›¾ç‰‡æ•°é‡
            'csv_output': {
                'enabled': True,
                'output_dir': 'workspace/image_recognition_output',
                'filename': 'image_recognition_results.csv',
                'encoding': 'utf-8-sig'  # æ”¯æŒä¸­æ–‡çš„CSVç¼–ç 
            }
        }
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def create_image_recognition_graph(self) -> StateGraph:
        """åˆ›å»ºå›¾ç‰‡è¯†åˆ«å·¥ä½œæµå›¾"""
        self.graph = StateGraph(name="image_recognition_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹
        image_loading_node = ImageLoadingNode()  # å›¾ç‰‡åŠ è½½å’Œé¢„å¤„ç†èŠ‚ç‚¹
        recognition_node = ImageRecognitionNode()  # å›¾ç‰‡è¯†åˆ«èŠ‚ç‚¹
        save_result_node = ResultSaveNode()  # ç»“æœä¿å­˜èŠ‚ç‚¹
        story_generation_node = StoryGenerationNode()  # æ•…äº‹ç”ŸæˆèŠ‚ç‚¹
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("image_loading", image_loading_node)
        self.graph.add_node("image_recognition", recognition_node)
        self.graph.add_node("save_result", save_result_node)
        self.graph.add_node("story_generation", story_generation_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.graph.add_edge("image_loading", "image_recognition")
        self.graph.add_edge("image_recognition", "save_result")
        self.graph.add_edge("save_result", "story_generation")
        
        # æ–°å¢æ¡ä»¶è¾¹ï¼šå¦‚æœå°šæœªå®Œæˆå…¨éƒ¨æ‰¹æ¬¡ï¼Œåˆ™å›åˆ°å›¾ç‰‡åŠ è½½èŠ‚ç‚¹
        def loop_condition(state):
            """å½“å°šæœªå®Œæˆå…¨éƒ¨æ‰¹æ¬¡æ—¶ç»§ç»­å¾ªç¯ï¼Œå¦åˆ™ç»“æŸ"""
            if state.get('recognition_complete', False):
                return "__end__"
            return "image_loading"
        
        self.graph.add_conditional_edges("story_generation", loop_condition)
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("image_loading")
        
        return self.graph
    
    async def execute_workflow_stream(self, config: Dict[str, Any], workflow_chat, images=None):
        """æµå¼æ‰§è¡Œå›¾ç‰‡è¯†åˆ«å·¥ä½œæµ"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'config': config,
                'workflow_chat': workflow_chat,
                'llm': self.llm,
                'images': images or [],  # å›¾ç‰‡è·¯å¾„åˆ—è¡¨
                'current_batch_index': 0,
                'recognition_complete': False
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_image_recognition_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å›¾ç‰‡è¯†åˆ«å·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    node_display_name = self._get_node_display_name(node_name)
                    workflow_chat.current_node = self._get_node_id(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        "å¼€å§‹æ‰§è¡Œ...",
                        "progress"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        image_count = 0
                        for key in ['loaded_images', 'recognition_results']:
                            if key in intermediate_result.state_update:
                                if isinstance(intermediate_result.state_update[key], list):
                                    image_count = len(intermediate_result.state_update[key])
                                break
                        
                        if image_count > 0:
                            node_display_name = self._get_node_display_name(node_name)
                            await workflow_chat.add_node_message(
                                node_display_name,
                                f"æ­£åœ¨å¤„ç†å›¾ç‰‡... å½“å‰æ•°é‡: {image_count}",
                                "streaming"
                            )
                            
                            yield (
                                workflow_chat._create_workflow_progress(),
                                "",
                                f"æ­£åœ¨å¤„ç†å›¾ç‰‡... å½“å‰æ•°é‡: {image_count}",
                                False
                            )
                
                elif event_type == 'node_complete':
                    node_display_name = self._get_node_display_name(node_name)
                    
                    if node_name == 'image_recognition':
                        result_content = "âœ… å›¾ç‰‡è¯†åˆ«å®Œæˆ"
                        if 'recognition_results' in stream_event.get('output', {}):
                            results = stream_event['output']['recognition_results']
                            if isinstance(results, list):
                                result_content = f"âœ… å·²æˆåŠŸè¯†åˆ«{len(results)}å¼ å›¾ç‰‡"
                    else:
                        result_content = "âœ… æ‰§è¡Œå®Œæˆ"
                        
                    await workflow_chat.add_node_message(
                        node_display_name,
                        result_content,
                        "completed"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    node_display_name = self._get_node_display_name(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        f"æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å›¾ç‰‡è¯†åˆ«å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                else:
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å›¾ç‰‡è¯†åˆ«å·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡è¯†åˆ«å·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow_chat.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow_chat._create_workflow_progress(),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'image_loading': 'å›¾ç‰‡åŠ è½½',
            'image_recognition': 'å›¾ç‰‡è¯†åˆ«',
            'save_result': 'ç»“æœä¿å­˜',
            'story_generation': 'æ•…äº‹ç”Ÿæˆ'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'image_loading': 'loading',
            'image_recognition': 'recognition',
            'save_result': 'save',
            'story_generation': 'story'
        }
        return id_mapping.get(node_name, node_name)


class ImageLoadingNode(BaseNode):
    """å›¾ç‰‡åŠ è½½å’Œé¢„å¤„ç†èŠ‚ç‚¹ - åŠ è½½å›¾ç‰‡å¹¶è¿›è¡Œé¢„å¤„ç†"""
    
    def __init__(self):
        super().__init__(name="image_loading", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå›¾ç‰‡åŠ è½½èŠ‚ç‚¹"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå›¾ç‰‡åŠ è½½èŠ‚ç‚¹"""
        print("ğŸ“· å¼€å§‹åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡...")
        
        workflow_chat = input_data.get('workflow_chat')
        images = input_data.get('images', [])
        current_batch_index = input_data.get('current_batch_index', 0)
        batch_size = input_data.get('config', {}).get('batch_size', 5)
        
        if not images or current_batch_index * batch_size >= len(images):
            # æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œæ¯•
            output_data = input_data.copy()
            output_data['recognition_complete'] = True
            output_data['loaded_images'] = []
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å›¾ç‰‡åŠ è½½",
                    "âœ… æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œæˆ",
                    "success"
                )
            
            yield output_data
            return
        
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å›¾ç‰‡ç´¢å¼•èŒƒå›´
        start_idx = current_batch_index * batch_size
        end_idx = min(start_idx + batch_size, len(images))
        current_batch_images = images[start_idx:end_idx]
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å›¾ç‰‡åŠ è½½",
                f"æ­£åœ¨åŠ è½½ç¬¬ {current_batch_index + 1} æ‰¹æ¬¡ï¼Œå…± {len(current_batch_images)} å¼ å›¾ç‰‡...",
                "progress"
            )
        
        # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
        loaded_images = []
        for img_idx, img_path in enumerate(current_batch_images):
            try:
                # å¤„ç†ç‰¹æ®Šæ–‡ä»¶åï¼ˆä»¥@å¼€å¤´çš„æ–‡ä»¶åï¼‰
                actual_path = img_path
                if img_path.startswith('@'):
                    # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰è¯¥æ–‡ä»¶
                    if os.path.exists(img_path):
                        actual_path = img_path
                    else:
                        # å°è¯•åœ¨å„ä¸ªå¯èƒ½çš„ç›®å½•ä¸‹æŸ¥æ‰¾
                        possible_paths = [
                            # å½“å‰ç›®å½•
                            img_path,
                            # å»æ‰@çš„æ–‡ä»¶å
                            img_path[1:],
                            # workspace/inputç›®å½•
                            os.path.join('workspace', 'input', img_path),
                            os.path.join('workspace', 'input', img_path[1:]),
                            # å…¶ä»–å¯èƒ½çš„ç›®å½•
                            os.path.join('.', img_path),
                            os.path.join('.', img_path[1:])
                        ]
                        
                        # å¯»æ‰¾ç¬¬ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶è·¯å¾„
                        for path in possible_paths:
                            if os.path.exists(path):
                                actual_path = path
                                logger.info(f"æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {path}")
                                break
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(actual_path):
                    logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}ï¼Œè·³è¿‡å¤„ç†")
                    continue
                
                # è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶è¿›è¡ŒBase64ç¼–ç 
                with open(actual_path, "rb") as img_file:
                    img_data = img_file.read()
                    base64_img = base64.b64encode(img_data).decode("utf-8")
                
                # è·å–æ–‡ä»¶ä¿¡æ¯
                img_name = os.path.basename(img_path)
                img_size = len(img_data)  # ä½¿ç”¨æ–‡ä»¶å†…å®¹å¤§å°è€Œä¸æ˜¯æ–‡ä»¶å¤§å°
                img_ext = os.path.splitext(img_path)[1].lower()
                if not img_ext:  # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ ¹æ®æ–‡ä»¶å¤´æ¨æ–­
                    if img_data.startswith(b'\x89PNG'):
                        img_ext = '.png'
                    elif img_data.startswith(b'\xff\xd8'):
                        img_ext = '.jpg'
                    else:
                        img_ext = '.png'  # é»˜è®¤ä¸ºPNG
                
                # ç¡®å®šMIMEç±»å‹
                mime_type = "image/jpeg"  # é»˜è®¤å€¼
                if img_ext == ".png":
                    mime_type = "image/png"
                elif img_ext == ".gif":
                    mime_type = "image/gif"
                elif img_ext in [".jpg", ".jpeg"]:
                    mime_type = "image/jpeg"
                elif img_ext in [".webp"]:
                    mime_type = "image/webp"
                
                loaded_images.append({
                    "image_path": img_path,
                    "actual_path": actual_path,
                    "image_name": img_name,
                    "base64_data": base64_img,
                    "mime_type": mime_type,
                    "file_size": img_size,
                    "batch_index": current_batch_index,
                    "image_index": img_idx
                })
                
                logger.info(f"æˆåŠŸåŠ è½½å›¾ç‰‡: {img_name} ({img_size} å­—èŠ‚)")
                
            except Exception as e:
                logger.error(f"åŠ è½½å›¾ç‰‡å¤±è´¥ ({img_path}): {e}")
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å›¾ç‰‡åŠ è½½",
                f"âœ… å·²æˆåŠŸåŠ è½½ {len(loaded_images)} å¼ å›¾ç‰‡",
                "success"
            )
        
        # æ„å»ºè¾“å‡ºæ•°æ®
        output_data = input_data.copy()
        output_data['loaded_images'] = loaded_images
        output_data['current_batch_index'] = current_batch_index + 1
        
        logger.info(f"âœ… ç¬¬ {current_batch_index + 1} æ‰¹æ¬¡å›¾ç‰‡åŠ è½½å®Œæˆï¼Œå…± {len(loaded_images)} å¼ ")
        yield output_data


class ImageRecognitionNode(BaseNode):
    """å›¾ç‰‡è¯†åˆ«èŠ‚ç‚¹ - ä½¿ç”¨DoubaoLLMåˆ†æå›¾ç‰‡å†…å®¹"""
    
    def __init__(self):
        super().__init__(name="image_recognition", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå›¾ç‰‡è¯†åˆ«èŠ‚ç‚¹"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå›¾ç‰‡è¯†åˆ«èŠ‚ç‚¹"""
        print("ğŸ” å¼€å§‹å›¾ç‰‡è¯†åˆ«...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        loaded_images = input_data.get('loaded_images', [])
        
        if not loaded_images:
            # æ²¡æœ‰å›¾ç‰‡éœ€è¦å¤„ç†ï¼Œç›´æ¥è¿”å›
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å›¾ç‰‡è¯†åˆ«",
                    "âš ï¸ æ²¡æœ‰å›¾ç‰‡éœ€è¦å¤„ç†",
                    "warning"
                )
            
            output_data = input_data.copy()
            output_data['recognition_results'] = []
            yield output_data
            return
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å›¾ç‰‡è¯†åˆ«",
                f"æ­£åœ¨è¯†åˆ« {len(loaded_images)} å¼ å›¾ç‰‡...",
                "progress"
            )
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        recognition_results = []
        for img_idx, img_data in enumerate(loaded_images):
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰LLM
                if not llm:
                    raise Exception("LLMæœªåˆå§‹åŒ–")
                
                # æ„å»ºå›¾ç‰‡è¯†åˆ«æç¤ºè¯
                system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡è¯†åˆ«åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå›¾ç‰‡å†…å®¹å¹¶ç”Ÿæˆå‡†ç¡®çš„æ ‡é¢˜å’Œè¯¦ç»†æè¿°ã€‚
è¯·æ ¹æ®æä¾›çš„å›¾ç‰‡å†…å®¹ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. ç”Ÿæˆä¸€ä¸ªç®€çŸ­è€Œç²¾ç¡®çš„æ ‡é¢˜ï¼ˆ5-10ä¸ªå­—ï¼‰
2. æä¾›è¯¦ç»†çš„å›¾ç‰‡å†…å®¹æè¿°ï¼ˆ100-200å­—ï¼‰
3. è¯†åˆ«å›¾ç‰‡ä¸­çš„å…³é”®ç‰©ä½“ã€äººç‰©ã€åœºæ™¯ç­‰å…ƒç´ 

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šJSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- title: å›¾ç‰‡æ ‡é¢˜
- description: è¯¦ç»†æè¿°
- elements: å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ ï¼Œæ¦‚å¿µï¼Œé£æ ¼ï¼Œæƒ…æ„ŸåŸºè°ƒï¼ˆæ•°ç»„ï¼‰

è¯·ç¡®ä¿è¾“å‡ºä¸ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚
{
  "title": "å…¬å›­ç°çŒ«",
  "description": "åœ¨ç§‹æ—¥å…¬å›­æ‹æ‘„çš„ç…§ç‰‡ï¼Œç”»é¢ä¸­ä¸€åªé“¶ç°è‰²çŸ­æ¯›çŒ«æ­£è¹²ååœ¨äººè¡Œé“ä¸Šï¼Œå¥½å¥‡åœ°ç”¨çˆªå­è§¦ç¢°ä¸€ç‰‡æ¯é»„çš„è½å¶ã€‚èƒŒæ™¯æ˜¯å…¬å›­å…¥å£å¤„çš„ç»¿è‰²æ‹±é—¨å’Œæ ‡è¯†ç‰Œï¼Œå‘¨å›´ç¯ç»•ç€å¤šæ£µè½å¶æ ‘æœ¨ï¼Œæ ‘å¶å‘ˆç°é‡‘é»„è‰²è°ƒã€‚é˜³å…‰é€è¿‡æ ‘å¶å½¢æˆæŸ”å’Œçš„å…‰å½±æ•ˆæœï¼Œæ•´ä¸ªåœºæ™¯å……æ»¡å®é™ç¥¥å’Œçš„ç§‹æ—¥æ°›å›´ã€‚çŒ«å’ªçš„ç»¿è‰²çœ¼ç›å’Œè­¦è§‰çš„å§¿æ€ä¸å‘¨å›´ç¯å¢ƒå½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚",
  "elements": ["ç°çŒ«", "è½å¶", "å…¬å›­", "æ‹±é—¨", "ç§‹å¤©æ™¯è‰²", "æ ‘æœ¨", "åŸå¸‚é£å…‰", "å®é™æ°›å›´"]
}

"""
                # æ„å»ºç”¨æˆ·æ¶ˆæ¯ - è¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰©å±•æ¶ˆæ¯ç±»æ¥æ”¯æŒå›¾ç‰‡
                # å› ä¸ºå½“å‰Messageç±»ä¸æ”¯æŒç›´æ¥åŒ…å«å›¾ç‰‡ï¼Œæˆ‘ä»¬å°†base64å›¾ç‰‡æ•°æ®æ”¾åœ¨å…ƒæ•°æ®ä¸­
                
                user_message = Message(
                    role=MessageRole.USER,
                    content="è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œæä¾›æ ‡é¢˜å’Œè¯¦ç»†æè¿°ã€‚",
                    metadata={
                        "has_image": True,
                        "image_data": img_data["base64_data"],
                        "image_mime": img_data["mime_type"]
                    }
                )
                
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                messages = [
                    Message(role=MessageRole.SYSTEM, content=system_prompt),
                    user_message
                ]
                
                # ä¿®æ”¹doubao_llmçš„_convert_messagesæ–¹æ³•ä»¥æ”¯æŒå›¾ç‰‡
                # è¿™æ˜¯ä¸€ä¸ªmonkey patchï¼Œå®é™…åº”è¯¥åœ¨LLMç±»ä¸­å®ç°
                original_convert_messages = llm._convert_messages
                
                def patched_convert_messages(messages_list):
                    """æ·»åŠ å¯¹å›¾ç‰‡çš„æ”¯æŒ"""
                    converted = []
                    for msg in messages_list:
                        role = "user" if msg.role == MessageRole.USER else "assistant"
                        if msg.role == MessageRole.SYSTEM:
                            role = "system"
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
                        if msg.metadata and msg.metadata.get("has_image"):
                            # æ·»åŠ å›¾ç‰‡å†…å®¹
                            converted.append({
                                "role": role,
                                "content": [
                                    {"type": "text", "text": msg.content},
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:{msg.metadata.get('image_mime', 'image/jpeg')};base64,{msg.metadata.get('image_data')}",
                                        }
                                    }
                                ]
                            })
                        else:
                            # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                            converted.append({
                                "role": role,
                                "content": msg.content
                            })
                    
                    return converted
                
                # åº”ç”¨monkey patch
                llm._convert_messages = patched_convert_messages
                
                # è°ƒç”¨LLMè¿›è¡Œå›¾ç‰‡è¯†åˆ«
                logger.info(f"å¼€å§‹è¯†åˆ«å›¾ç‰‡: {img_data['image_name']}")
                
                try:
                    # æ›´æ–°æ¨¡å‹åç§°ä¸ºæ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹
                    original_model = llm.config.model_name
                    # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹åç§°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    vision_model = os.getenv('DOUBAO_MODEL_VISION_PRO', 'ep-20250704095927-j6t2g')
                    llm.config.model_name = vision_model
                    
                    logger.info(f"ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹: {vision_model}")
                    
                    # è°ƒç”¨LLM
                    response = await llm.generate(
                        messages,
                        temperature=0.7,
                        max_tokens=4096,
                        mode="normal"
                    )
                    
                    # æ¢å¤åŸå§‹æ¨¡å‹åç§°
                    llm.config.model_name = original_model
                    
                    # æ¢å¤åŸå§‹æ–¹æ³•
                    llm._convert_messages = original_convert_messages
                    
                    # è§£æç»“æœ
                    content = response.content
                    
                    # ä»å›å¤ä¸­æå–JSON
                    import re
                    json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                    
                    if json_match:
                        json_str = json_match.group(1)
                    else:
                        # å°è¯•æ‰¾åˆ°å¤§æ‹¬å·åŒ…å›´çš„JSON
                        json_match = re.search(r'\{.*\}', content, re.DOTALL)
                        if json_match:
                            json_str = json_match.group(0)
                        else:
                            json_str = content
                    
                    # è§£æJSON
                    try:
                        result_data = json.loads(json_str.strip())
                    except json.JSONDecodeError:
                        logger.warning(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å›å¤")
                        result_data = {
                            "title": "æ— æ³•è§£æç»“æœ",
                            "description": content,
                            "elements": [],
                            "style": "æœªçŸ¥",
                            "mood": "æœªçŸ¥"
                        }
                    
                    # æ·»åŠ å›¾ç‰‡ä¿¡æ¯
                    result_data["image_name"] = img_data["image_name"]
                    result_data["image_path"] = img_data["image_path"]
                    
                    recognition_results.append(result_data)
                    logger.info(f"å›¾ç‰‡è¯†åˆ«æˆåŠŸ: {img_data['image_name']}")
                    
                except Exception as e:
                    logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
                    # æ·»åŠ é”™è¯¯ç»“æœ
                    recognition_results.append({
                        "image_name": img_data["image_name"],
                        "image_path": img_data["image_path"],
                        "title": "è¯†åˆ«å¤±è´¥",
                        "description": f"å›¾ç‰‡è¯†åˆ«è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
                        "elements": [],
                        "style": "æœªçŸ¥",
                        "mood": "é”™è¯¯",
                        "error": str(e)
                    })
                
            except Exception as e:
                logger.error(f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {e}")
                recognition_results.append({
                    "image_name": img_data["image_name"] if "image_name" in img_data else "æœªçŸ¥å›¾ç‰‡",
                    "image_path": img_data["image_path"] if "image_path" in img_data else "æœªçŸ¥è·¯å¾„",
                    "title": "å¤„ç†é”™è¯¯",
                    "description": f"å›¾ç‰‡å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
                    "elements": [],
                    "style": "æœªçŸ¥",
                    "mood": "é”™è¯¯",
                    "error": str(e)
                })
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å›¾ç‰‡è¯†åˆ«",
                f"âœ… å·²æˆåŠŸè¯†åˆ« {len(recognition_results)} å¼ å›¾ç‰‡",
                "success"
            )
        
        # è¾“å‡ºç»“æœ
        output_data = input_data.copy()
        output_data['recognition_results'] = recognition_results
        
        logger.info(f"âœ… å›¾ç‰‡è¯†åˆ«å®Œæˆï¼Œå…± {len(recognition_results)} å¼ ")
        yield output_data


class ResultSaveNode(BaseNode):
    """ç»“æœä¿å­˜èŠ‚ç‚¹ - å°†è¯†åˆ«ç»“æœä¿å­˜åˆ°CSV"""
    
    def __init__(self):
        super().__init__(name="result_save", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç»“æœä¿å­˜èŠ‚ç‚¹"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œç»“æœä¿å­˜èŠ‚ç‚¹"""
        print("ğŸ’¾ å¼€å§‹ä¿å­˜è¯†åˆ«ç»“æœ...")
        
        workflow_chat = input_data.get('workflow_chat')
        recognition_results = input_data.get('recognition_results', [])
        config = input_data.get('config', {})
        
        if not recognition_results:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç»“æœä¿å­˜",
                    "âš ï¸ æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜",
                    "warning"
                )
            yield input_data
            return
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "ç»“æœä¿å­˜",
                f"æ­£åœ¨ä¿å­˜{len(recognition_results)}æ¡è¯†åˆ«ç»“æœ...",
                "progress"
            )
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        csv_save_result = await self._save_to_csv(recognition_results, config, workflow_chat)
        
        # æ„å»ºæœ€ç»ˆè¾“å‡º
        output_data = input_data.copy()
        output_data.update({
            'csv_save_result': csv_save_result,
            'save_success': csv_save_result.get('success', False),
            'save_message': csv_save_result.get('message', 'ä¿å­˜å®Œæˆ')
        })
        
        yield output_data
    
    async def _save_to_csv(self, recognition_results: List[Dict], config: Dict, workflow_chat=None) -> Dict:
        """ä¿å­˜è¯†åˆ«ç»“æœåˆ°CSVæ–‡ä»¶"""
        try:
            import csv
            from datetime import datetime
            
            # è·å–CSVé…ç½®
            csv_config = config.get('csv_output', {})
            output_dir = csv_config.get('output_dir', 'workspace/image_recognition_output')
            filename = csv_config.get('filename', 'image_recognition_results.csv')
            encoding = csv_config.get('encoding', 'utf-8-sig')
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # CSVæ–‡ä»¶è·¯å¾„
            csv_file = os.path.join(output_dir, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå†³å®šæ˜¯å¦å†™å…¥è¡¨å¤´
            file_exists = os.path.exists(csv_file)
            
            # å†™å…¥CSVæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
            with open(csv_file, 'a', newline='', encoding=encoding) as f:
                fieldnames = ['å›¾ç‰‡åç§°', 'å›¾ç‰‡è·¯å¾„', 'æ ‡é¢˜', 'è¯¦ç»†æè¿°', 'ä¸»è¦å…ƒç´ ', 'è¯†åˆ«æ—¶é—´']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™å…¥è¡¨å¤´
                if not file_exists:
                    writer.writeheader()
                
                # å†™å…¥å½“å‰æ‰¹æ¬¡çš„è¯†åˆ«ç»“æœ
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                for result in recognition_results:
                    writer.writerow({
                        'å›¾ç‰‡åç§°': result.get('image_name', ''),
                        'å›¾ç‰‡è·¯å¾„': result.get('image_path', ''),
                        'æ ‡é¢˜': result.get('title', ''),
                        'è¯¦ç»†æè¿°': result.get('description', ''),
                        'ä¸»è¦å…ƒç´ ': ','.join(result.get('elements', [])) if isinstance(result.get('elements'), list) else result.get('elements', ''),
                        'è¯†åˆ«æ—¶é—´': timestamp
                    })
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç»“æœä¿å­˜",
                    f"âœ… {len(recognition_results)}æ¡è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°CSVæ–‡ä»¶",
                    "success"
                )
            
            logger.info(f"âœ… CSVä¿å­˜å®Œæˆï¼š{len(recognition_results)}æ¡è¯†åˆ«ç»“æœä¿å­˜åˆ° {csv_file}")
            
            return {
                'success': True,
                'message': f"æˆåŠŸä¿å­˜{len(recognition_results)}æ¡è¯†åˆ«ç»“æœ",
                'count': len(recognition_results),
                'file_path': csv_file
            }
            
        except Exception as e:
            logger.error(f"CSVä¿å­˜å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç»“æœä¿å­˜",
                    f"âŒ CSVä¿å­˜å¤±è´¥: {str(e)}",
                    "error"
                )
            
            return {
                'success': False,
                'message': f"ä¿å­˜å¤±è´¥: {str(e)}",
                'error': str(e)
            }


# æœ¬åœ°æµ‹è¯•è¿è¡Œå…¥å£
async def main():
    """æœ¬åœ°æµ‹è¯•è¿è¡Œå›¾ç‰‡è¯†åˆ«å·¥ä½œæµ"""
    print("ğŸ­ å¯åŠ¨å›¾ç‰‡è¯†åˆ«å·¥ä½œæµæœ¬åœ°æµ‹è¯•...")
    
    # ç®€å•çš„æ¨¡æ‹ŸèŠå¤©ç•Œé¢
    class MockWorkflowChat:
        def __init__(self):
            self.current_node = ""
        
        async def add_node_message(self, node_name: str, message: str, status: str):
            print(f"[{node_name}] {status}: {message}")
        
        def _create_workflow_progress(self):
            return "<div>å·¥ä½œæµè¿›åº¦</div>"
    
    try:
        # é…ç½®LLM
        llm = None
        try:
            from llm.doubao import DoubaoLLM
            from core.types import LLMConfig
            
            # ä½¿ç”¨ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°å’ŒAPIå¯†é’¥
            vision_model = os.getenv('DOUBAO_MODEL_VISION_PRO', 'ep-20250704095927-j6t2g')
            api_key = os.getenv('ARK_API_KEY') or os.getenv('DOUBAO_API_KEY')
            
            # åˆ›å»ºLLMé…ç½®
            llm_config = LLMConfig(
                provider="doubao",
                model_name=vision_model,  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹
                api_key=api_key,  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
                api_base="https://ark.cn-beijing.volces.com/api/v3"
            )
            llm = DoubaoLLM(config=llm_config)
            print(f"âœ… LLMé…ç½®æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {vision_model}")
        except Exception as e:
            print(f"âš ï¸ LLMé…ç½®å¤±è´¥ï¼Œå°†è·³è¿‡å®é™…è¯†åˆ«: {e}")
        
        # åˆå§‹åŒ–å·¥ä½œæµ
        workflow = ImageRecognitionWorkflow(llm=llm)
        print("âœ… å›¾ç‰‡è¯†åˆ«å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
        
        # æµ‹è¯•é…ç½®
        test_config = {
            'batch_size': 2,  # æ¯æ‰¹å¤„ç†2å¼ å›¾ç‰‡
            'csv_output': {
                'enabled': True,
                'output_dir': 'workspace/image_recognition_output',
                'filename': 'image_recognition_results.csv',
                'encoding': 'utf-8-sig'
            }
        }
        
        print(f"ğŸ“Š æµ‹è¯•é…ç½®: {test_config}")
        
        # æ¨¡æ‹Ÿå›¾ç‰‡è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„å®é™…ç¯å¢ƒä¿®æ”¹ï¼‰
        test_images = [
            "@25455127221_185539693045_è·¯è¾¹å¯çˆ±åŠ¨ç‰© (4)(1).png"  # ä½¿ç”¨æä¾›çš„å›¾ç‰‡è·¯å¾„
        ]
        
        print(f"ğŸ–¼ï¸ æµ‹è¯•å›¾ç‰‡: {test_images}")
        
        # åˆ›å»ºæ¨¡æ‹ŸèŠå¤©ç•Œé¢
        mock_chat = MockWorkflowChat()
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        graph = await workflow.create_image_recognition_graph()
        compiled_graph = graph.compile()
        print("âœ… å·¥ä½œæµå›¾åˆ›å»ºå®Œæˆ")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = {
            'config': test_config,
            'workflow_chat': mock_chat,
            'llm': llm,
            'images': test_images,
            'current_batch_index': 0
        }
        
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œå›¾ç‰‡è¯†åˆ«å·¥ä½œæµ...")
        
        # æ‰§è¡Œå·¥ä½œæµ
        final_result = None
        async for result in compiled_graph.stream(input_data):
            if result:
                final_result = result
        
        # æ˜¾ç¤ºç»“æœ
        if final_result:
            print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ!")
            
            recognition_results = final_result.get('recognition_results', [])
            print(f"ğŸ“ è¯†åˆ«ç»“æœæ•°é‡: {len(recognition_results)}")
            
            if recognition_results:
                print("\nğŸ–¼ï¸ è¯†åˆ«ç»“æœç¤ºä¾‹:")
                for i, result in enumerate(recognition_results[:2], 1):  # æ˜¾ç¤ºå‰2æ¡
                    print(f"\n--- ç»“æœ {i} ---")
                    print(f"å›¾ç‰‡: {result.get('image_name', 'N/A')}")
                    print(f"æ ‡é¢˜: {result.get('title', 'N/A')}")
                    print(f"æè¿°: {result.get('description', 'N/A')}")
                    print(f"å…ƒç´ : {result.get('elements', [])}")
                    print(f"é£æ ¼: {result.get('style', 'N/A')}")
                    print(f"æƒ…æ„Ÿ: {result.get('mood', 'N/A')}")
                    print("-" * 50)
                
                # æ˜¾ç¤ºCSVä¿å­˜ç»“æœ
                csv_result = final_result.get('csv_save_result', {})
                if csv_result.get('success'):
                    csv_file = csv_result.get('file_path', 'æœªçŸ¥')
                    print(f"\nğŸ’¾ CSVç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
                else:
                    print(f"\nâš ï¸ CSVä¿å­˜å¤±è´¥: {csv_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            
            else:
                print("âš ï¸ æ²¡æœ‰è¯†åˆ«ç»“æœï¼ˆå¯èƒ½æ˜¯APIå¯†é’¥æ— æ•ˆæˆ–ç½‘ç»œé—®é¢˜ï¼‰")
        
        else:
            print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæœ¬åœ°æµ‹è¯•"""
    print("ğŸ–¼ï¸ å›¾ç‰‡è¯†åˆ«å·¥ä½œæµ - æœ¬åœ°æµ‹è¯•æ¨¡å¼")
    print("=" * 60)
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
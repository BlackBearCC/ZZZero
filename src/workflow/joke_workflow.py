"""ç¬‘è¯ç”Ÿæˆå·¥ä½œæµ - åŸºäºæ–¹çŸ¥è¡¡äººè®¾çš„ç¬‘è¯åˆ›ä½œç³»ç»Ÿ
æ ¹æ®ä¸»è§’çš„æ€§æ ¼ç‰¹ç‚¹ç”Ÿæˆç¬¦åˆäººè®¾çš„å¹½é»˜å†…å®¹ï¼Œæ”¯æŒæ‰¹é‡ç”Ÿæˆå‡ åƒæ¡ä¸é‡æ ·çš„ç¬‘è¯
"""

import json
import asyncio
import random
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole

logger = logging.getLogger(__name__)

class JokeWorkflow:
    """ç¬‘è¯ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None
        self.protagonist_data = ""  # ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾
        self.current_config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',  # å›ºå®šä¸»è§’
            'batch_size': 50,  # æ¯æ‰¹ç”Ÿæˆçš„ç¬‘è¯æ•°é‡
            'total_target': 1000,  # æ€»ç›®æ ‡æ•°é‡
            'joke_categories': [
                'å­¦æœ¯å¹½é»˜', 'ç”Ÿæ´»æ—¥å¸¸', 'æ¯’å¥¶ä½“è´¨', 'ç½‘ç»œè½ä¼', 
                'å¤æ¿è®¤çœŸ', 'æ¸©å’Œåæ§½', 'ç†æ€§åˆ†æ', 'æ„å¤–åå·®'
            ],
            'difficulty_levels': ['ç®€å•', 'ä¸­ç­‰', 'å¤æ‚'],
            'humor_styles': ['å†·å¹½é»˜', 'è‡ªå˜²', 'è§‚å¯Ÿå¼', 'åå·®èŒ'],
            'pg_config': {
                'host': 'localhost',
                'port': 5432,
                'database': 'jokes_db',
                'user': 'postgres',
                'password': 'password'
            }
        }
        
        # åŠ è½½ä¸»è§’äººè®¾
        self._load_protagonist_data()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
    
    def _load_protagonist_data(self):
        """åŠ è½½ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾"""
        try:
            protagonist_path = os.path.join(os.path.dirname(__file__), '../../config/åŸºç¡€äººè®¾.txt')
            if os.path.exists(protagonist_path):
                with open(protagonist_path, 'r', encoding='utf-8') as f:
                    self.protagonist_data = f.read()
                    logger.info(f"æˆåŠŸåŠ è½½ä¸»è§’äººè®¾ï¼Œå†…å®¹é•¿åº¦: {len(self.protagonist_data)} å­—ç¬¦")
            else:
                logger.warning("ä¸»è§’äººè®¾æ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            logger.error(f"åŠ è½½ä¸»è§’äººè®¾å¤±è´¥: {e}")
    
    def _init_database(self):
        """åˆå§‹åŒ–PostgreSQLæ•°æ®åº“å’Œè¡¨ç»“æ„"""
        try:
            pg_config = self.current_config['pg_config']
            
            # è¿æ¥æ•°æ®åº“
            conn = psycopg2.connect(**pg_config)
            cursor = conn.cursor()
            
            # åˆ›å»ºç¬‘è¯è¡¨
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS jokes (
                id SERIAL PRIMARY KEY,
                joke_id VARCHAR(50) UNIQUE NOT NULL,
                category VARCHAR(50) NOT NULL,
                difficulty_level VARCHAR(20) NOT NULL,
                humor_style VARCHAR(30) NOT NULL,
                setup TEXT NOT NULL,
                punchline TEXT NOT NULL,
                context TEXT,
                character_traits TEXT[],
                tags TEXT[],
                rating INTEGER DEFAULT 0,
                is_used BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            CREATE INDEX IF NOT EXISTS idx_jokes_category ON jokes(category);
            CREATE INDEX IF NOT EXISTS idx_jokes_rating ON jokes(rating);
            CREATE INDEX IF NOT EXISTS idx_jokes_created_at ON jokes(created_at);
            """
            
            cursor.execute(create_table_sql)
            conn.commit()
            
            cursor.close()
            conn.close()
            
            logger.info("æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def create_joke_graph(self) -> StateGraph:
        """åˆ›å»ºç¬‘è¯ç”Ÿæˆå›¾å·¥ä½œæµ"""
        self.graph = StateGraph(name="joke_generation_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹
        theme_planning_node = ThemePlanningNode()  # ä¸»é¢˜è§„åˆ’èŠ‚ç‚¹
        joke_generate_node = JokeGenerateNode()   # ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
        quality_check_node = QualityCheckNode()   # è´¨é‡æ£€æŸ¥èŠ‚ç‚¹
        database_save_node = JokeDatabaseSaveNode()  # æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("theme_planning", theme_planning_node)
        self.graph.add_node("joke_generate", joke_generate_node)
        self.graph.add_node("quality_check", quality_check_node)
        self.graph.add_node("database_save", database_save_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.graph.add_edge("theme_planning", "joke_generate")
        self.graph.add_edge("joke_generate", "quality_check")
        self.graph.add_edge("quality_check", "database_save")
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("theme_planning")
        
        return self.graph
    
    async def execute_workflow_stream(self, config: Dict[str, Any], workflow_chat):
        """æµå¼æ‰§è¡Œç¬‘è¯ç”Ÿæˆå·¥ä½œæµ"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'protagonist_data': self.protagonist_data,
                'config': config,
                'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
                'batch_size': config.get('batch_size', 50),
                'total_target': config.get('total_target', 1000),
                'joke_categories': config.get('joke_categories', self.current_config['joke_categories']),
                'difficulty_levels': config.get('difficulty_levels', self.current_config['difficulty_levels']),
                'humor_styles': config.get('humor_styles', self.current_config['humor_styles']),
                'pg_config': config.get('pg_config', self.current_config['pg_config']),
                'workflow_chat': workflow_chat,
                'llm': self.llm
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_joke_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    node_display_name = self._get_node_display_name(node_name)
                    workflow_chat.current_node = self._get_node_id(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        "å¼€å§‹æ‰§è¡Œ...",
                        "progress"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        content_length = 0
                        for key in ['jokes_data', 'generated_jokes', 'checked_jokes']:
                            if key in intermediate_result.state_update:
                                if isinstance(intermediate_result.state_update[key], list):
                                    content_length = len(intermediate_result.state_update[key])
                                break
                        
                        if content_length > 0:
                            node_display_name = self._get_node_display_name(node_name)
                            await workflow_chat.add_node_message(
                                node_display_name,
                                f"æ­£åœ¨å¤„ç†ç¬‘è¯å†…å®¹... å½“å‰æ•°é‡: {content_length}",
                                "streaming"
                            )
                            
                            yield (
                                workflow_chat._create_workflow_progress(),
                                "",
                                f"æ­£åœ¨å¤„ç†ç¬‘è¯... å½“å‰æ•°é‡: {content_length}",
                                False
                            )
                
                elif event_type == 'node_complete':
                    node_display_name = self._get_node_display_name(node_name)
                    
                    if node_name == 'joke_generate':
                        result_content = "âœ… ç¬‘è¯ç”Ÿæˆå®Œæˆ"
                        if 'generated_jokes' in stream_event.get('output', {}):
                            jokes_data = stream_event['output']['generated_jokes']
                            if isinstance(jokes_data, list):
                                result_content = f"âœ… å·²æˆåŠŸç”Ÿæˆ{len(jokes_data)}æ¡ç¬‘è¯"
                    else:
                        result_content = "âœ… æ‰§è¡Œå®Œæˆ"
                        
                    await workflow_chat.add_node_message(
                        node_display_name,
                        result_content,
                        "completed"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    node_display_name = self._get_node_display_name(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        f"æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                else:
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow_chat.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow_chat._create_workflow_progress(),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'theme_planning': 'ä¸»é¢˜è§„åˆ’',
            'joke_generate': 'ç¬‘è¯ç”Ÿæˆ',
            'quality_check': 'è´¨é‡æ£€æŸ¥',
            'database_save': 'æ•°æ®åº“ä¿å­˜'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'theme_planning': 'planning',
            'joke_generate': 'generate',
            'quality_check': 'check',
            'database_save': 'save'
        }
        return id_mapping.get(node_name, node_name)


class ThemePlanningNode(BaseNode):
    """ä¸»é¢˜è§„åˆ’èŠ‚ç‚¹ - æ ¹æ®äººè®¾ç‰¹ç‚¹è§„åˆ’ç¬‘è¯ä¸»é¢˜å’Œé£æ ¼"""
    
    def __init__(self):
        super().__init__(name="theme_planning", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä¸»é¢˜è§„åˆ’èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œä¸»é¢˜è§„åˆ’èŠ‚ç‚¹"""
        print("ğŸ¯ å¼€å§‹ä¸»é¢˜è§„åˆ’...")
        
        workflow_chat = input_data.get('workflow_chat')
        
        # è·å–é…ç½®å‚æ•°
        protagonist = input_data.get('protagonist', 'æ–¹çŸ¥è¡¡')
        batch_size = input_data.get('batch_size', 50)
        total_target = input_data.get('total_target', 1000)
        joke_categories = input_data.get('joke_categories', [])
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "ä¸»é¢˜è§„åˆ’",
                f"æ­£åœ¨ä¸º{protagonist}è§„åˆ’{total_target}æ¡ç¬‘è¯çš„ä¸»é¢˜åˆ†å¸ƒ...",
                "progress"
            )
        
        try:
            # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªæ‰¹æ¬¡
            total_batches = (total_target + batch_size - 1) // batch_size
            
            # ä¸ºæ¯ä¸ªæ‰¹æ¬¡åˆ†é…ä¸»é¢˜
            theme_plan = {
                'total_batches': total_batches,
                'batch_size': batch_size,
                'category_distribution': {},
                'batch_themes': []
            }
            
            # å¹³è¡¡åˆ†é…å„ä¸ªç±»åˆ«
            categories_per_batch = max(1, len(joke_categories) // total_batches)
            
            for batch_idx in range(total_batches):
                # ä¸ºå½“å‰æ‰¹æ¬¡é€‰æ‹©ä¸»é¢˜ç±»åˆ«
                start_cat = (batch_idx * categories_per_batch) % len(joke_categories)
                end_cat = min(start_cat + categories_per_batch, len(joke_categories))
                batch_categories = joke_categories[start_cat:end_cat]
                
                # å¦‚æœç±»åˆ«ä¸å¤Ÿï¼Œä»å¤´å¼€å§‹è¡¥å……
                if len(batch_categories) < categories_per_batch:
                    remaining = categories_per_batch - len(batch_categories)
                    batch_categories.extend(joke_categories[:remaining])
                
                batch_theme = {
                    'batch_number': batch_idx + 1,
                    'categories': batch_categories,
                    'focus_trait': self._get_focus_trait(batch_idx),
                    'humor_emphasis': self._get_humor_emphasis(batch_idx)
                }
                
                theme_plan['batch_themes'].append(batch_theme)
            
            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            for theme in theme_plan['batch_themes']:
                for cat in theme['categories']:
                    theme_plan['category_distribution'][cat] = theme_plan['category_distribution'].get(cat, 0) + 1
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ä¸»é¢˜è§„åˆ’",
                    f"âœ… è§„åˆ’å®Œæˆï¼š{total_batches}ä¸ªæ‰¹æ¬¡ï¼Œå¹³è¡¡åˆ†é…{len(joke_categories)}ä¸ªä¸»é¢˜ç±»åˆ«",
                    "success"
                )
            
            # è¾“å‡ºç»“æœ
            output_data = input_data.copy()
            output_data['theme_plan'] = theme_plan
            output_data['current_batch_index'] = 0
            
            logger.info(f"âœ… ä¸»é¢˜è§„åˆ’å®Œæˆï¼Œç”Ÿæˆäº†{total_batches}ä¸ªæ‰¹æ¬¡çš„ä¸»é¢˜åˆ†é…")
            yield output_data
            
        except Exception as e:
            logger.error(f"ä¸»é¢˜è§„åˆ’å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ä¸»é¢˜è§„åˆ’",
                    f"âŒ è§„åˆ’å¤±è´¥: {str(e)}",
                    "error"
                )
            raise Exception(f"ä¸»é¢˜è§„åˆ’å¤±è´¥: {str(e)}")
    
    def _get_focus_trait(self, batch_idx: int) -> str:
        """æ ¹æ®æ‰¹æ¬¡è·å–é‡ç‚¹äººè®¾ç‰¹å¾"""
        traits = [
            'ç†æ€§ä¸¥è°¨', 'å†…æ•›æ¸©å’Œ', 'æ¯’å¥¶ä½“è´¨', 'ç½‘ç»œè½ä¼',
            'å¤æ¿è®¤çœŸ', 'å­¦æœ¯ä¸“æ³¨', 'ç”Ÿæ´»ç»†è‡´', 'æ¸©å’Œåæ§½'
        ]
        return traits[batch_idx % len(traits)]
    
    def _get_humor_emphasis(self, batch_idx: int) -> str:
        """æ ¹æ®æ‰¹æ¬¡è·å–å¹½é»˜é‡ç‚¹"""
        emphasis = [
            'å†·å¹½é»˜', 'è‡ªå˜²å¼', 'è§‚å¯Ÿå¼', 'åå·®èŒ',
            'å­¦è€…é£èŒƒ', 'ç”Ÿæ´»æ™ºæ…§', 'æ„å¤–æƒŠå–œ', 'æ¸©å’Œåæ§½'
        ]
        return emphasis[batch_idx % len(emphasis)]


class JokeGenerateNode(BaseNode):
    """ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - åŸºäºäººè®¾ç”Ÿæˆç¬¦åˆç‰¹ç‚¹çš„ç¬‘è¯"""
    
    def __init__(self):
        super().__init__(name="joke_generate", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - åˆ†æ‰¹ç”Ÿæˆ"""
        print("ğŸ˜„ å¼€å§‹ç¬‘è¯ç”Ÿæˆ...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–ä¸»é¢˜è§„åˆ’æ•°æ®
        theme_plan = input_data.get('theme_plan', {})
        current_batch_index = input_data.get('current_batch_index', 0)
        batch_themes = theme_plan.get('batch_themes', [])
        
        if not batch_themes or current_batch_index >= len(batch_themes):
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç¬‘è¯ç”Ÿæˆ",
                    "âœ… æ‰€æœ‰æ‰¹æ¬¡çš„ç¬‘è¯ç”Ÿæˆå·²å®Œæˆï¼",
                    "success"
                )
            
            output_data = input_data.copy()
            output_data['generation_complete'] = True
            yield output_data
            return
        
        # è·å–å½“å‰æ‰¹æ¬¡ä¿¡æ¯
        current_batch = batch_themes[current_batch_index]
        batch_categories = current_batch['categories']
        focus_trait = current_batch['focus_trait']
        humor_emphasis = current_batch['humor_emphasis']
        batch_size = input_data.get('batch_size', 50)
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "ç¬‘è¯ç”Ÿæˆ",
                f"æ­£åœ¨ç”Ÿæˆç¬¬ {current_batch_index + 1}/{len(batch_themes)} æ‰¹æ¬¡ç¬‘è¯ï¼ˆ{batch_size}æ¡ï¼‰...",
                "progress"
            )
        
        # æ„å»ºç¬‘è¯ç”Ÿæˆæç¤ºè¯
        protagonist_data = input_data.get('protagonist_data', '')
        
        generation_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¹½é»˜åˆ›ä½œè€…ï¼Œéœ€è¦åŸºäºæ–¹çŸ¥è¡¡çš„äººè®¾ç‰¹ç‚¹ç”Ÿæˆ{batch_size}æ¡ç¬¦åˆå…¶æ€§æ ¼çš„ç¬‘è¯ã€‚

# è§’è‰²äººè®¾ä¿¡æ¯
{protagonist_data}

# æœ¬æ‰¹æ¬¡é‡ç‚¹ç‰¹å¾
- é‡ç‚¹äººè®¾ç‰¹å¾ï¼š{focus_trait}
- å¹½é»˜é£æ ¼é‡ç‚¹ï¼š{humor_emphasis}
- ä¸»é¢˜ç±»åˆ«ï¼š{', '.join(batch_categories)}

# ç¬‘è¯ç”Ÿæˆè¦æ±‚

## ç¬¦åˆäººè®¾çš„å¹½é»˜ç‰¹ç‚¹
1. **ç†æ€§ä¸¥è°¨**ï¼šç”¨å­¦æœ¯æ€ç»´åˆ†ææ—¥å¸¸å°äº‹ï¼Œäº§ç”Ÿåå·®å¹½é»˜
2. **å†…æ•›æ¸©å’Œ**ï¼šä¸ä¼šè¯´ç²—è¯ï¼Œå¹½é»˜æ–¹å¼æ¸©å’Œæœ‰ç¤¼è²Œ
3. **æ¯’å¥¶ä½“è´¨**ï¼šè¯´å¥½çš„ä¸çµåçš„çµï¼Œç»å¸¸æ— æ„ä¸­"ä¹Œé¸¦å˜´"
4. **ç½‘ç»œè½ä¼**ï¼šå¯¹ç½‘ç»œæ¢—å’Œæµè¡Œè¯­ä¸ç†Ÿæ‚‰ï¼Œäº§ç”Ÿä»£æ²Ÿç¬‘è¯
5. **å¤æ¿è®¤çœŸ**ï¼šç”¨è¿‡äºè®¤çœŸçš„æ€åº¦å¯¹å¾…å°äº‹ï¼Œå½¢æˆåå·®
6. **å­¦è€…é£èŒƒ**ï¼šå¶å°”ä¼šç”¨ä¸“ä¸šæœ¯è¯­è§£é‡Šç”Ÿæ´»ç°è±¡
7. **ç”Ÿæ´»ç»†è‡´**ï¼šå¯¹ç»†èŠ‚çš„è¿‡åº¦å…³æ³¨äº§ç”Ÿçš„å¹½é»˜
8. **æ¸©å’Œåæ§½**ï¼šä»¥æ¸©å’Œçš„æ–¹å¼è¡¨è¾¾å¯¹æŸäº›ç°è±¡çš„ä¸ç†è§£

## ç¬‘è¯ç»“æ„è¦æ±‚
æ¯æ¡ç¬‘è¯åŒ…å«ï¼š
- **setupï¼ˆé“ºå«ï¼‰**ï¼šè®¾ç½®æƒ…å¢ƒï¼Œ150å­—ä»¥å†…
- **punchlineï¼ˆç¬‘ç‚¹ï¼‰**ï¼šå…³é”®ç¬‘æ–™ï¼Œ100å­—ä»¥å†…
- **contextï¼ˆèƒŒæ™¯ï¼‰**ï¼šç®€çŸ­è¯´æ˜ç¬‘è¯èƒŒæ™¯ï¼Œ50å­—ä»¥å†…

## å†…å®¹åŸåˆ™
1. **ç»¿è‰²å¥åº·**ï¼šå†…å®¹ç§¯æå‘ä¸Šï¼Œé€‚åˆæ‰€æœ‰å¹´é¾„æ®µ
2. **é¿å…æ•æ„Ÿ**ï¼šä¸æ¶‰åŠæ”¿æ²»ã€å®—æ•™ã€ç§æ—ç­‰æ•æ„Ÿè¯é¢˜
3. **ç¬¦åˆèº«ä»½**ï¼šç¬¦åˆå¤§å­¦æ•™æˆçš„èº«ä»½å’Œä¿®å…»
4. **ç”Ÿæ´»åŒ–**ï¼šåŸºäºçœŸå®ç”Ÿæ´»åœºæ™¯ï¼Œè´´è¿‘æ—¥å¸¸
5. **åŸåˆ›æ€§**ï¼šé¿å…æŠ„è¢­å·²æœ‰ç¬‘è¯ï¼Œç¡®ä¿åŸåˆ›æ€§

## ç¬‘è¯ç±»å‹åˆ†å¸ƒ
- å­¦æœ¯å¹½é»˜ï¼šç”¨å­¦æœ¯æ€ç»´è§£é‡Šæ—¥å¸¸ï¼ˆ10-15æ¡ï¼‰
- ç”Ÿæ´»æ—¥å¸¸ï¼šç”Ÿæ´»ä¸­çš„å°å°´å°¬å’Œå°å‘ç°ï¼ˆ10-15æ¡ï¼‰
- æ¯’å¥¶ä½“è´¨ï¼šæ— æ„ä¸­è¯´ä¸­åäº‹çš„æƒ…å†µï¼ˆ8-10æ¡ï¼‰
- ç½‘ç»œè½ä¼ï¼šå¯¹æ–°äº‹ç‰©çš„ä¸ç†è§£ï¼ˆ5-8æ¡ï¼‰
- å…¶ä»–ç±»å‹ï¼šæ ¹æ®æœ¬æ‰¹æ¬¡ä¸»é¢˜çµæ´»åˆ†é…

# è¾“å‡ºæ ¼å¼
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º{batch_size}æ¡ç¬‘è¯ï¼š

```json
{{
  "batch_info": {{
    "batch_number": {current_batch_index + 1},
    "total_jokes": {batch_size},
    "focus_trait": "{focus_trait}",
    "humor_emphasis": "{humor_emphasis}",
    "categories": {batch_categories}
  }},
  "jokes": [
    {{
      "joke_id": "JOKE_æ‰¹æ¬¡å·_åºå·ï¼ˆå¦‚JOKE_01_001ï¼‰",
      "category": "å…·ä½“åˆ†ç±»",
      "difficulty_level": "ç®€å•/ä¸­ç­‰/å¤æ‚",
      "humor_style": "å†·å¹½é»˜/è‡ªå˜²/è§‚å¯Ÿå¼/åå·®èŒ",
      "setup": "ç¬‘è¯é“ºå«éƒ¨åˆ†ï¼Œè®¾ç½®æƒ…å¢ƒ",
      "punchline": "ç¬‘è¯çš„ç¬‘ç‚¹éƒ¨åˆ†",
      "context": "ç¬‘è¯çš„èƒŒæ™¯è¯´æ˜",
      "character_traits": ["ä½“ç°çš„äººè®¾ç‰¹å¾1", "ä½“ç°çš„äººè®¾ç‰¹å¾2"],
      "tags": ["ç›¸å…³æ ‡ç­¾1", "ç›¸å…³æ ‡ç­¾2", "ç›¸å…³æ ‡ç­¾3"]
    }},
    // ... ç»§ç»­åˆ°ç¬¬{batch_size}æ¡
  ]
}}
```

# é‡è¦æé†’
1. **æ•°é‡è¦æ±‚**ï¼šå¿…é¡»ç”Ÿæˆå‡†ç¡®çš„{batch_size}æ¡ç¬‘è¯
2. **IDè§„èŒƒ**ï¼šjoke_idä½¿ç”¨æ ¼å¼"JOKE_æ‰¹æ¬¡å·_åºå·"ï¼Œå¦‚"JOKE_01_001"
3. **è´¨é‡è¦æ±‚**ï¼šæ¯æ¡ç¬‘è¯éƒ½è¦æœ‰æ˜ç¡®çš„setupå’Œpunchline
4. **äººè®¾ç¬¦åˆåº¦**ï¼šæ¯æ¡ç¬‘è¯éƒ½è¦ä½“ç°æ–¹çŸ¥è¡¡çš„å…·ä½“äººè®¾ç‰¹å¾
5. **åŸåˆ›æ€§**ï¼šç¡®ä¿å†…å®¹åŸåˆ›ï¼Œé¿å…é‡å¤å·²æœ‰ç¬‘è¯
6. **æŠ€æœ¯è¦æ±‚**ï¼šç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®

è¯·å¼€å§‹ç”Ÿæˆè¿™æ‰¹å……æ»¡æ–¹çŸ¥è¡¡ç‰¹è‰²çš„å¹½é»˜ç¬‘è¯ã€‚
"""
        
        # è°ƒç”¨LLMç”Ÿæˆç¬‘è¯
        if llm:
            try:
                from core.types import Message, MessageRole
                message = Message(role=MessageRole.USER, content=generation_prompt)
                messages = [message]
                
                logger.info(f"ç¬‘è¯ç”Ÿæˆæ‰¹æ¬¡ {current_batch_index + 1}: å¼€å§‹LLMè°ƒç”¨")
                
                # æµå¼è°ƒç”¨LLM
                final_content = ""
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True
                ):
                    content_part = chunk_data.get("content", "")
                    final_content += content_part
                
                logger.info(f"æ‰¹æ¬¡ {current_batch_index + 1} LLMç”Ÿæˆå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"æ‰¹æ¬¡ {current_batch_index + 1} LLMè°ƒç”¨å¤±è´¥: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            raise Exception("LLMæœªåˆå§‹åŒ–")
        
        # è§£æJSONç»“æœ
        jokes_data = None
        try:
            json_content = self._extract_json_from_content(final_content)
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'jokes' in parsed_result:
                jokes_data = parsed_result
                generated_jokes = jokes_data.get('jokes', [])
                logger.info(f"æ‰¹æ¬¡ {current_batch_index + 1} æˆåŠŸè§£æï¼ŒåŒ…å« {len(generated_jokes)} æ¡ç¬‘è¯")
                
                if workflow_chat:
                    await workflow_chat.add_node_message(
                        "ç¬‘è¯ç”Ÿæˆ",
                        f"âœ… æ‰¹æ¬¡ {current_batch_index + 1} ç”Ÿæˆå®Œæˆï¼ˆ{len(generated_jokes)}æ¡ç¬‘è¯ï¼‰",
                        "success"
                    )
            else:
                raise Exception(f"æ‰¹æ¬¡è§£æå¤±è´¥ï¼šç¼ºå°‘jokeså­—æ®µ")
                
        except Exception as parse_error:
            logger.error(f"æ‰¹æ¬¡ {current_batch_index + 1} JSONè§£æå¤±è´¥: {parse_error}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç¬‘è¯ç”Ÿæˆ",
                    f"âš ï¸ æ‰¹æ¬¡ {current_batch_index + 1} è§£æå¤±è´¥ï¼Œè·³è¿‡",
                    "warning"
                )
            jokes_data = None
        
        # æ„å»ºè¾“å‡ºæ•°æ®
        output_data = input_data.copy()
        output_data['generated_jokes'] = jokes_data.get('jokes', []) if jokes_data else []
        output_data['current_batch_index'] = current_batch_index + 1
        
        print(f"âœ… æ‰¹æ¬¡ {current_batch_index + 1} ç¬‘è¯ç”Ÿæˆå®Œæˆ")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        return content.strip()


class QualityCheckNode(BaseNode):
    """è´¨é‡æ£€æŸ¥èŠ‚ç‚¹ - æ£€æŸ¥ç”Ÿæˆçš„ç¬‘è¯è´¨é‡å’Œäººè®¾ç¬¦åˆåº¦"""
    
    def __init__(self):
        super().__init__(name="quality_check", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œè´¨é‡æ£€æŸ¥èŠ‚ç‚¹"""
        print("ğŸ” å¼€å§‹è´¨é‡æ£€æŸ¥...")
        
        workflow_chat = input_data.get('workflow_chat')
        generated_jokes = input_data.get('generated_jokes', [])
        
        if not generated_jokes:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "è´¨é‡æ£€æŸ¥",
                    "âš ï¸ æ²¡æœ‰ç¬‘è¯éœ€è¦æ£€æŸ¥",
                    "warning"
                )
            yield input_data
            return
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "è´¨é‡æ£€æŸ¥",
                f"æ­£åœ¨æ£€æŸ¥{len(generated_jokes)}æ¡ç¬‘è¯çš„è´¨é‡...",
                "progress"
            )
        
        # è´¨é‡æ£€æŸ¥é€»è¾‘
        checked_jokes = []
        filtered_count = 0
        
        for joke in generated_jokes:
            try:
                # åŸºæœ¬å­—æ®µæ£€æŸ¥
                required_fields = ['joke_id', 'category', 'setup', 'punchline']
                if not all(field in joke and joke[field] for field in required_fields):
                    filtered_count += 1
                    continue
                
                # å†…å®¹é•¿åº¦æ£€æŸ¥
                setup = joke.get('setup', '')
                punchline = joke.get('punchline', '')
                
                if len(setup) < 10 or len(punchline) < 5:
                    filtered_count += 1
                    continue
                
                if len(setup) > 300 or len(punchline) > 200:
                    filtered_count += 1
                    continue
                
                # å†…å®¹å¥åº·æ€§æ£€æŸ¥ï¼ˆç®€å•å…³é”®è¯è¿‡æ»¤ï¼‰
                sensitive_words = ['æ”¿æ²»', 'å®—æ•™', 'ç§æ—', 'è‰²æƒ…', 'æš´åŠ›']
                content_check = setup + punchline
                if any(word in content_check for word in sensitive_words):
                    filtered_count += 1
                    continue
                
                # é€šè¿‡æ£€æŸ¥çš„ç¬‘è¯
                joke['quality_score'] = self._calculate_quality_score(joke)
                checked_jokes.append(joke)
                
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç¬‘è¯æ—¶å‡ºé”™: {e}")
                filtered_count += 1
                continue
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "è´¨é‡æ£€æŸ¥",
                f"âœ… è´¨é‡æ£€æŸ¥å®Œæˆï¼š{len(checked_jokes)}æ¡é€šè¿‡ï¼Œ{filtered_count}æ¡è¢«è¿‡æ»¤",
                "success"
            )
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        checked_jokes.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
        
        output_data = input_data.copy()
        output_data['checked_jokes'] = checked_jokes
        output_data['filtered_count'] = filtered_count
        
        logger.info(f"âœ… è´¨é‡æ£€æŸ¥å®Œæˆï¼Œ{len(checked_jokes)}æ¡ç¬‘è¯é€šè¿‡æ£€æŸ¥")
        yield output_data
    
    def _calculate_quality_score(self, joke: Dict[str, Any]) -> int:
        """è®¡ç®—ç¬‘è¯è´¨é‡åˆ†æ•°"""
        score = 50  # åŸºç¡€åˆ†æ•°
        
        # é•¿åº¦åˆç†æ€§åŠ åˆ†
        setup_len = len(joke.get('setup', ''))
        punchline_len = len(joke.get('punchline', ''))
        
        if 50 <= setup_len <= 150:
            score += 10
        if 20 <= punchline_len <= 100:
            score += 10
        
        # äººè®¾ç‰¹å¾åŠ åˆ†
        traits = joke.get('character_traits', [])
        if len(traits) >= 2:
            score += 15
        
        # æ ‡ç­¾ä¸°å¯Œåº¦åŠ åˆ†
        tags = joke.get('tags', [])
        if len(tags) >= 3:
            score += 10
        
        # å†…å®¹åŸåˆ›æ€§åˆ¤æ–­ï¼ˆç®€å•å®ç°ï¼‰
        if 'æ–¹çŸ¥è¡¡' in joke.get('setup', '') or 'æ–¹çŸ¥è¡¡' in joke.get('punchline', ''):
            score += 5
        
        return min(score, 100)


class JokeDatabaseSaveNode(BaseNode):
    """æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹ - å°†æ£€æŸ¥è¿‡çš„ç¬‘è¯ä¿å­˜åˆ°PostgreSQL"""
    
    def __init__(self):
        super().__init__(name="joke_database_save", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åº“ä¿å­˜èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œæ•°æ®åº“ä¿å­˜èŠ‚ç‚¹"""
        print("ğŸ’¾ å¼€å§‹ä¿å­˜åˆ°PostgreSQLæ•°æ®åº“...")
        
        workflow_chat = input_data.get('workflow_chat')
        checked_jokes = input_data.get('checked_jokes', [])
        pg_config = input_data.get('pg_config', {})
        
        if not checked_jokes:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    "âš ï¸ æ²¡æœ‰ç¬‘è¯éœ€è¦ä¿å­˜",
                    "warning"
                )
            yield input_data
            return
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "æ•°æ®åº“ä¿å­˜",
                f"æ­£åœ¨å°†{len(checked_jokes)}æ¡ç¬‘è¯ä¿å­˜åˆ°æ•°æ®åº“...",
                "progress"
            )
        
        try:
            # è¿æ¥æ•°æ®åº“
            conn = psycopg2.connect(**pg_config)
            cursor = conn.cursor()
            
            # æ‰¹é‡æ’å…¥ç¬‘è¯
            success_count = 0
            duplicate_count = 0
            error_count = 0
            
            for joke in checked_jokes:
                try:
                    insert_sql = """
                    INSERT INTO jokes (
                        joke_id, category, difficulty_level, humor_style,
                        setup, punchline, context, character_traits, tags, rating
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (joke_id) DO NOTHING
                    """
                    
                    cursor.execute(insert_sql, (
                        joke.get('joke_id'),
                        joke.get('category'),
                        joke.get('difficulty_level', 'ä¸­ç­‰'),
                        joke.get('humor_style', 'å†·å¹½é»˜'),
                        joke.get('setup'),
                        joke.get('punchline'),
                        joke.get('context', ''),
                        joke.get('character_traits', []),
                        joke.get('tags', []),
                        joke.get('quality_score', 50)
                    ))
                    
                    if cursor.rowcount > 0:
                        success_count += 1
                    else:
                        duplicate_count += 1
                        
                except Exception as e:
                    logger.warning(f"ä¿å­˜å•æ¡ç¬‘è¯å¤±è´¥: {e}")
                    error_count += 1
                    continue
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            cursor.close()
            conn.close()
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    f"âœ… ä¿å­˜å®Œæˆï¼š{success_count}æ¡æˆåŠŸï¼Œ{duplicate_count}æ¡é‡å¤ï¼Œ{error_count}æ¡å¤±è´¥",
                    "success"
                )
            
            output_data = input_data.copy()
            output_data.update({
                'save_success': True,
                'saved_count': success_count,
                'duplicate_count': duplicate_count,
                'error_count': error_count,
                'save_message': f"æˆåŠŸä¿å­˜{success_count}æ¡ç¬‘è¯åˆ°æ•°æ®åº“"
            })
            
            logger.info(f"âœ… æ•°æ®åº“ä¿å­˜å®Œæˆï¼š{success_count}æ¡æˆåŠŸä¿å­˜")
            yield output_data
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    f"âŒ ä¿å­˜å¤±è´¥: {str(e)}",
                    "error"
                )
            
            output_data = input_data.copy()
            output_data.update({
                'save_success': False,
                'save_message': f"ä¿å­˜å¤±è´¥ï¼š{str(e)}"
            })
            yield output_data 
"""
å‰§æƒ…ç”Ÿæˆå·¥ä½œæµ - åŸºäºGraph+Nodeçš„å‰§æƒ…åˆ›ä½œç³»ç»Ÿ
é›†æˆè§’è‰²åº“ã€åœ°ç‚¹åº“ã€å‰§æƒ…ç”Ÿæˆç­‰åŠŸèƒ½
"""

import json
import asyncio
import csv
import random
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole

logger = logging.getLogger(__name__)

class StoryWorkflow:
    """å‰§æƒ…ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None
        self.characters_data = {}
        self.locations_data = {}
        self.protagonist_data = ""  # ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾
        self.current_config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',  # å›ºå®šä¸»è§’
            'selected_characters': [],
            'selected_locations': [],
            'story_type': 'daily_life',  # daily_life, romance, adventure, mystery
            'story_length': 'medium',    # short, medium, long
            'relationship_depth': 'casual',  # casual, close, intimate
            'time_setting': 'current',   # current, specific_date
            'mood_tone': 'neutral',      # light, neutral, serious, dramatic
            'interaction_level': 'normal'  # minimal, normal, intensive
        }
        
        # åŠ è½½è§’è‰²ã€åœ°ç‚¹å’Œä¸»è§’æ•°æ®
        self._load_game_data()
        self._load_protagonist_data()
    
    def _load_game_data(self):
        """åŠ è½½æ¸¸æˆè§’è‰²å’Œåœ°ç‚¹æ•°æ®"""
        try:
            # åŠ è½½è§’è‰²æ•°æ®
            char_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_characters.json')
            if os.path.exists(char_path):
                with open(char_path, 'r', encoding='utf-8') as f:
                    self.characters_data = json.load(f)
                    logger.info(f"æˆåŠŸåŠ è½½è§’è‰²æ•°æ®ï¼ŒåŒ…å« {len(self.characters_data.get('è§’è‰²åˆ—è¡¨', {}))} ä¸ªè§’è‰²")
            
            # åŠ è½½åœ°ç‚¹æ•°æ®
            loc_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_locations.json')
            if os.path.exists(loc_path):
                with open(loc_path, 'r', encoding='utf-8') as f:
                    self.locations_data = json.load(f)
                    district_count = len(self.locations_data.get("districts", {}))
                    logger.info(f"æˆåŠŸåŠ è½½åœ°ç‚¹æ•°æ®ï¼ŒåŒ…å« {district_count} ä¸ªåŒºåŸŸ")
                    
        except Exception as e:
            logger.error(f"åŠ è½½æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
    
    def _load_protagonist_data(self):
        """åŠ è½½ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾"""
        try:
            protagonist_path = os.path.join(os.path.dirname(__file__), '../../config/åŸºç¡€äººè®¾.txt')
            if os.path.exists(protagonist_path):
                with open(protagonist_path, 'r', encoding='utf-8') as f:
                    self.protagonist_data = f.read()
                    logger.info(f"æˆåŠŸåŠ è½½ä¸»è§’äººè®¾ï¼Œå†…å®¹é•¿åº¦: {len(self.protagonist_data)} å­—ç¬¦")
            else:
                logger.warning("ä¸»è§’äººè®¾æ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            logger.error(f"åŠ è½½ä¸»è§’äººè®¾å¤±è´¥: {e}")
    
    def get_protagonist_info(self) -> Dict[str, Any]:
        """è·å–ä¸»è§’ä¿¡æ¯"""
        return {
            'name': 'æ–¹çŸ¥è¡¡',
            'type': 'protagonist',
            'description': 'äº‘æ¢å¤§å­¦å¤©æ–‡ç³»å®¢åº§æ•™æˆã€é¦™ä¸˜å¤©æ–‡é™¢ç ”ç©¶å‘˜ï¼Œ28å²ï¼Œç†æ€§ä¸¥è°¨ã€å†…æ•›æ¸©å’Œã€å¹³ç­‰åŒ…å®¹ã€è´£ä»»æ„Ÿå¼º',
            'full_profile': self.protagonist_data[:200] + "..." if len(self.protagonist_data) > 200 else self.protagonist_data
        }
    
    def get_characters_list(self) -> List[Dict[str, Any]]:
        """è·å–è§’è‰²åˆ—è¡¨ï¼ˆä¸åŒ…å«ä¸»è§’ï¼‰"""
        characters = []
        char_list = self.characters_data.get("è§’è‰²åˆ—è¡¨", {})
        
        for name, info in char_list.items():
            # è·³è¿‡ä¸»è§’ï¼Œä¸»è§’å•ç‹¬å¤„ç†
            if name == 'æ–¹çŸ¥è¡¡':
                continue
                
            characters.append({
                'name': name,
                'age': info.get('å¹´é¾„', 'æœªçŸ¥'),
                'personality': info.get('æ€§æ ¼', ''),
                'description': info.get('ç®€ä»‹', ''),
                'locations': info.get('æ´»åŠ¨åœ°ç‚¹', []),
                'plots': info.get('å¯è§¦å‘å‰§æƒ…', []),
                'backstory': info.get('èƒŒæ™¯æ•…äº‹', ''),
                'relationships': info.get('äººé™…å…³ç³»', {}),
                'habits': info.get('ç”Ÿæ´»ä¹ æƒ¯', []),
                'appearance': info.get('å¤–è²Œç‰¹å¾', ''),
                'skills': info.get('ç‰¹é•¿æŠ€èƒ½', [])
            })
        
        return characters
    
    def get_character_details(self, character_name: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šè§’è‰²çš„è¯¦ç»†ä¿¡æ¯"""
        char_list = self.characters_data.get("è§’è‰²åˆ—è¡¨", {})
        char_info = char_list.get(character_name, {})
        
        if not char_info:
            return {}
            
        return {
            'name': character_name,
            'age': char_info.get('å¹´é¾„', 'æœªçŸ¥'),
            'personality': char_info.get('æ€§æ ¼', ''),
            'description': char_info.get('ç®€ä»‹', ''),
            'backstory': char_info.get('èƒŒæ™¯æ•…äº‹', ''),
            'relationships': char_info.get('äººé™…å…³ç³»', {}),
            'habits': char_info.get('ç”Ÿæ´»ä¹ æƒ¯', []),
            'appearance': char_info.get('å¤–è²Œç‰¹å¾', ''),
            'skills': char_info.get('ç‰¹é•¿æŠ€èƒ½', []),
            'locations': char_info.get('æ´»åŠ¨åœ°ç‚¹', []),
            'plots': char_info.get('å¯è§¦å‘å‰§æƒ…', []),
            'dialogue_style': char_info.get('å¯¹è¯é£æ ¼', ''),
            'motivations': char_info.get('åŠ¨æœºç›®æ ‡', [])
        }
    
    def get_locations_list(self) -> List[Dict[str, Any]]:
        """è·å–åœ°ç‚¹åˆ—è¡¨"""
        locations = []
        districts = self.locations_data.get("districts", {})
        
        for district_name, district_info in districts.items():
            district_locations = district_info.get("locations", {})
            for loc_name, loc_info in district_locations.items():
                locations.append({
                    'name': loc_info.get('name', loc_name),
                    'type': loc_info.get('type', ''),
                    'district': district_info.get('name', district_name),
                    'description': loc_info.get('description', ''),
                    'atmosphere': loc_info.get('atmosphere', ''),
                    'keywords': loc_info.get('keywords', [])
                })
        
        return locations
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def create_story_graph(self) -> StateGraph:
        """åˆ›å»ºå‰§æƒ…ç”Ÿæˆå›¾å·¥ä½œæµ"""
        self.graph = StateGraph(name="story_generation_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹ï¼ˆç§»é™¤è§’è‰²åˆ†æèŠ‚ç‚¹ï¼‰
        story_plan_node = StoryPlanningNode()
        plot_generation_node = PlotGenerationNode()
        csv_export_node = CSVExportNode()
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("story_planning", story_plan_node)
        self.graph.add_node("plot_generation", plot_generation_node)
        self.graph.add_node("csv_export", csv_export_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»ï¼ˆç›´æ¥ä»è§„åˆ’åˆ°ç”Ÿæˆï¼‰
        self.graph.add_edge("story_planning", "plot_generation")
        self.graph.add_edge("plot_generation", "csv_export")
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("story_planning")
        
        return self.graph
    
    async def execute_story_generation(self, config: Dict[str, Any]) -> TaskResult:
        """æ‰§è¡Œå‰§æƒ…ç”Ÿæˆå·¥ä½œæµ"""
        if not self.graph:
            await self.create_story_graph()
        
        # å‡†å¤‡åˆå§‹è¾“å…¥
        initial_input = {
            'characters_data': self.characters_data,
            'locations_data': self.locations_data,
            'protagonist_data': self.protagonist_data,
            'config': config,
            'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
            'selected_characters': config.get('selected_characters', []),
            'selected_locations': config.get('selected_locations', []),
            'story_type': config.get('story_type', 'daily_life'),
            'story_length': config.get('story_length', 'medium'),
            'relationship_depth': config.get('relationship_depth', 'casual'),
            'time_setting': config.get('time_setting', 'current'),
            'mood_tone': config.get('mood_tone', 'neutral'),
            'interaction_level': config.get('interaction_level', 'normal')
        }
        
        # ç¼–è¯‘å¹¶æ‰§è¡Œå›¾å·¥ä½œæµ
        compiled_graph = self.graph.compile()
        result = await compiled_graph.invoke(initial_input)
        
        return result

    async def execute_workflow_stream(self, config: Dict[str, Any], workflow_chat):
        """æµå¼æ‰§è¡Œå·¥ä½œæµ - ä½¿ç”¨StateGraphè‡ªåŠ¨ç¼–æ’"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'characters_data': self.characters_data,
                'locations_data': self.locations_data,
                'protagonist_data': self.protagonist_data,  # æ·»åŠ ä¸»è§’å®Œæ•´äººè®¾
                'config': config,
                'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
                'selected_characters': config.get('selected_characters', []),
                'selected_locations': config.get('selected_locations', []),
                'story_count': config.get('story_count', 5),  # å‰§æƒ…æ•°é‡é…ç½®
                'story_type': config.get('story_type', 'daily_life'),
                'story_length': config.get('story_length', 'medium'),
                'relationship_depth': config.get('relationship_depth', 'casual'),
                'time_setting': config.get('time_setting', 'current'),
                'mood_tone': config.get('mood_tone', 'neutral'),
                'interaction_level': config.get('interaction_level', 'normal'),
                'workflow_chat': workflow_chat,  # ä¼ é€’UIæ›´æ–°å™¨
                'llm': self.llm  # ä¼ é€’LLMå®ä¾‹
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_story_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    # å·¥ä½œæµå¼€å§‹
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    # èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
                    node_display_name = self._get_node_display_name(node_name)
                    workflow_chat.current_node = self._get_node_id(node_name)
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "active"),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    # èŠ‚ç‚¹æµå¼æ‰§è¡Œä¸­ - å®æ—¶æ›´æ–°UIæ˜¾ç¤ºè¿›åº¦
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        # è·å–å½“å‰ç”Ÿæˆçš„å†…å®¹é•¿åº¦
                        content_length = 0
                        for key in ['planning_result', 'plot_content']:
                            if key in intermediate_result.state_update:
                                content_length = len(intermediate_result.state_update[key])
                                break
                        
                        # å®æ—¶æ›´æ–°è¿›åº¦ä¿¡æ¯ - é‡è¦ï¼šè·å–æœ€æ–°çš„è¿›åº¦HTMLï¼Œå› ä¸ºèŠ‚ç‚¹å†…éƒ¨å·²ç»æ›´æ–°äº†ç»“æœ
                        if content_length > 0:
                            yield (
                                workflow_chat._create_workflow_progress(),  # è¿™ä¸ªä¼šåŒ…å«èŠ‚ç‚¹å†…éƒ¨æ›´æ–°çš„æœ€æ–°å†…å®¹
                                "",  # å¿«æ·å›å¤åŒºåŸŸä¿æŒç©º
                                f"æ­£åœ¨ç”Ÿæˆå†…å®¹... å½“å‰é•¿åº¦: {content_length} å­—ç¬¦",
                                False  # å‘é€æŒ‰é’®ä¿æŒç¦ç”¨
                            )
                
                elif event_type == 'node_complete':
                    # èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
                    node_display_name = self._get_node_display_name(node_name)
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "completed"),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    # èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    
                    await workflow_chat.add_node_message(
                        "ç³»ç»Ÿ",
                        f"èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "error"),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    # å·¥ä½œæµå®Œæˆ
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                # å…¶ä»–äº‹ä»¶ç±»å‹å¯ä»¥å¿½ç•¥æˆ–è®°å½•æ—¥å¿—
                else:
                    # æŒç»­æ›´æ–°UIä»¥ä¿æŒæµç•…æ€§
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"å·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow_chat.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow_chat.update_node_state("planning", "error"),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'story_planning': 'å‰§æƒ…è§„åˆ’',
            'plot_generation': 'å‰§æƒ…ç”Ÿæˆ',
            'csv_export': 'CSVå¯¼å‡º'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'story_planning': 'planning',
            'plot_generation': 'plot', 
            'csv_export': 'export'
        }
        return id_mapping.get(node_name, node_name)


class StoryPlanningNode(BaseNode):
    """å‰§æƒ…è§„åˆ’èŠ‚ç‚¹ - åˆ†æè§’è‰²å…³ç³»å’Œæ•…äº‹å¤§çº²"""
    
    def __init__(self):
        super().__init__(name="story_planning", stream=True)
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå‰§æƒ…è§„åˆ’èŠ‚ç‚¹ - æ¯ä¸ªLLM chunkéƒ½yield"""
        print("ğŸ¯ å¼€å§‹å‰§æƒ…è§„åˆ’...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–æ‰€æœ‰é…ç½®å‚æ•°
        protagonist_data = input_data.get('protagonist_data', '')
        characters_data = input_data.get('characters_data', {})
        locations_data = input_data.get('locations_data', {})
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        story_count = input_data.get('story_count', 5)  # å‰§æƒ…æ•°é‡
        story_type = input_data.get('story_type', 'daily_life')
        story_length = input_data.get('story_length', 'medium')
        relationship_depth = input_data.get('relationship_depth', 'casual')
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å‰§æƒ…è§„åˆ’",
                "æ­£åœ¨åˆ†æä¸»è§’æ–¹çŸ¥è¡¡ä¸é€‰å®šè§’è‰²çš„å…³ç³»ï¼Œç”Ÿæˆå‰§æƒ…æ¡†æ¶...",
                "progress"
            )
        
        # æ„å»ºè¯¦ç»†çš„è§’è‰²ä¿¡æ¯
        character_details = []
        char_list = characters_data.get("è§’è‰²åˆ—è¡¨", {})
        for char_name in selected_characters:
            if char_name in char_list:
                char_info = char_list[char_name]
                detail = f"""
## {char_name}

- å¹´é¾„ï¼š{char_info.get('å¹´é¾„', 'æœªçŸ¥')}
- æ€§æ ¼ï¼š{char_info.get('æ€§æ ¼', '')}
- ç®€ä»‹ï¼š{char_info.get('ç®€ä»‹', '')}
- èƒŒæ™¯æ•…äº‹ï¼š{char_info.get('èƒŒæ™¯æ•…äº‹', '')}
- æ´»åŠ¨åœ°ç‚¹ï¼š{', '.join(char_info.get('æ´»åŠ¨åœ°ç‚¹', []))}
- äººé™…å…³ç³»ï¼š{char_info.get('äººé™…å…³ç³»', {})}
- å¯è§¦å‘å‰§æƒ…ï¼š{', '.join(char_info.get('å¯è§¦å‘å‰§æƒ…', []))}
"""
                character_details.append(detail)
        
        # æ„å»ºè¯¦ç»†çš„åœ°ç‚¹ä¿¡æ¯
        location_details = []
        districts = locations_data.get("districts", {})
        for loc_name in selected_locations:
            for district_name, district_info in districts.items():
                locations = district_info.get("locations", {})
                for location_key, location_info in locations.items():
                    if location_info.get('name') == loc_name or location_key == loc_name:
                        detail = f"""
## {location_info.get('name', loc_name)}ï¼ˆ{district_info.get('name', district_name)}åŒºï¼‰

- ç±»å‹ï¼š{location_info.get('type', '')}
- æè¿°ï¼š{location_info.get('description', '')}
- æ°›å›´ï¼š{location_info.get('atmosphere', '')}
- å…³é”®è¯ï¼š{', '.join(location_info.get('keywords', []))}
"""
                        location_details.append(detail)
        
        # æ„å»ºé€šç”¨çš„å‰§æƒ…è§„åˆ’æç¤ºè¯
        planning_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å‰§æƒ…ç­–åˆ’å¸ˆï¼Œéœ€è¦åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ¶å®šå‰§æƒ…è§„åˆ’æ¡†æ¶ï¼š

# ä¸»è§’è®¾å®š

{protagonist_data}

# å‚ä¸è§’è‰²ä¿¡æ¯

{''.join(character_details) if character_details else 'æ— å…¶ä»–è§’è‰²å‚ä¸'}

# åœ°ç‚¹ä¿¡æ¯

{''.join(location_details) if location_details else 'æ— ç‰¹å®šåœ°ç‚¹é™åˆ¶'}

# å‰§æƒ…é…ç½®

- å‰§æƒ…æ•°é‡ï¼š{story_count} ä¸ªå¤§å‰§æƒ…
- å‰§æƒ…ç±»å‹ï¼š{story_type}
- å‰§æƒ…ç»†åˆ†ç¨‹åº¦ï¼š{story_length}ï¼ˆæ¯ä¸ªå‰§æƒ…åŒ…å«çš„ç‹¬ç«‹å°èŠ‚æ•°é‡ï¼‰
- å…³ç³»æ·±åº¦ï¼š{relationship_depth}

**é‡è¦è¦æ±‚**ï¼š
1. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹çš„ä¸€å¹•æ¼”ç»ï¼Œä¸èƒ½æœ‰æ—¶é—´æˆ–ç©ºé—´çš„è¿ç»­æ€§
2. è¿™äº›å°èŠ‚ä¼šè¢«åˆ†å¸ƒåˆ°ä»»æ„æ—¶é—´åœ°ç‚¹ä½¿ç”¨ï¼Œå¿…é¡»å®Œå…¨ç‹¬ç«‹
3. æ¯ä¸ªå°èŠ‚å¿…é¡»åŒ…å«å®Œæ•´çš„å››å¹•å¼ç»“æ„ï¼ˆå¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€ï¼‰
4. æ¯ä¸ªå°èŠ‚éƒ½å¿…é¡»å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²

# è¾“å‡ºè¦æ±‚

è¯·ä»¥JSONæ ¼å¼è¾“å‡º **{story_count} ä¸ªå®Œæ•´å¤§å‰§æƒ…** çš„è§„åˆ’æ¡†æ¶ï¼Œé‡ç‚¹å…³æ³¨ç‹¬ç«‹å°èŠ‚çš„è®¾è®¡ï¼š

```json
{{
  "planning": {{
    "æ€»ä½“è®¾è®¡": {{
      "å‰§æƒ…æ€»æ•°": {story_count},
      "æ•´ä½“ä¸»é¢˜": "æ‰€æœ‰å‰§æƒ…çš„ç»Ÿä¸€ä¸»é¢˜",
      "è§’è‰²å…³ç³»ç½‘ç»œ": {{
        "ä¸»è§’å…³ç³»å®šä½": {{
          "ä¸è§’è‰²A": "å…·ä½“å…³ç³»å®šä½å’Œå‘å±•è·¯å¾„",
          "ä¸è§’è‰²B": "å…·ä½“å…³ç³»å®šä½å’Œå‘å±•è·¯å¾„"
        }},
        "è§’è‰²é—´å…³ç³»": "ç›¸äº’å…³ç³»å’Œäº’åŠ¨æ¨¡å¼",
        "å…³ç³»å‘å±•è·¯å¾„": "å…³ç³»æ¼”å˜çš„å¯èƒ½æ€§å’Œæ–¹å‘"
      }},
      "åœ°ç‚¹è¿ç”¨ç­–ç•¥": {{
        "åœ°ç‚¹åŠŸèƒ½å®šä½": {{
          "åœ°ç‚¹1": "åœ¨å‰§æƒ…ä¸­çš„åŠŸèƒ½å®šä½å’Œæ°›å›´ä½œç”¨",
          "åœ°ç‚¹2": "åœ¨å‰§æƒ…ä¸­çš„åŠŸèƒ½å®šä½å’Œæ°›å›´ä½œç”¨"
        }},
        "æ°›å›´è¥é€ ": "åœ°ç‚¹æ°›å›´å¦‚ä½•æœåŠ¡äºæƒ…èŠ‚å‘å±•",
        "ç©ºé—´è½¬æ¢æ„ä¹‰": "ç©ºé—´è½¬æ¢çš„å™äº‹ä½œç”¨"
      }}
    }},
    "å‰§æƒ…è§„åˆ’åˆ—è¡¨": [
      {{
        "å‰§æƒ…ID": "STORY_001",
        "å‰§æƒ…åç§°": "ç¬¬1ä¸ªå¤§å‰§æƒ…çš„åç§°",
        "æ•…äº‹ä¸»é¢˜ä¸æ ¸å¿ƒå†²çª": {{
          "æ•…äº‹ä¸»é¢˜": "åŸºäºä¸»è§’æ€§æ ¼ç‰¹å¾å’Œç”Ÿæ´»èƒŒæ™¯ç¡®å®šçš„ä¸»é¢˜",
          "æ ¸å¿ƒå†²çª": "ç»“åˆå‚ä¸è§’è‰²è®¾è®¡çš„åˆç†å†²çªç‚¹"
        }},
        "ä¸»è¦å‰§æƒ…çº¿": {{
          "å¼€ç«¯": "è®¾å®šèƒŒæ™¯å’Œåˆå§‹æƒ…å†µçš„å…·ä½“æè¿°",
          "å‘å±•": "çŸ›ç›¾é€æ­¥å‡çº§å’Œè§’è‰²äº’åŠ¨çš„è¯¦ç»†è¿‡ç¨‹",
          "é«˜æ½®": "æ ¸å¿ƒå†²çªè¾¾åˆ°é¡¶ç‚¹çš„å…³é”®äº‹ä»¶",
          "ç»“å±€": "é—®é¢˜è§£å†³å’Œè§’è‰²æˆé•¿çš„å®Œæ•´æè¿°"
        }},
        "å…³é”®äº‹ä»¶èŠ‚ç‚¹": [
          {{
            "äº‹ä»¶å": "é‡è¦è½¬æŠ˜ç‚¹æè¿°",
            "è§¦å‘æ¡ä»¶": "å‰ç½®è¦æ±‚å’Œæ¡ä»¶",
            "é¢„æœŸç»“æœ": "å¯¹åç»­å‰§æƒ…çš„å½±å“",
            "é€»è¾‘å…³è”": "ä¸å…¶ä»–äº‹ä»¶çš„é€»è¾‘å…³ç³»"
          }}
        ],
        "æƒ…æ„Ÿå¼ åŠ›è®¾è®¡": {{
          "æƒ…æ„ŸåŸºè°ƒ": "æ ¹æ®é…ç½®çš„mood_toneè®¾è®¡åŸºè°ƒ",
          "æƒ…æ„Ÿèµ·ä¼æ›²çº¿": "æƒ…æ„Ÿå‘å±•çš„å…·ä½“å®‰æ’",
          "è¡¨è¾¾æ–¹å¼": "ç¬¦åˆä¸»è§’æ€§æ ¼çš„æƒ…æ„Ÿè¡¨è¾¾",
          "ç†æ€§æ„Ÿæ€§å¹³è¡¡": "ç†æ€§ä¸æ„Ÿæ€§å†²çªçš„å¤„ç†"
        }}
      }}
    ]
  }}
}}
```

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®ç”Ÿæˆ **{story_count} ä¸ªå®Œæ•´çš„å¤§å‰§æƒ…è§„åˆ’**
2. æ¯ä¸ªå‰§æƒ…çš„å…³é”®äº‹ä»¶èŠ‚ç‚¹è®¾è®¡è¦è€ƒè™‘ç‹¬ç«‹å°èŠ‚çš„ç‰¹æ€§
3. è§’è‰²å…³ç³»ç½‘ç»œæ¸…æ™°è¯¦ç»†ï¼Œé€‚ç”¨äºæ‰€æœ‰å‰§æƒ…
4. åœ°ç‚¹è¿ç”¨ç­–ç•¥è¦æ”¯æŒç‹¬ç«‹åœºæ™¯çš„è®¾è®¡
5. æƒ…æ„Ÿå¼ åŠ›è®¾è®¡è¦åœ¨å•ä¸ªå°èŠ‚å†…å½¢æˆå®Œæ•´å¼§çº¿
6. æ‰€æœ‰å‰§æƒ…ç›¸äº’ç‹¬ç«‹ï¼Œæ¯ä¸ªå°èŠ‚ä¹Ÿå¿…é¡»ç‹¬ç«‹
7. æ¯ä¸ªå‰§æƒ…éƒ½æœ‰ç‹¬ç‰¹çš„å†²çªç‚¹ï¼Œä½†è¦èƒ½åˆ†è§£ä¸ºç‹¬ç«‹çš„å°èŠ‚æƒ…å¢ƒ
"""
        
        # æµå¼è°ƒç”¨LLMå¹¶åœ¨æ¯ä¸ªchunkæ—¶yield
        full_content = ""
        if llm:
            try:
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                message = Message(role=MessageRole.USER, content=planning_prompt)
                messages = [message]
                
                logger.info(f"å‰§æƒ…è§„åˆ’: å¼€å§‹æµå¼LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(planning_prompt)}")
                
                # ä½¿ç”¨thinkæ¨¡å¼æµå¼è°ƒç”¨
                chunk_count = 0
                think_content = ""
                final_content = ""
                full_content = ""  # åˆå§‹åŒ–full_contentå˜é‡ï¼Œç”¨äºå…¼å®¹æ¨¡å¼
                
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True  # å·¥ä½œæµéœ€è¦å­—å…¸æ ¼å¼æ¥åŒºåˆ†thinkå’Œcontent
                ):
                    chunk_count += 1
                    
                    # thinkæ¨¡å¼è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼š{"think": "æ€è€ƒå†…å®¹", "content": "æ­£å¼å›ç­”"}
                    if isinstance(chunk_data, dict):
                        think_part = chunk_data.get("think", "")
                        content_part = chunk_data.get("content", "")
                        
                        think_content += think_part
                        final_content += content_part
                        
                        # å®æ—¶æ›´æ–°UI - æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œæ­£å¼å†…å®¹
                        if workflow_chat:
                            try:
                                # æ„å»ºå¸¦æ ·å¼åŒºåˆ†çš„æ˜¾ç¤ºå†…å®¹
                                display_content = ""
                                if think_content.strip():
                                    display_content += f"""
<div style="background: #f8f9fa; border-left: 4px solid #6c757d; padding: 10px; margin: 10px 0; border-radius: 4px;">
ğŸ¤” æ€è€ƒè¿‡ç¨‹ï¼š<br>
{think_content}
</div>"""
                                
                                if final_content.strip():
                                    display_content += f"""
<div style="background: #e8f5e9; border-left: 4px solid #28a745; padding: 10px; margin: 10px 0; border-radius: 4px;">
ğŸ“‹ è§„åˆ’ç»“æœï¼š<br>
{final_content}
</div>"""
                                
                                await workflow_chat.add_node_message(
                                    "å‰§æƒ…è§„åˆ’",
                                    display_content,
                                    "streaming"
                                )
                            except Exception as ui_error:
                                logger.warning(f"å‰§æƒ…è§„åˆ’UIæ›´æ–°å¤±è´¥: {ui_error}")
                    else:
                        # å…¼å®¹å­—ç¬¦ä¸²æ ¼å¼
                        full_content += str(chunk_data)
                        final_content = full_content
                        
                        if workflow_chat:
                            try:
                                await workflow_chat.add_node_message(
                                    "å‰§æƒ…è§„åˆ’",
                                    full_content,
                                    "streaming"
                                )
                            except Exception as ui_error:
                                logger.warning(f"å‰§æƒ…è§„åˆ’UIæ›´æ–°å¤±è´¥: {ui_error}")
                    
                    # æ¯ä¸ªchunkéƒ½yieldï¼Œè®©StateGraphExecutorèƒ½å®æ—¶æ„ŸçŸ¥è¿›åº¦
                    yield {
                        'planning_result': final_content,  # åªä¼ é€’æ­£å¼å†…å®¹ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                        'planning_think': think_content,   # ä¿å­˜æ€è€ƒè¿‡ç¨‹ç”¨äºè°ƒè¯•
                        'chunk_progress': f"{chunk_count} chunks processed"
                    }
                
                logger.info(f"å‰§æƒ…è§„åˆ’: æµå¼ç”Ÿæˆå®Œæˆï¼Œæ€»chunkæ•°: {chunk_count}ï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"å‰§æƒ…è§„åˆ’LLMè°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            error_msg = "å‰§æƒ…è§„åˆ’: LLMæœªåˆå§‹åŒ–"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # æµå¼æ˜¾ç¤ºå·²ç»åŒ…å«å®Œæ•´ç»“æœï¼Œæ— éœ€é¢å¤–çš„å®ŒæˆçŠ¶æ€æ˜¾ç¤º
        
        # å°è¯•è§£æJSONæ ¼å¼çš„ç»“æœ
        try:
            # ä½¿ç”¨BaseNodeçš„parseåŠŸèƒ½è§£æJSON
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            
            # ä»ç”Ÿæˆçš„å†…å®¹ä¸­æå–JSONéƒ¨åˆ†
            json_content = self._extract_json_from_content(final_content)
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'planning' in parsed_result:
                planning_data = parsed_result['planning']
                logger.info(f"æˆåŠŸè§£æå‰§æƒ…è§„åˆ’JSONç»“æœ:{planning_data}")
            else:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºå¤‡é€‰
                planning_data = final_content
                logger.warning(f"å‰§æƒ…è§„åˆ’JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹:{planning_data}")
                
        except Exception as parse_error:
            logger.warning(f"å‰§æƒ…è§„åˆ’JSONè§£æå¼‚å¸¸: {parse_error}ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            planning_data = final_content
        
        # æœ€ç»ˆå®Œæ•´ç»“æœ
        output_data = input_data.copy()
        output_data['planning_result'] = planning_data  # ä¼ é€’è§£æåçš„ç»“æœç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        
        print(f"âœ… å‰§æƒ…è§„åˆ’å®Œæˆï¼Œplanning_dataç±»å‹: {type(planning_data)}")
        logger.info(f"å‰§æƒ…è§„åˆ’èŠ‚ç‚¹è¾“å‡ºæ•°æ®: planning_resultç±»å‹={type(planning_data)}")
        logger.info(f"å‰§æƒ…è§„åˆ’èŠ‚ç‚¹è¾“å‡ºæ•°æ®é”®: {list(output_data.keys())}")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œå®é™…ä½¿ç”¨ execute_stream"""
        last_result = None
        async for result in self.execute_stream(input_data):
            last_result = result
        return last_result



class PlotGenerationNode(BaseNode):
    """å‰§æƒ…ç”ŸæˆèŠ‚ç‚¹ - ç”Ÿæˆå…·ä½“çš„å‰§æƒ…äº‹ä»¶"""
    
    def __init__(self):
        super().__init__(name="plot_generation", stream=True)
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå‰§æƒ…ç”ŸæˆèŠ‚ç‚¹ - æ¯ä¸ªLLM chunkéƒ½yield"""
        print("ğŸ“š å¼€å§‹ç”Ÿæˆå‰§æƒ…...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        planning_result = input_data.get('planning_result', '')
        
        # è°ƒè¯•ï¼šè¾“å‡ºinput_dataçš„é”®å’Œå€¼
        logger.info(f"å‰§æƒ…ç”ŸæˆèŠ‚ç‚¹æ¥æ”¶åˆ°çš„input_dataé”®: {list(input_data.keys())}")
        logger.info(f"planning_resultç±»å‹: {type(planning_result)}")
        logger.info(f"planning_resultå€¼: {repr(planning_result[:100]) if planning_result else 'Noneæˆ–ç©º'}")
        logger.info(f"planning_resultæ˜¯å¦ä¸ºç©ºå­—ç¬¦ä¸²: {planning_result == ''}")
        logger.info(f"planning_resulté•¿åº¦: {len(planning_result) if planning_result else 0}")
        
        # éªŒè¯è§„åˆ’ç»“æœ
        if not planning_result or not planning_result.strip():
            error_msg = f"å‰§æƒ…ç”Ÿæˆå¤±è´¥ï¼šç¼ºå°‘å‰§æƒ…è§„åˆ’ç»“æœã€‚input_dataé”®: {list(input_data.keys())}"
            logger.error(error_msg)
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å‰§æƒ…ç”Ÿæˆ",
                    error_msg,
                    "error"
                )
            raise Exception(error_msg)
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å‰§æƒ…ç”Ÿæˆ", 
                f"æ­£åœ¨åŸºäºè§„åˆ’ç»“æœç”Ÿæˆå…·ä½“å‰§æƒ…ï¼ˆè§„åˆ’é•¿åº¦ï¼š{len(planning_result)} å­—ç¬¦ï¼‰...",
                "progress"
            )
        
        # è·å–å®Œæ•´çš„é…ç½®å’Œè§„åˆ’ç»“æœ
        protagonist_data = input_data.get('protagonist_data', '')
        characters_data = input_data.get('characters_data', {})
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        story_count = input_data.get('story_count', 5)  # å‰§æƒ…æ•°é‡
        story_type = input_data.get('story_type', 'daily_life')
        story_length = input_data.get('story_length', 'medium')
        relationship_depth = input_data.get('relationship_depth', 'casual')
        
        # æ„å»ºé€šç”¨çš„å‰§æƒ…ç”Ÿæˆæç¤ºè¯
        plot_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å‰§æƒ…ç¼–å‰§ï¼Œéœ€è¦åŸºäºå‰§æƒ…è§„åˆ’ç”Ÿæˆå…·ä½“çš„å‰§æƒ…å†…å®¹ã€‚

# å‰§æƒ…è§„åˆ’

{planning_result}

# è§’è‰²è®¾å®š

{protagonist_data}

# å‰§æƒ…é…ç½®

- å‰§æƒ…æ•°é‡ï¼š{story_count} ä¸ªå¤§å‰§æƒ…
- å‰§æƒ…ç±»å‹ï¼š{story_type}
- å‰§æƒ…ç»†åˆ†ç¨‹åº¦ï¼š{story_length}ï¼ˆæ¯ä¸ªå‰§æƒ…åŒ…å«çš„ç‹¬ç«‹å°èŠ‚æ•°é‡ï¼‰
- å…³ç³»æ·±åº¦ï¼š{relationship_depth}

**æ ¸å¿ƒè¦æ±‚**ï¼š
1. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹çš„ä¸€å¹•æ¼”ç»ï¼ŒåŒ…å«å®Œæ•´çš„å››å¹•å¼ç»“æ„
2. æ¯ä¸ªå°èŠ‚å¿…é¡»åŒæ—¶å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²
3. å°èŠ‚ä¹‹é—´æ²¡æœ‰æ—¶é—´ç©ºé—´è”ç³»ï¼Œå¯ä»¥åœ¨ä»»æ„æ—¶é—´åœ°ç‚¹ä½¿ç”¨
4. æ¯ä¸ªå°èŠ‚éƒ½æœ‰å¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€çš„å®Œæ•´æˆå‰§å¼§çº¿

# è¾“å‡ºè¦æ±‚

è¯·åŸºäºè§„åˆ’ä¸­çš„ **{story_count} ä¸ªå¤§å‰§æƒ…**ï¼Œä»¥JSONæ ¼å¼è¾“å‡ºä¸°å¯Œçš„ç‹¬ç«‹å°èŠ‚å†…å®¹ï¼š

```json
{{
  "story": {{
    "æ€»ä½“ä¿¡æ¯": {{
      "å‰§æƒ…æ€»æ•°": {story_count},
      "ç”Ÿæˆæ—¶é—´": "{{ç”Ÿæˆæ—¶é—´}}",
      "ä¸»è§’": "æ–¹çŸ¥è¡¡"
    }},
    "å‰§æƒ…åˆ—è¡¨": [
      {{
        "å‰§æƒ…ID": "STORY_001",
        "å‰§æƒ…åç§°": "ç¬¬1ä¸ªå¤§å‰§æƒ…çš„åç§°",
        "å‰§æƒ…å°èŠ‚": [
          {{
            "å°èŠ‚ID": "S001_SCENE_001",
            "å°èŠ‚æ ‡é¢˜": "ç‹¬ç«‹å°èŠ‚çš„æ ‡é¢˜",
            "å°èŠ‚å†…å®¹": "å®Œæ•´çš„æ•…äº‹å†…å®¹ï¼Œè‡ªç„¶èå…¥å››å¹•å¼ç»“æ„ï¼ˆå¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€ï¼‰ï¼ŒåŒ…å«è§’è‰²å¯¹è¯å’Œæƒ…æ„Ÿå˜åŒ–ï¼Œä½“ç°ç‹¬ç«‹å®Œæ•´çš„ä¸€å¹•æ¼”ç»ï¼Œç¦æ­¢åŒ…å«æ—¶é—´",
            "åœ°ç‚¹": "å‘ç”Ÿåœ°ç‚¹",
            "å‚ä¸è§’è‰²": ["æ–¹çŸ¥è¡¡", "æŒ‡å®šè§’è‰²å"]
          }}
        ],
        "å‰§æƒ…æ€»ç»“": {{
          "ä¸»è¦å†²çª": "æ ¸å¿ƒçŸ›ç›¾ç‚¹",
          "æƒ…æ„Ÿå‘å±•": "è§’è‰²å…³ç³»çš„æ•´ä½“å‘å±•",
          "åç»­é“ºå«": "ä¸ºåç»­å‰§æƒ…è®¾ç½®çš„ä¼ç¬”"
        }}
      }}
    ]
  }}
}}
```

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®ç”Ÿæˆ **{story_count} ä¸ªå®Œæ•´çš„å¤§å‰§æƒ…**
2. æ¯ä¸ªå¤§å‰§æƒ…æ ¹æ®story_lengthè®¾ç½®ç”Ÿæˆç›¸åº”æ•°é‡çš„ç‹¬ç«‹å°èŠ‚ï¼š
   - short: 1-2ä¸ªç‹¬ç«‹å°èŠ‚
   - medium: 3-5ä¸ªç‹¬ç«‹å°èŠ‚  
   - long: 5-8ä¸ªç‹¬ç«‹å°èŠ‚
3. **å°èŠ‚å†…å®¹å¿…é¡»æ˜¯å®Œæ•´çš„æ•…äº‹æ®µè½**ï¼Œè‡ªç„¶èå…¥å››å¹•å¼ç»“æ„
4. **æ¯ä¸ªå°èŠ‚éƒ½å¿…é¡»åŒæ—¶å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²**
5. **å°èŠ‚å®Œå…¨ç‹¬ç«‹**ï¼Œä¸ä¾èµ–å‰åå°èŠ‚çš„æ—¶é—´ç©ºé—´è”ç³»
6. **å¯¹è¯å’Œæƒ…æ„Ÿå˜åŒ–è‡ªç„¶èå…¥æ•…äº‹å†…å®¹**ï¼Œä¸å•ç‹¬åˆ†ç¦»
7. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹å®Œæ•´çš„ä¸€å¹•æ¼”ç»ï¼Œå¯ä»¥å•ç‹¬ä½¿ç”¨
8. å†…å®¹ç”ŸåŠ¨è¯¦ç»†ï¼ŒåŒ…å«åœºæ™¯æè¿°ã€è§’è‰²äº’åŠ¨ã€å†²çªè§£å†³
"""
        
        # æµå¼è°ƒç”¨LLM
        full_content = ""
        if llm:
            try:
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                message = Message(role=MessageRole.USER, content=plot_prompt)
                messages = [message]
                
                logger.info(f"å‰§æƒ…ç”Ÿæˆ: å¼€å§‹æµå¼LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(plot_prompt)}")
                
                # ä½¿ç”¨thinkæ¨¡å¼æµå¼è°ƒç”¨
                chunk_count = 0
                think_content = ""
                final_content = ""
                full_content = ""  # å…¼å®¹æ¨¡å¼
                
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True  # å·¥ä½œæµéœ€è¦å­—å…¸æ ¼å¼æ¥åŒºåˆ†thinkå’Œcontent
                ):
                    chunk_count += 1
                    
                    # thinkæ¨¡å¼è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼š{"think": "æ€è€ƒå†…å®¹", "content": "æ­£å¼å›ç­”"}
                    if isinstance(chunk_data, dict):
                        think_part = chunk_data.get("think", "")
                        content_part = chunk_data.get("content", "")
                        
                        think_content += think_part
                        final_content += content_part
                        
                        # å®æ—¶æ›´æ–°UI - æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œæ­£å¼å†…å®¹
                        if workflow_chat:
                            try:
                                # æ„å»ºå¸¦æ ·å¼åŒºåˆ†çš„æ˜¾ç¤ºå†…å®¹
                                display_content = ""
                                if think_content.strip():
                                    display_content += f"""
<div style="background: #f8f9fa; border-left: 4px solid #6c757d; padding: 10px; margin: 10px 0; border-radius: 4px;">
ğŸ¤” æ€è€ƒè¿‡ç¨‹ï¼š<br>
{think_content}
</div>"""
                                
                                if final_content.strip():
                                    display_content += f"""
<div style="background: #e8f5e9; border-left: 4px solid #28a745; padding: 10px; margin: 10px 0; border-radius: 4px;">
ğŸ“– å‰§æƒ…å†…å®¹ï¼š<br>
{final_content}
</div>"""
                                
                                await workflow_chat.add_node_message(
                                    "å‰§æƒ…ç”Ÿæˆ",
                                    display_content,
                                    "streaming"
                                )
                            except Exception as ui_error:
                                logger.warning(f"å‰§æƒ…ç”ŸæˆUIæ›´æ–°å¤±è´¥: {ui_error}")
                    else:
                        # å…¼å®¹å­—ç¬¦ä¸²æ ¼å¼
                        full_content += str(chunk_data)
                        final_content = full_content
                        
                        if workflow_chat:
                            try:
                                await workflow_chat.add_node_message(
                                    "å‰§æƒ…ç”Ÿæˆ",
                                    full_content,
                                    "streaming"
                                )
                            except Exception as ui_error:
                                logger.warning(f"å‰§æƒ…ç”ŸæˆUIæ›´æ–°å¤±è´¥: {ui_error}")
                    
                    # æ¯ä¸ªchunkéƒ½yieldï¼Œåªä¼ é€’æ­£å¼å†…å®¹ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                    yield {
                        'plot_content': final_content,  # åªä¼ é€’æ­£å¼å†…å®¹
                        'plot_think': think_content,    # ä¿å­˜æ€è€ƒè¿‡ç¨‹ç”¨äºè°ƒè¯•
                        'chunk_progress': f"{chunk_count} chunks processed"
                    }
                
                logger.info(f"å‰§æƒ…ç”Ÿæˆ: æµå¼ç”Ÿæˆå®Œæˆï¼Œæ€»chunkæ•°: {chunk_count}ï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"å‰§æƒ…ç”ŸæˆLLMè°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            error_msg = f"å‰§æƒ…ç”Ÿæˆ: LLMæœªåˆå§‹åŒ–"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # æµå¼æ˜¾ç¤ºå·²ç»åŒ…å«å®Œæ•´ç»“æœï¼Œæ— éœ€é¢å¤–çš„å®ŒæˆçŠ¶æ€æ˜¾ç¤º
        
        # å°è¯•è§£æJSONæ ¼å¼çš„ç»“æœ
        try:
            # ä½¿ç”¨BaseNodeçš„parseåŠŸèƒ½è§£æJSON
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            
            # ä»ç”Ÿæˆçš„å†…å®¹ä¸­æå–JSONéƒ¨åˆ†
            json_content = self._extract_json_from_content(final_content)
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'story' in parsed_result:
                story_data = parsed_result['story']
                logger.info("æˆåŠŸè§£æå‰§æƒ…ç”ŸæˆJSONç»“æœ")
            else:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºå¤‡é€‰
                story_data = final_content
                logger.warning("å‰§æƒ…ç”ŸæˆJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                
        except Exception as parse_error:
            logger.warning(f"å‰§æƒ…ç”ŸæˆJSONè§£æå¼‚å¸¸: {parse_error}ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            story_data = final_content
        
        output_data = input_data.copy()
        output_data['plot_content'] = story_data
        
        print("âœ… å‰§æƒ…ç”Ÿæˆå®Œæˆ")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œå®é™…ä½¿ç”¨ execute_stream"""
        last_result = None
        async for result in self.execute_stream(input_data):
            last_result = result
        return last_result


class CSVExportNode(BaseNode):
    """CSVå¯¼å‡ºèŠ‚ç‚¹ - å°†å‰§æƒ…æ•°æ®å¯¼å‡ºä¸ºCSVæ ¼å¼"""
    
    def __init__(self):
        super().__init__(name="csv_export")
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒCSVå¯¼å‡º - æ”¯æŒJSONæ•°æ®è§£æ"""
        print("ğŸ“„ å¼€å§‹å¯¼å‡ºCSV...")
        
        workflow_chat = input_data.get('workflow_chat')
        plot_content = input_data.get('plot_content', '')
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "CSVå¯¼å‡º",
                "æ­£åœ¨è§£æå‰§æƒ…æ•°æ®å¹¶å¯¼å‡ºä¸ºCSVæ ¼å¼...",
                "progress"
            )
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            from datetime import datetime
            import csv
            import os
            import json
            from pathlib import Path
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"story_plot_{timestamp}.csv"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = Path("workspace/output")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            filepath = output_dir / filename
            
            # CSVæ ‡é¢˜è¡Œ - ç®€åŒ–ç»“æ„
            csv_headers = [
                "å‰§æƒ…åç§°", "å°èŠ‚ID", "å°èŠ‚æ ‡é¢˜", "å°èŠ‚å†…å®¹", "åœ°ç‚¹", "å‚ä¸è§’è‰²"
            ]
            
            csv_data = []
            story_name = ""
            
            # è§£æJSONæ ¼å¼çš„å‰§æƒ…æ•°æ®
            if isinstance(plot_content, dict):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å¤šå‰§æƒ…æ ¼å¼
                if 'å‰§æƒ…åˆ—è¡¨' in plot_content:
                    # æ–°çš„å¤šå‰§æƒ…æ ¼å¼
                    story_list = plot_content.get('å‰§æƒ…åˆ—è¡¨', [])
                    total_scenes = 0
                    logger.info(f"æˆåŠŸè§£æå¤šå‰§æƒ…JSONæ ¼å¼æ•°æ®ï¼ŒåŒ…å« {len(story_list)} ä¸ªå¤§å‰§æƒ…")
                    
                    for story in story_list:
                        story_name = story.get('å‰§æƒ…åç§°', 'æœªå‘½åå‰§æƒ…')
                        story_id = story.get('å‰§æƒ…ID', '')
                        scenes = story.get('å‰§æƒ…å°èŠ‚', [])
                        total_scenes += len(scenes)
                        
                        for scene in scenes:
                            csv_data.append([
                                f"{story_name} ({story_id})",
                                scene.get('å°èŠ‚ID', ''),
                                scene.get('å°èŠ‚æ ‡é¢˜', ''),
                                scene.get('å°èŠ‚å†…å®¹', ''),
                                scene.get('åœ°ç‚¹', ''),
                                ', '.join(scene.get('å‚ä¸è§’è‰²', []))
                            ])
                    
                    story_name = f"å¤šå‰§æƒ…é›†åˆ({len(story_list)}ä¸ªå‰§æƒ…)"
                    
                elif 'å‰§æƒ…å°èŠ‚' in plot_content:
                    # æ—§çš„å•å‰§æƒ…æ ¼å¼
                    story_name = plot_content.get('å‰§æƒ…åç§°', 'æœªå‘½åå‰§æƒ…')
                    scenes = plot_content.get('å‰§æƒ…å°èŠ‚', [])
                    logger.info(f"æˆåŠŸè§£æå•å‰§æƒ…JSONæ ¼å¼æ•°æ®ï¼Œå‰§æƒ…åç§°: {story_name}ï¼ŒåŒ…å« {len(scenes)} ä¸ªå°èŠ‚")
                    
                    for scene in scenes:
                        csv_data.append([
                            story_name,
                            scene.get('å°èŠ‚ID', ''),
                            scene.get('å°èŠ‚æ ‡é¢˜', ''),
                            scene.get('å°èŠ‚å†…å®¹', ''),
                            scene.get('åœ°ç‚¹', ''),
                            ', '.join(scene.get('å‚ä¸è§’è‰²', []))
                        ])
                else:
                    raise ValueError("æ— æ³•è¯†åˆ«çš„å‰§æƒ…æ•°æ®æ ¼å¼")
                    
            elif isinstance(plot_content, str):
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­è§£æJSON
                try:
                    # ä½¿ç”¨JSONParserè§£æ
                    from parsers.json_parser import JSONParser
                    parser = JSONParser()
                    
                    # æå–JSONå†…å®¹
                    json_content = self._extract_json_from_content(plot_content)
                    parsed_data = parser.parse(json_content)
                    
                    if parsed_data and 'story' in parsed_data:
                        story_data = parsed_data['story']
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å¤šå‰§æƒ…æ ¼å¼
                        if 'å‰§æƒ…åˆ—è¡¨' in story_data:
                            # æ–°çš„å¤šå‰§æƒ…æ ¼å¼
                            story_list = story_data.get('å‰§æƒ…åˆ—è¡¨', [])
                            total_scenes = 0
                            logger.info(f"ä»å­—ç¬¦ä¸²è§£æå¤šå‰§æƒ…JSONæˆåŠŸï¼ŒåŒ…å« {len(story_list)} ä¸ªå¤§å‰§æƒ…")
                            
                            for story in story_list:
                                story_name_item = story.get('å‰§æƒ…åç§°', 'æœªå‘½åå‰§æƒ…')
                                story_id = story.get('å‰§æƒ…ID', '')
                                scenes = story.get('å‰§æƒ…å°èŠ‚', [])
                                total_scenes += len(scenes)
                                
                                for scene in scenes:
                                    csv_data.append([
                                        f"{story_name_item} ({story_id})",
                                        scene.get('å°èŠ‚ID', ''),
                                        scene.get('å°èŠ‚æ ‡é¢˜', ''),
                                        scene.get('å°èŠ‚å†…å®¹', ''),
                                        scene.get('åœ°ç‚¹', ''),
                                        ', '.join(scene.get('å‚ä¸è§’è‰²', []))
                                    ])
                            
                            story_name = f"å¤šå‰§æƒ…é›†åˆ({len(story_list)}ä¸ªå‰§æƒ…)"
                            
                        elif 'å‰§æƒ…å°èŠ‚' in story_data:
                            # æ—§çš„å•å‰§æƒ…æ ¼å¼
                            story_name = story_data.get('å‰§æƒ…åç§°', 'æœªå‘½åå‰§æƒ…')
                            scenes = story_data.get('å‰§æƒ…å°èŠ‚', [])
                            logger.info(f"ä»å­—ç¬¦ä¸²è§£æå•å‰§æƒ…JSONæˆåŠŸï¼Œå‰§æƒ…åç§°: {story_name}ï¼ŒåŒ…å« {len(scenes)} ä¸ªå°èŠ‚")
                            
                            for scene in scenes:
                                csv_data.append([
                                    story_name,
                                    scene.get('å°èŠ‚ID', ''),
                                    scene.get('å°èŠ‚æ ‡é¢˜', ''),
                                    scene.get('å°èŠ‚å†…å®¹', ''),
                                    scene.get('åœ°ç‚¹', ''),
                                    ', '.join(scene.get('å‚ä¸è§’è‰²', []))
                                ])
                        else:
                            raise ValueError("æœªæ‰¾åˆ°story.å‰§æƒ…åˆ—è¡¨æˆ–story.å‰§æƒ…å°èŠ‚å­—æ®µ")
                    else:
                        raise ValueError("æœªæ‰¾åˆ°storyå­—æ®µ")
                        
                except Exception as parse_error:
                    logger.warning(f"JSONè§£æå¤±è´¥: {parse_error}ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æ®µæ–¹å¼")
                    # å›é€€åˆ°ç®€å•æ–‡æœ¬åˆ†æ®µæ–¹å¼
                    story_name = "æ–‡æœ¬è§£æå‰§æƒ…"
                    lines = plot_content.split('\n')
                    for i, line in enumerate(lines[:10]):
                        if line.strip():
                            csv_data.append([
                                story_name,
                                f"SCENE_{i+1:03d}",
                                f"ç¬¬{i+1}èŠ‚",
                                line,
                                "é»˜è®¤åœ°ç‚¹",
                                "ä¸»è§’"
                            ])
            else:
                logger.error(f"æ— æ³•å¤„ç†çš„å‰§æƒ…æ•°æ®ç±»å‹: {type(plot_content)}")
                raise ValueError(f"æ— æ³•å¤„ç†çš„å‰§æƒ…æ•°æ®ç±»å‹: {type(plot_content)}")
            
            # å†™å…¥CSVæ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(csv_headers)
                writer.writerows(csv_data)
            
            # è·å–ç»å¯¹è·¯å¾„
            abs_filepath = str(filepath.absolute())
            
            # ç”Ÿæˆç»“æœä¿¡æ¯
            result = f"""âœ… CSVå¯¼å‡ºæˆåŠŸï¼

# æ–‡ä»¶ä¿¡æ¯

- æ–‡ä»¶åï¼š{filename}
- ä¿å­˜è·¯å¾„ï¼š{filepath}
- ç»å¯¹è·¯å¾„ï¼š{abs_filepath}

# ç»Ÿè®¡ä¿¡æ¯

- å‰§æƒ…åç§°ï¼š{story_name}
- å¯¼å‡ºå°èŠ‚æ•°ï¼š{len(csv_data)} ä¸ª
- CSVå­—æ®µæ•°ï¼š{len(csv_headers)} ä¸ª
- æ•°æ®è§£ææ–¹å¼ï¼š{'JSONç»“æ„åŒ–è§£æ' if isinstance(plot_content, dict) else 'JSONå­—ç¬¦ä¸²è§£æ'}

# è®¿é—®æ–‡ä»¶

ğŸ”— ç‚¹å‡»æ‰“å¼€æ–‡ä»¶ï¼šfile:///{abs_filepath.replace(os.sep, '/')}
ğŸ“‚ åœ¨æ–‡ä»¶å¤¹ä¸­æŸ¥çœ‹ï¼š{filepath.parent}

# ä¸‹è½½è¯´æ˜

æ–‡ä»¶å·²ä¿å­˜åˆ°é¡¹ç›®çš„ workspace/output ç›®å½•ä¸­ã€‚
"""
            
            # æ›´æ–°UI - å®ŒæˆçŠ¶æ€
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "CSVå¯¼å‡º",
                    result,
                    "completed"
                )
            
            output_data = input_data.copy()
            output_data['export_file'] = str(filepath)
            output_data['csv_data'] = csv_data
            output_data['csv_headers'] = csv_headers
            
            print(f"âœ… CSVå¯¼å‡ºå®Œæˆ: {filepath}")
            return output_data
            
        except Exception as e:
            error_msg = f"CSVå¯¼å‡ºå¤±è´¥: {str(e)}"
            print(error_msg)
            logger.error(error_msg, exc_info=True)
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "CSVå¯¼å‡º",
                    error_msg,
                    "error"
                )
            
            raise e
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip() 
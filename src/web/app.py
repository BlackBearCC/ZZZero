"""
Gradioåº”ç”¨ä¸»æ–‡ä»¶ - æä¾›ç±»ChatGPTé£æ ¼çš„ç•Œé¢
"""
import gradio as gr
import asyncio
import logging
from typing import List, Dict, Any, Optional, Tuple
import json
from datetime import datetime

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.types import AgentType, ToolConfig, LLMConfig, TaskResult
from agents.react_agent import ReactAgent
from llm.base import LLMFactory

from tools.mcp_tools import MCPToolManager 

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class AgentApp:
    """Agentåº”ç”¨ç•Œé¢"""
    
    def __init__(self, 
                 title: str = "ZZZero AI Agent",
                 description: str = "åŸºäºèŠ‚ç‚¹ç¼–æ’çš„AI Agentæ¡†æ¶"):
        self.title = title
        self.description = description
        self.current_agent = None
        self.agent = None  # æ·»åŠ agentå±æ€§
        self.tool_manager = None
        self.llm = None
        # ä¿å­˜å½“å‰é…ç½®
        self.current_config = {
            'llm_provider': 'doubao',
            'model_name': 'ep-20250221154410-vh78x',
            'temperature': 0.7,
            'agent_type': 'react',
            'max_iterations': 5,
            'available_tools': [],
            'enabled_mcp_servers': []
        }
        
        # å·¥ä½œç©ºé—´é…ç½®
        self.workspace_config = {
            'base_dir': './workspace',
            'input_dir': './workspace/input',
            'output_dir': './workspace/output',
            'vectordb_dir': './workspace/vectordb',
            'temp_dir': './workspace/temp'
        }
        
        # åˆ›å»ºå·¥ä½œç©ºé—´ç›®å½•
        self._ensure_workspace_dirs()
        
    async def _update_agent_config(self):
        """æ›´æ–°Agenté…ç½®"""
        try:
            # åˆ›å»ºå·¥å…·ç®¡ç†å™¨ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
            if not self.tool_manager:
                self.tool_manager = MCPToolManager()
                await self.tool_manager.initialize()
            
            # åˆ›å»ºLLMå®ä¾‹ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
            if not self.llm:
                # åˆ›å»ºLLMé…ç½®å¯¹è±¡
                llm_config = LLMConfig(
                    provider=self.current_config.get('llm_provider', 'doubao'),
                    model_name=self.current_config.get('model_name', 'ep-20250221154410-vh78x'),
                    temperature=self.current_config.get('temperature', 0.7)
                )
                
                # ä½¿ç”¨å·¥å‚åˆ›å»ºLLMå®ä¾‹
                self.llm = LLMFactory.create(llm_config)
                await self.llm.initialize()
            
            # æ›´æ–°å·¥å…·ç®¡ç†å™¨çš„å¯ç”¨æœåŠ¡å™¨ï¼ˆä»…åœ¨å·¥å…·ç®¡ç†å™¨å­˜åœ¨æ—¶ï¼‰
            enabled_servers = self.current_config.get('enabled_mcp_servers', ['csv', 'chromadb', 'filemanager'])  # é»˜è®¤å¯ç”¨
            if self.tool_manager:
                self.tool_manager.set_enabled_servers(enabled_servers)
            
            # åˆ›å»ºæˆ–æ›´æ–°Agent
            self.agent = ReactAgent(
                llm=self.llm,  # ä¼ é€’LLMå®ä¾‹ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°
                tool_manager=self.tool_manager,
                max_iterations=self.current_config.get('max_iterations', 10),
                name="æ™ºèƒ½åŠ©æ‰‹"
            )
            
            # åŒæ—¶è®¾ç½®current_agentä»¥å…¼å®¹å…¶ä»–æ–¹æ³•
            self.current_agent = self.agent
            
            logger.info("Agenté…ç½®æ›´æ–°æˆåŠŸ")
            
        except Exception as e:
            error_msg = f"æ›´æ–°Agenté…ç½®å¤±è´¥: {e}"
            logger.error(error_msg)
            return error_msg
    
    def _ensure_workspace_dirs(self):
        """ç¡®ä¿å·¥ä½œç©ºé—´ç›®å½•å­˜åœ¨"""
        import os
        for dir_path in self.workspace_config.values():
            os.makedirs(dir_path, exist_ok=True)
            logger.info(f"åˆ›å»ºå·¥ä½œç©ºé—´ç›®å½•: {dir_path}")
    
    def _list_files_in_dir(self, dir_path: str) -> List[Dict[str, Any]]:
        """åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶"""
        import os
        from pathlib import Path
        
        files = []
        if os.path.exists(dir_path):
            for item in Path(dir_path).iterdir():
                if item.is_file():
                    stat = item.stat()
                    files.append({
                        'name': item.name,
                        'path': str(item),
                        'size': stat.st_size,
                        'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                        'type': item.suffix.lower()
                    })
        return sorted(files, key=lambda x: x['modified'], reverse=True)
    
    def _format_file_list_html(self, files: List[Dict], title: str) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶åˆ—è¡¨ä¸ºHTML"""
        if not files:
            return f"<div style='padding: 10px; color: #666;'>{title}: æš‚æ— æ–‡ä»¶</div>"
        
        html = f"<div style='margin-bottom: 10px;'><strong>{title} ({len(files)} ä¸ªæ–‡ä»¶)</strong></div>"
        html += "<div style='max-height: 200px; overflow-y: auto; border: 1px solid #ddd; border-radius: 4px;'>"
        
        for file in files:
            size_str = self._format_file_size(file['size'])
            html += f"""
            <div style='padding: 8px; border-bottom: 1px solid #eee; display: flex; justify-content: space-between;'>
                <div>
                    <strong>{file['name']}</strong>
                    <div style='font-size: 0.8em; color: #666;'>{file['modified']}</div>
                </div>
                <div style='text-align: right; color: #888;'>{size_str}</div>
            </div>
            """
        html += "</div>"
        return html
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    

            
    def create_interface(self) -> gr.Blocks:
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(title=self.title, theme=gr.themes.Soft(), head="""
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>
        <script>
            document.addEventListener('DOMContentLoaded', function() {
                // åˆå§‹åŒ–highlight.js
                hljs.highlightAll();
                
                // ç›‘å¬DOMå˜åŒ–ä»¥é«˜äº®æ–°æ·»åŠ çš„ä»£ç å—
                const observer = new MutationObserver(function(mutations) {
                    mutations.forEach(function(mutation) {
                        mutation.addedNodes.forEach(function(node) {
                            if (node.nodeType === 1) {
                                // æŸ¥æ‰¾æ–°æ·»åŠ çš„ä»£ç å—
                                const codeBlocks = node.querySelectorAll('pre code, code');
                                codeBlocks.forEach(function(block) {
                                    if (!block.classList.contains('hljs')) {
                                        hljs.highlightElement(block);
                                    }
                                });
                            }
                        });
                    });
                });
                
                observer.observe(document.body, {
                    childList: true,
                    subtree: true
                });
            });
        </script>
        """) as app:
            # æ ‡é¢˜
            gr.Markdown(f"# {self.title}")
            gr.Markdown(f"{self.description}")
            
            with gr.Row():
                # å·¦ä¾§é…ç½®é¢æ¿
                with gr.Column(scale=1):
                    gr.Markdown("## âš™ï¸ é…ç½®é¢æ¿")
                    
                    # LLMé…ç½®
                    with gr.Accordion("ğŸ§  LLMé…ç½®", open=True):
                        llm_provider = gr.Dropdown(
                            choices=["doubao", "openai"],
                            value="doubao",
                            label="LLMæä¾›å•†"
                        )
                        model_name = gr.Textbox(
                            value="ep-20250221154410-vh78x",  # DOUBAO_MODEL_DEEPSEEKV3
                            label="æ¨¡å‹åç§°",
                            placeholder="ä¾‹å¦‚: ep-20250221154410-vh78x (deepseekv3)"
                        )
                        temperature = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.7,
                            step=0.1,
                            label="ç”Ÿæˆæ¸©åº¦"
                        )
                    
                    # Agenté…ç½®
                    with gr.Accordion("ğŸ¤– Agenté…ç½®", open=True):
                        agent_type = gr.Dropdown(
                            choices=["react"],
                            value="react",
                            label="Agentç±»å‹"
                        )
                        max_iterations = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=5,
                            step=1,
                            label="æœ€å¤§è¿­ä»£æ¬¡æ•°"
                        )
                    
                    # MCPæœåŠ¡å™¨ç®¡ç†
                    with gr.Accordion("ğŸ”Œ MCPæœåŠ¡å™¨ç®¡ç†", open=True):
                        # æœåŠ¡å™¨çŠ¶æ€å’Œå‹¾é€‰åœ¨ä¸€èµ·
                        mcp_servers_status = gr.HTML(
                            value="<p>æ­£åœ¨åŠ è½½MCPæœåŠ¡å™¨ä¿¡æ¯...</p>",
                            label="MCPæœåŠ¡å™¨çŠ¶æ€"
                        )
                        
                        # è·å–åˆå§‹çš„serversåˆ—è¡¨å¹¶è®¾ç½®é»˜è®¤å€¼
                        initial_choices = []
                        default_enabled = []
                        try:
                            if self.tool_manager:
                                servers_status = self.tool_manager.get_servers_status()
                                for server_id, server_info in servers_status.items():
                                    choice = (f"{server_info['name']} ({server_id})", server_id)
                                    initial_choices.append(choice)
                                    # é»˜è®¤å‹¾é€‰csvã€chromadbå’Œfilemanager
                                    if server_id in ['csv', 'chromadb', 'filemanager']:
                                        default_enabled.append(server_id)
                        except Exception as e:
                            print(f"åˆå§‹åŒ–MCPæœåŠ¡å™¨å¤±è´¥: {e}")
                        
                        enabled_mcp_servers = gr.CheckboxGroup(
                            choices=initial_choices,
                            value=default_enabled,
                            label="å¯ç”¨çš„MCPæœåŠ¡å™¨"
                        )
                        
                        # è¿œç¨‹æœåŠ¡å™¨æ·»åŠ 
                        with gr.Row():
                            remote_server_name = gr.Textbox(
                                placeholder="æœåŠ¡å™¨åç§°",
                                scale=2,
                                label="è¿œç¨‹æœåŠ¡å™¨åç§°"
                            )
                            remote_server_url = gr.Textbox(
                                placeholder="http://localhost:3000",
                                scale=3,
                                label="è¿œç¨‹æœåŠ¡å™¨URL"
                            )
                            add_remote_btn = gr.Button("æ·»åŠ è¿œç¨‹æœåŠ¡å™¨", scale=1)
                        
                        refresh_mcp_btn = gr.Button("åˆ·æ–°MCPæœåŠ¡å™¨", variant="secondary")
                    
                    # å·¥å…·é€‰æ‹©
                    with gr.Accordion("ğŸ”§ ä¼ ç»Ÿå·¥å…·é…ç½®", open=False):
                        available_tools = gr.CheckboxGroup(
                            choices=[
                                "web_search",
                                "calculator", 
                                "file_reader",
                                "code_executor",
                                "database_query"
                            ],
                            value=[],
                            label="å¯ç”¨çš„ä¼ ç»Ÿå·¥å…·"
                        )
                    
                    # æ–‡ä»¶ç®¡ç†
                    with gr.Accordion("ğŸ“ æ–‡ä»¶ç®¡ç†", open=True):
                        # æ–‡ä»¶ä¸Šä¼ 
                        with gr.Tab("ä¸Šä¼ æ–‡ä»¶"):
                            file_upload = gr.File(
                                label="ä¸Šä¼ æ–‡ä»¶åˆ°è¾“å…¥ç›®å½•",
                                file_count="multiple",
                                file_types=None
                            )
                            upload_btn = gr.Button("ä¸Šä¼ æ–‡ä»¶", variant="primary")
                            upload_status = gr.HTML()
                        
                        # æ–‡ä»¶æµè§ˆ
                        with gr.Tab("æ–‡ä»¶æµè§ˆ"):
                            refresh_files_btn = gr.Button("åˆ·æ–°æ–‡ä»¶åˆ—è¡¨", variant="secondary")
                            
                            input_files_display = gr.HTML(
                                value="<p>æ­£åœ¨åŠ è½½è¾“å…¥æ–‡ä»¶...</p>",
                                label="è¾“å…¥æ–‡ä»¶å¤¹"
                            )
                            
                            output_files_display = gr.HTML(
                                value="<p>æ­£åœ¨åŠ è½½è¾“å‡ºæ–‡ä»¶...</p>", 
                                label="è¾“å‡ºæ–‡ä»¶å¤¹"
                            )
                    
                    # é…ç½®çŠ¶æ€ï¼ˆåªæ˜¾ç¤ºï¼Œä¸éœ€è¦åº”ç”¨æŒ‰é’®ï¼‰
                    config_status = gr.Textbox(label="é…ç½®çŠ¶æ€", interactive=False, value="âœ… é…ç½®å·²è‡ªåŠ¨åº”ç”¨")
                
                # å³ä¾§èŠå¤©ç•Œé¢
                with gr.Column(scale=3):
                    # èŠå¤©å†å²
                    chatbot = gr.Chatbot(
                        height=500,
                        show_label=False,
                        elem_classes=["chat-window"],
                        type="messages",
                        render_markdown=True,
                        sanitize_html=False  # å…è®¸HTMLæ¸²æŸ“ä»¥æ”¯æŒé«˜äº®
                    )
                    
                    # è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        msg_input = gr.Textbox(
                            placeholder="è¾“å…¥æ¶ˆæ¯...",
                            show_label=False,
                            scale=9,
                            lines=1,
                            max_lines=5
                        )
                        send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                    
                    # æ‰¹é‡ä»»åŠ¡
                    with gr.Accordion("ğŸ“‹ æ‰¹é‡ä»»åŠ¡", open=False):
                        batch_input = gr.Textbox(
                            placeholder="æ¯è¡Œä¸€ä¸ªä»»åŠ¡...",
                            lines=5,
                            label="æ‰¹é‡ä»»åŠ¡åˆ—è¡¨"
                        )
                        batch_parallel = gr.Checkbox(
                            label="å¹¶è¡Œæ‰§è¡Œ",
                            value=True
                        )
                        batch_btn = gr.Button("æ‰§è¡Œæ‰¹é‡ä»»åŠ¡")
                        batch_results = gr.Dataframe(
                            headers=["ä»»åŠ¡", "çŠ¶æ€", "ç»“æœ", "è€—æ—¶"],
                            label="æ‰¹é‡ä»»åŠ¡ç»“æœ"
                        )
                    
                    # æ‰§è¡Œè¯¦æƒ…
                    with gr.Accordion("ğŸ“Š æ‰§è¡Œè¯¦æƒ…", open=False):
                        execution_trace = gr.JSON(label="æ‰§è¡Œè½¨è¿¹")
                        metrics_display = gr.Textbox(label="æ‰§è¡ŒæŒ‡æ ‡", lines=3)
                        
                    # æµç¨‹å¯è§†åŒ–
                    with gr.Accordion("ğŸ”„ æµç¨‹å¯è§†åŒ–", open=False):
                        # å®æ—¶èŠ‚ç‚¹çŠ¶æ€
                        node_status = gr.DataFrame(
                            headers=["èŠ‚ç‚¹", "ç±»å‹", "çŠ¶æ€", "è€—æ—¶(s)", "è¾“å‡ºé¢„è§ˆ"],
                            label="èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€",
                            interactive=False
                        )
                        # æµç¨‹å›¾
                        flow_diagram = gr.HTML(label="æ‰§è¡Œæµç¨‹å›¾")
                        # è‡ªåŠ¨åˆ·æ–°
                        auto_refresh = gr.Checkbox(label="è‡ªåŠ¨åˆ·æ–°", value=True)
            
            # === é…ç½®å˜åŒ–è‡ªåŠ¨åº”ç”¨ ===
            async def on_config_change(*args):
                """é…ç½®å˜åŒ–æ—¶è‡ªåŠ¨åº”ç”¨"""
                llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers = args
                
                # æ›´æ–°é…ç½®
                old_config = self.current_config.copy()
                self.current_config.update({
                    'llm_provider': llm_provider,
                    'model_name': model_name,
                    'temperature': temperature,
                    'agent_type': agent_type,
                    'max_iterations': max_iterations,
                    'available_tools': available_tools,
                    'enabled_mcp_servers': enabled_mcp_servers
                })
                
                # åªæœ‰åœ¨é…ç½®çœŸæ­£æ”¹å˜æ—¶æ‰æ›´æ–°Agent
                config_changed = old_config != self.current_config
                if config_changed:
                    await self._update_agent_config()
                    logger.info("é…ç½®å·²æ›´æ”¹ï¼ŒAgentå·²æ›´æ–°")
                
                total_tools = len(available_tools) + len(enabled_mcp_servers)
                status_text = f"âœ… é…ç½®å·²åº”ç”¨ï¼ä½¿ç”¨ {llm_provider}/{model_name}ï¼Œå¯ç”¨ {total_tools} ä¸ªå·¥å…·"
                if not config_changed:
                    status_text += " (æ— å˜åŒ–)"
                
                return status_text
            
            # ç»‘å®šé…ç½®å˜åŒ–äº‹ä»¶
            for component in [llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers]:
                component.change(
                    on_config_change,
                    inputs=[llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers],
                    outputs=[config_status]
                )
            
            # MCPæœåŠ¡å™¨ç›¸å…³äº‹ä»¶
            refresh_mcp_btn.click(
                self._refresh_mcp_servers,
                outputs=[mcp_servers_status, enabled_mcp_servers]
            )
            
            add_remote_btn.click(
                self._add_remote_server,
                inputs=[remote_server_name, remote_server_url],
                outputs=[remote_server_name, remote_server_url, mcp_servers_status, enabled_mcp_servers]
            )
            
            # é¡µé¢åŠ è½½æ—¶çš„åˆå§‹åŒ–
            async def on_load():
                """é¡µé¢åŠ è½½æ—¶çš„åˆå§‹åŒ–"""
                try:
                    # åˆå§‹åŒ–é…ç½®ï¼ˆMCPæœåŠ¡å™¨å·²åœ¨main.pyä¸­å¯åŠ¨ï¼‰
                    await self._update_agent_config()
                    
                    # è·å–æœåŠ¡å™¨çŠ¶æ€å¹¶æ›´æ–°ç•Œé¢
                    servers_status = self.tool_manager.get_servers_status() if self.tool_manager else {}
                    
                    # ç”ŸæˆçŠ¶æ€HTML
                    status_html = "<div style='font-family: monospace;'>"
                    status_html += "<h4>ğŸ”Œ MCPæœåŠ¡å™¨çŠ¶æ€</h4>"
                    
                    if not servers_status:
                        status_html += "<p>æš‚æ— å¯ç”¨çš„MCPæœåŠ¡å™¨</p>"
                    else:
                        for server_id, info in servers_status.items():
                            status_icon = "ğŸŸ¢" if info['running'] else "ğŸ”´"
                            enable_icon = "âœ…" if info.get('enabled', False) else "âšª"
                            
                            status_html += f"<div style='margin: 8px 0; padding: 8px; border: 1px solid #ddd; border-radius: 4px;'>"
                            status_html += f"<strong>{status_icon} {enable_icon} {info['name']}</strong><br/>"
                            status_html += f"<small>ID: {server_id} | çŠ¶æ€: {'è¿è¡Œä¸­' if info['running'] else 'æœªè¿è¡Œ'}</small><br/>"
                            status_html += f"<small>å·¥å…·: {info.get('enabled_tools', 0)}/{info.get('total_tools', 0)} ä¸ªå¯ç”¨</small><br/>"
                            status_html += f"<small>{info['description']}</small>"
                            status_html += "</div>"
                    
                    status_html += "</div>"
                    
                    # ç”Ÿæˆå¯é€‰æ‹©çš„æœåŠ¡å™¨åˆ—è¡¨
                    choices = []
                    default_enabled = []
                    
                    for server_id, info in servers_status.items():
                        label = f"{info['name']} ({server_id})"
                        choices.append((label, server_id))
                        # é»˜è®¤å‹¾é€‰å·²å¯ç”¨çš„æœåŠ¡å™¨
                        if info.get('enabled', False):
                            default_enabled.append(server_id)
                    
                    # è¿”å›çŠ¶æ€HTMLå’Œæ›´æ–°åçš„CheckboxGroupï¼Œä»¥åŠæ¼”ç¤ºæ¶ˆæ¯
                    import gradio as gr
                    demo_messages = [
                        {
                            "role": "assistant", 
                            "content": """ğŸ‰ æ¬¢è¿ä½¿ç”¨ ZZZero AI Agentï¼

**æ ·å¼æ¼”ç¤º**ï¼š

<span class="agent-keyword-question">Question:</span> è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ç¤ºä¾‹
<span class="agent-keyword-thought">Thought:</span> è¿™æ˜¯æ€è€ƒè¿‡ç¨‹
<span class="agent-keyword-action">Action:</span> è¿™æ˜¯æ‰§è¡Œçš„åŠ¨ä½œ
<span class="agent-keyword-action-input">Action Input:</span> è¿™æ˜¯åŠ¨ä½œè¾“å…¥
<span class="agent-keyword-observation">Observation:</span> è¿™æ˜¯è§‚å¯Ÿç»“æœ
<span class="agent-keyword-final-answer">Final Answer:</span> è¿™æ˜¯æœ€ç»ˆç­”æ¡ˆ

**ä»£ç å—ç¤ºä¾‹**ï¼š

```python
def hello_world():
    print("Hello, World!")
    return {"status": "success"}
```

```json
{
  "name": "ZZZero Agent",
  "version": "1.0.0",
  "features": ["markdown", "syntax_highlighting", "keyword_highlighting"]
}
```

å†…è”ä»£ç ï¼š`print("Hello")`

ç°åœ¨å¯ä»¥å¼€å§‹å¯¹è¯äº†ï¼"""
                        }
                    ]
                    
                    return (
                        status_html,
                        gr.update(choices=choices, value=default_enabled),
                        demo_messages
                    )
                    
                except Exception as e:
                    error_msg = f"é¡µé¢åŠ è½½åˆå§‹åŒ–å¤±è´¥: {e}"
                    logger.error(error_msg)
                    import gradio as gr
                    return (
                        f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}",
                        gr.update(choices=[], value=[]),
                        []
                    )
            
            app.load(
                on_load,
                outputs=[mcp_servers_status, enabled_mcp_servers, chatbot]
            )
            
            # MCPæœåŠ¡å™¨å‹¾é€‰å˜åŒ–äº‹ä»¶
            enabled_mcp_servers.change(
                self._on_mcp_servers_change,
                inputs=[enabled_mcp_servers],
                outputs=[mcp_servers_status]
            )
            
            # æ–‡ä»¶ç®¡ç†äº‹ä»¶
            upload_btn.click(
                self._upload_files,
                inputs=[file_upload],
                outputs=[upload_status, input_files_display]
            )
            
            refresh_files_btn.click(
                self._refresh_file_lists,
                outputs=[input_files_display, output_files_display]
            )
            
            # é¡µé¢åŠ è½½æ—¶åˆ·æ–°æ–‡ä»¶åˆ—è¡¨
            app.load(
                self._refresh_file_lists,
                outputs=[input_files_display, output_files_display]
            )
            
            msg_input.submit(
                self._stream_chat,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot, execution_trace, metrics_display, node_status, flow_diagram],
                show_progress=False  # ç¦ç”¨è¿›åº¦æ¡ä»¥æ”¯æŒæµå¼è¾“å‡º
            )
            
            send_btn.click(
                self._stream_chat,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot, execution_trace, metrics_display, node_status, flow_diagram],
                show_progress=False  # ç¦ç”¨è¿›åº¦æ¡ä»¥æ”¯æŒæµå¼è¾“å‡º
            )
            
            batch_btn.click(
                self._batch_execute,
                inputs=[batch_input, batch_parallel],
                outputs=[batch_results]
            )
            
            # æ·»åŠ è‡ªå®šä¹‰CSS
            app.css = """
            * {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
            }
            .chat-window {
                border-radius: 10px;
                border: 1px solid #e0e0e0;
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
            }
            .chat-window .message {
                padding: 10px;
                margin: 5px;
                border-radius: 10px;
            }
            .chat-window .user {
                background-color: #e3f2fd;
                margin-left: 20%;
            }
            .chat-window .bot {
                background-color: #f5f5f5;
                margin-right: 20%;
            }
            .gradio-container {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
                height: 100vh;
                overflow-y: auto;
            }
            
            /* ä»£ç å—æ ·å¼ - é»‘è‰²èƒŒæ™¯ */
            .chat-window pre {
                background-color: #0d1117 !important;
                color: #e6edf3 !important;
                border-radius: 8px !important;
                padding: 16px !important;
                margin: 12px 0 !important;
                border: 1px solid #30363d !important;
                overflow-x: auto !important;
                font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace !important;
                font-size: 14px !important;
                line-height: 1.5 !important;
                position: relative !important;
            }
            
            .chat-window pre code {
                background-color: transparent !important;
                color: inherit !important;
                padding: 0 !important;
                border-radius: 0 !important;
                font-family: inherit !important;
                font-size: inherit !important;
            }
            
            /* å†…è”ä»£ç æ ·å¼ */
            .chat-window code:not(pre code) {
                background-color: #f6f8fa !important;
                color: #d73a49 !important;
                padding: 2px 4px !important;
                border-radius: 3px !important;
                font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace !important;
                font-size: 85% !important;
                border: 1px solid #e1e4e8 !important;
            }
            
            /* ç¡®ä¿ä»£ç å—åœ¨èŠå¤©æ¶ˆæ¯ä¸­æ­£ç¡®æ˜¾ç¤º */
            .chat-window .message {
                overflow: visible !important;
            }
            
            .chat-window .message pre {
                white-space: pre !important;
                word-wrap: normal !important;
            }
            
            /* Agentå…³é”®è¯é«˜äº®æ ·å¼ */
            .chat-window .bot .message-content {
                position: relative;
            }
            
            /* Question æ ·å¼ - è“è‰² */
            .chat-window .agent-keyword-question {
                color: #0066cc !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(0, 102, 204, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #0066cc !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* Thought æ ·å¼ - ç»¿è‰² */
            .chat-window .agent-keyword-thought {
                color: #22c55e !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(34, 197, 94, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #22c55e !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* Action æ ·å¼ - æ©™è‰² */
            .chat-window .agent-keyword-action {
                color: #f59e0b !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(245, 158, 11, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #f59e0b !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* Action Input æ ·å¼ - ç´«è‰² */
            .chat-window .agent-keyword-action-input {
                color: #8b5cf6 !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(139, 92, 246, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #8b5cf6 !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* Observation æ ·å¼ - é’è‰² */
            .chat-window .agent-keyword-observation {
                color: #06b6d4 !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(6, 182, 212, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #06b6d4 !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* Final Answer æ ·å¼ - çº¢è‰² */
            .chat-window .agent-keyword-final-answer {
                color: #dc2626 !important;
                font-weight: bold !important;
                font-size: 16px !important;
                background-color: rgba(220, 38, 38, 0.1) !important;
                padding: 2px 6px !important;
                border-radius: 4px !important;
                border-left: 4px solid #dc2626 !important;
                padding-left: 8px !important;
                display: inline-block !important;
                margin: 2px 0 !important;
            }
            
            /* highlight.js æ·±è‰²ä¸»é¢˜é€‚é… */
            .chat-window .hljs {
                background: #0d1117 !important;
                color: #e6edf3 !important;
            }
            
            /* è¯­è¨€æ ‡ç­¾æ ·å¼ */
            .chat-window pre::before {
                content: attr(data-language);
                position: absolute;
                top: 8px;
                right: 12px;
                background: rgba(255, 255, 255, 0.1);
                color: #e6edf3;
                padding: 2px 6px;
                border-radius: 3px;
                font-size: 11px;
                text-transform: uppercase;
                font-weight: bold;
            }
            
            /* è®©æ¶ˆæ¯å†…å®¹å¯ä»¥æ­£ç¡®æ˜¾ç¤ºHTML */
            .chat-window .message-content {
                white-space: pre-wrap;
                word-wrap: break-word;
            }
            """
            
        return app
    
    async def _refresh_mcp_servers(self):
        """åˆ·æ–°MCPæœåŠ¡å™¨çŠ¶æ€"""
        import gradio as gr
        
        try:
            if not self.tool_manager:
                error_html = "<div style='color: red;'>âŒ å·¥å…·ç®¡ç†å™¨æœªåˆå§‹åŒ–</div>"
                return error_html, gr.update(choices=[])
            
            # ä½¿ç”¨å·¥å…·ç®¡ç†å™¨è·å–æœåŠ¡å™¨çŠ¶æ€
            servers_dict = self.tool_manager.get_servers_status()
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä»¥å…¼å®¹åç»­ä»£ç 
            servers = []
            for server_id, info in servers_dict.items():
                servers.append({
                    'id': server_id,
                    'name': info['name'],
                    'description': info['description'],
                    'connected': info['running'],  # running å¯¹åº” connected
                    'type': 'local_stdio',
                    'tools': []  # ç®€åŒ–ç‰ˆæ²¡æœ‰å·¥å…·åˆ—è¡¨
                })
            
            # ç”ŸæˆçŠ¶æ€HTML
            status_html = "<div style='font-family: monospace;'>"
            status_html += "<h4>ğŸ”Œ MCPæœåŠ¡å™¨çŠ¶æ€</h4>"
            
            if not servers:
                status_html += "<p>æš‚æ— å¯ç”¨çš„MCPæœåŠ¡å™¨</p>"
            else:
                for server in servers:
                    status_icon = "ğŸŸ¢" if server['connected'] else "ğŸ”´"
                    type_icon = {"local_stdio": "ğŸ’»", "remote_http": "ğŸŒ", "local_http": "ğŸ "}.get(server['type'], "â“")
                    
                    status_html += f"<div style='margin: 8px 0; padding: 8px; border: 1px solid #ddd; border-radius: 4px;'>"
                    status_html += f"<strong>{status_icon} {type_icon} {server['name']}</strong><br/>"
                    status_html += f"<small>ID: {server['id']} | ç±»å‹: {server['type']}</small><br/>"
                    status_html += f"<small>çŠ¶æ€: {'å·²è¿æ¥' if server['connected'] else 'æœªè¿æ¥'}</small><br/>"
                    status_html += f"<small>{server['description']}</small>"
                    status_html += "</div>"
            
            status_html += "</div>"
            
            # ç”Ÿæˆå¯é€‰æ‹©çš„æœåŠ¡å™¨åˆ—è¡¨
            choices = []
            for server in servers:
                try:
                    if 'name' in server and 'id' in server:
                        label = f"{server['name']} ({server['id']})"
                        value = server['id']
                        choices.append((label, value))
                except Exception as e:
                    print(f"è·³è¿‡æ— æ•ˆæœåŠ¡å™¨é…ç½®: {e}")
                    continue
            
            return status_html, gr.update(choices=choices)
            
        except Exception as e:
            error_html = f"<div style='color: red;'>âŒ åˆ·æ–°MCPæœåŠ¡å™¨å¤±è´¥: {str(e)}</div>"
            return error_html, gr.update(choices=[])
    
    async def _upload_files(self, files):
        """ä¸Šä¼ æ–‡ä»¶åˆ°è¾“å…¥ç›®å½•"""
        import shutil
        import os
        
        if not files:
            return "âŒ è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶", self._format_file_list_html([], "è¾“å…¥æ–‡ä»¶å¤¹")
        
        try:
            uploaded_count = 0
            for file_info in files:
                if hasattr(file_info, 'name') and file_info.name:
                    # æ–‡ä»¶è·¯å¾„
                    src_path = file_info.name
                    filename = os.path.basename(src_path)
                    dst_path = os.path.join(self.workspace_config['input_dir'], filename)
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(src_path, dst_path)
                    uploaded_count += 1
                    logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {filename} -> {dst_path}")
            
            status_msg = f"âœ… æˆåŠŸä¸Šä¼  {uploaded_count} ä¸ªæ–‡ä»¶åˆ°è¾“å…¥ç›®å½•"
            
            # åˆ·æ–°è¾“å…¥æ–‡ä»¶åˆ—è¡¨
            input_files = self._list_files_in_dir(self.workspace_config['input_dir'])
            input_files_html = self._format_file_list_html(input_files, "è¾“å…¥æ–‡ä»¶å¤¹")
            
            return status_msg, input_files_html
            
        except Exception as e:
            error_msg = f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, self._format_file_list_html([], "è¾“å…¥æ–‡ä»¶å¤¹")
    
    async def _refresh_file_lists(self):
        """åˆ·æ–°æ–‡ä»¶åˆ—è¡¨"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self._ensure_workspace_dirs()
            
            # è·å–è¾“å…¥æ–‡ä»¶
            input_files = self._list_files_in_dir(self.workspace_config['input_dir'])
            input_files_html = self._format_file_list_html(input_files, "è¾“å…¥æ–‡ä»¶å¤¹")
            
            # è·å–è¾“å‡ºæ–‡ä»¶
            output_files = self._list_files_in_dir(self.workspace_config['output_dir'])
            output_files_html = self._format_file_list_html(output_files, "è¾“å‡ºæ–‡ä»¶å¤¹")
            
            return input_files_html, output_files_html
            
        except Exception as e:
            error_msg = f"âŒ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, error_msg
    
    async def _on_mcp_servers_change(self, enabled_servers: List[str]):
        """å¤„ç†MCPæœåŠ¡å™¨å‹¾é€‰å˜åŒ– - åªæ›´æ–°å·¥å…·æš´éœ²ï¼Œä¸é‡å¯æœåŠ¡å™¨"""
        try:
            # é˜²æŠ¤ï¼šå¦‚æœ enabled_servers ä¸ºç©ºæˆ–è€…æ— æ•ˆï¼Œç›´æ¥è¿”å›å½“å‰çŠ¶æ€
            if not isinstance(enabled_servers, list):
                enabled_servers = []
            
            # æ›´æ–°å·¥å…·ç®¡ç†å™¨çš„å¯ç”¨æœåŠ¡å™¨ï¼ˆåªå½±å“å·¥å…·æš´éœ²ï¼‰
            if self.tool_manager:
                self.tool_manager.set_enabled_servers(enabled_servers)
                logger.info(f"å·²æ›´æ–°å¯ç”¨çš„MCPæœåŠ¡å™¨: {enabled_servers}")
            
            # æ›´æ–°é…ç½®ä¸­çš„enabled_mcp_servers
            self.current_config['enabled_mcp_servers'] = enabled_servers
            
            # è·å–æ‰€æœ‰æœåŠ¡å™¨çŠ¶æ€
            servers_dict = self.tool_manager.get_servers_status() if self.tool_manager else {}
            if not servers_dict:
                status_html, _ = await self._refresh_mcp_servers()
                return status_html
            
            status_messages = []
            
            for server_id, info in servers_dict.items():
                is_enabled = server_id in enabled_servers
                is_running = info['running']
                
                # åªè®°å½•çŠ¶æ€å˜åŒ–ï¼Œä¸å®é™…å¯åŠ¨/åœæ­¢æœåŠ¡å™¨
                if is_enabled:
                    status_messages.append(f"âœ… å·²å¯ç”¨å·¥å…·: {info['name']}")
                else:
                    status_messages.append(f"âšª å·²ç¦ç”¨å·¥å…·: {info['name']}")
            
            # åˆ·æ–°çŠ¶æ€
            status_html, _ = await self._refresh_mcp_servers()
            
            # æ·»åŠ æ“ä½œæ¶ˆæ¯
            if status_messages:
                messages_html = "<br/>".join(status_messages)
                status_html = f"{status_html}<div style='margin-top: 10px; padding: 10px; background-color: #f0f8ff; border-radius: 4px;'>{messages_html}</div>"
            
            return status_html
            
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè¿”å›åˆ·æ–°åçš„çŠ¶æ€
            try:
                status_html, _ = await self._refresh_mcp_servers()
                error_msg = f"<div style='color: red;'>âŒ å¤„ç†MCPæœåŠ¡å™¨å˜åŒ–å¤±è´¥: {str(e)}</div>"
                return f"{status_html}<br/>{error_msg}"
            except:
                return f"<div style='color: red;'>âŒ å¤„ç†MCPæœåŠ¡å™¨å˜åŒ–å¤±è´¥: {str(e)}</div>"

    async def _add_remote_server(self, name: str, url: str):
        """æ·»åŠ è¿œç¨‹MCPæœåŠ¡å™¨"""
        import gradio as gr
        
        try:
            if not name or not url:
                return name, url, "<div style='color: red;'>âŒ è¯·å¡«å†™æœåŠ¡å™¨åç§°å’ŒURL</div>", gr.update()
            
            # ç”ŸæˆæœåŠ¡å™¨ID
            server_id = f"remote_{name.lower().replace(' ', '_')}"
            
            # æš‚æ—¶ä¸æ”¯æŒæ·»åŠ è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½
            raise NotImplementedError("æš‚æ—¶ä¸æ”¯æŒæ·»åŠ è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½")
            
            # åˆ·æ–°çŠ¶æ€
            status_html, checkbox_update = await self._refresh_mcp_servers()
            
            success_html = f"<div style='color: green;'>âœ… æˆåŠŸæ·»åŠ è¿œç¨‹æœåŠ¡å™¨: {name}</div>"
            
            # æ¸…ç©ºè¾“å…¥æ¡†
            return "", "", success_html, checkbox_update
            
        except Exception as e:
            error_html = f"<div style='color: red;'>âŒ æ·»åŠ è¿œç¨‹æœåŠ¡å™¨å¤±è´¥: {str(e)}</div>"
            return name, url, error_html, gr.update()
    
    def _highlight_agent_keywords(self, text: str) -> str:
        """ä¸ºAgentå…³é”®è¯æ·»åŠ é«˜äº®æ ·å¼ï¼Œé¿å…å¤„ç†ä»£ç å—å†…å®¹"""
        import re
        
        # å…ˆæå–æ‰€æœ‰ä»£ç å—ï¼Œé¿å…åœ¨ä»£ç å—å†…è¿›è¡Œå…³é”®è¯æ›¿æ¢
        code_blocks = []
        code_pattern = r'```[\s\S]*?```|`[^`]+`'
        
        def preserve_code(match):
            code_blocks.append(match.group())
            return f"__CODE_BLOCK_{len(code_blocks) - 1}__"
        
        # æš‚æ—¶æ›¿æ¢æ‰€æœ‰ä»£ç å—
        text_without_code = re.sub(code_pattern, preserve_code, text)
        
        # å®šä¹‰å…³é”®è¯åŠå…¶å¯¹åº”çš„CSSç±»
        keywords = {
            r'\bQuestion\s*:': 'agent-keyword-question',
            r'\bThought\s*:': 'agent-keyword-thought', 
            r'\bAction\s*:': 'agent-keyword-action',
            r'\bAction\s+Input\s*:': 'agent-keyword-action-input',
            r'\bObservation\s*:': 'agent-keyword-observation',
            r'\bFinal\s+Answer\s*:': 'agent-keyword-final-answer'
        }
        
        # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡Œæ›¿æ¢ï¼ˆåªåœ¨éä»£ç å—åŒºåŸŸï¼‰
        for pattern, css_class in keywords.items():
            text_without_code = re.sub(
                pattern,
                lambda m: f'<span class="{css_class}">{m.group()}</span>',
                text_without_code,
                flags=re.IGNORECASE
            )
        
        # æ¢å¤ä»£ç å—
        for i, code_block in enumerate(code_blocks):
            text_without_code = text_without_code.replace(f"__CODE_BLOCK_{i}__", code_block)
        
        return text_without_code
    
    async def _stream_chat(self, message: str, history: List[Dict[str, str]]):
        """æµå¼å¤„ç†èŠå¤©æ¶ˆæ¯ï¼Œæ”¯æŒæ‰“å­—æœºæ•ˆæœ"""
        # å¦‚æœæ²¡æœ‰Agentï¼Œå°è¯•åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
        if not self.current_agent:
            try:
                if not self.tool_manager:
                    await self._update_agent_config()
                else:
                    from agents.react_agent import ReactAgent
                    self.agent = ReactAgent(
                        llm=self.llm,
                        tool_manager=self.tool_manager,
                        max_iterations=self.current_config.get('max_iterations', 10),
                        name="æ™ºèƒ½åŠ©æ‰‹"
                    )
                    self.current_agent = self.agent
                    logger.info("Agentåˆ›å»ºå®Œæˆï¼ˆå¤ç”¨ç°æœ‰å·¥å…·ç®¡ç†å™¨ï¼‰")
            except Exception as e:
                print(f"åˆ›å»ºé»˜è®¤Agentå¤±è´¥: {e}")
                history.append({"role": "user", "content": message})
                history.append({"role": "assistant", "content": "æŠ±æ­‰ï¼Œç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åå†è¯•ã€‚"})
                yield "", history, {}, "", [], ""
                return
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        history.append({"role": "user", "content": message})
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯ç”¨äºæµå¼æ›´æ–°
        history.append({"role": "assistant", "content": ""})
        
        try:
            accumulated_response = ""
            tool_calls_made = []
            execution_trace = []
            
            # ä½¿ç”¨æµå¼æ–¹æ³•
            async for chunk_data in self.current_agent.stream_run(message):
                chunk_type = chunk_data.get("type", "")
                chunk_content = chunk_data.get("content", "")
                
                if chunk_type == "text_chunk":
                    # æ–‡æœ¬å— - æ‰“å­—æœºæ•ˆæœ
                    accumulated_response += chunk_content
                    
                    # åº”ç”¨å…³é”®è¯é«˜äº®
                    highlighted_content = self._highlight_agent_keywords(accumulated_response)
                    
                    # æ›´æ–°å†å²è®°å½•ä¸­çš„æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯
                    history[-1]["content"] = highlighted_content
                    
                    # è¿”å›æ›´æ–°çš„å†å²è®°å½•å®ç°æ‰“å­—æœºæ•ˆæœ
                    yield "", history, {}, "", [], ""
                    
                    # çŸ­æš‚å»¶è¿Ÿå®ç°æ‰“å­—æœºæ•ˆæœ
                    await asyncio.sleep(0.02)  # 20mså»¶è¿Ÿ
                    
                elif chunk_type == "tool_result":
                    # å·¥å…·è°ƒç”¨ç»“æœ
                    tool_name = chunk_data.get("metadata", {}).get("tool_name", "")
                    tool_input = chunk_data.get("metadata", {}).get("tool_input", "")
                    tool_output = chunk_data.get("metadata", {}).get("tool_output", "")
                    
                    accumulated_response += chunk_content
                    highlighted_content = self._highlight_agent_keywords(accumulated_response)
                    history[-1]["content"] = highlighted_content
                    
                    # è®°å½•å·¥å…·è°ƒç”¨
                    tool_calls_made.append({
                        "tool_name": tool_name,
                        "input": tool_input,
                        "output": tool_output
                    })
                    
                    # æ·»åŠ å·¥å…·è°ƒç”¨åˆ°æ‰§è¡Œè½¨è¿¹
                    execution_trace.append({
                        "node": "tool_execution",
                        "type": "tool",
                        "duration": 0.0,
                        "state": "success",
                        "output": {
                            "tool_name": tool_name,
                            "tool_input": tool_input,
                            "tool_output": tool_output
                        }
                    })
                    
                    yield "", history, execution_trace, "", [], ""
                    
                elif chunk_type == "tool_error":
                    # å·¥å…·æ‰§è¡Œé”™è¯¯
                    error_msg = chunk_data.get("metadata", {}).get("error", "")
                    accumulated_response += chunk_content
                    highlighted_content = self._highlight_agent_keywords(accumulated_response)
                    history[-1]["content"] = highlighted_content
                    
                    execution_trace.append({
                        "node": "tool_error",
                        "type": "tool",
                        "duration": 0.0,
                        "state": "failed",
                        "output": {"error": error_msg}
                    })
                    
                    yield "", history, execution_trace, "", [], ""
                    
                elif chunk_type == "final_result":
                    # æœ€ç»ˆç»“æœï¼ˆå›é€€æ¨¡å¼ï¼‰
                    highlighted_content = self._highlight_agent_keywords(chunk_content)
                    history[-1]["content"] = highlighted_content
                    yield "", history, {}, "", [], ""
            
            # ç”Ÿæˆæœ€ç»ˆæŒ‡æ ‡
            metrics_text = self._format_stream_metrics(tool_calls_made, accumulated_response)
            
            # ç”ŸæˆèŠ‚ç‚¹çŠ¶æ€è¡¨
            node_status = self._generate_node_status(execution_trace)
            
            # ç”Ÿæˆæµç¨‹å›¾
            flow_diagram = self._generate_flow_diagram(execution_trace)
            
            # æœ€ç»ˆè¾“å‡º
            yield "", history, execution_trace, metrics_text, node_status, flow_diagram
            
        except Exception as e:
            # å¤„ç†é”™è¯¯
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            print(error_msg)
            history[-1]["content"] = f"æŠ±æ­‰ï¼Œ{error_msg}"
            yield "", history, {}, "", [], ""
    
    def _format_stream_metrics(self, tool_calls: List[Dict], response_text: str) -> str:
        """æ ¼å¼åŒ–æµå¼å¤„ç†æŒ‡æ ‡"""
        metrics = {
            "å·¥å…·è°ƒç”¨æ¬¡æ•°": len(tool_calls),
            "å“åº”å­—ç¬¦æ•°": len(response_text),
            "å·¥å…·ç±»å‹": list(set(call.get("tool_name", "") for call in tool_calls)) if tool_calls else []
        }
        
        lines = []
        for key, value in metrics.items():
            if isinstance(value, list):
                lines.append(f"{key}: {', '.join(value) if value else 'æ— '}")
            else:
                lines.append(f"{key}: {value}")
        
        return "\n".join(lines)
    
    def _generate_node_status(self, trace: List[Dict[str, Any]]) -> List[List[Any]]:
        """ç”ŸæˆèŠ‚ç‚¹çŠ¶æ€è¡¨"""
        if not trace:
            return []
        
        status_data = []
        for step in trace:
            node_name = step.get("node", "")
            node_type = step.get("type", "")
            state = step.get("state", "")
            duration = step.get("duration", 0)
            
            # è·å–è¾“å‡ºé¢„è§ˆ
            output = step.get("output", {})
            if isinstance(output, dict):
                # æå–å…³é”®ä¿¡æ¯ä½œä¸ºé¢„è§ˆ
                if "answer" in output:
                    preview = output["answer"][:50] + "..." if len(output.get("answer", "")) > 50 else output.get("answer", "")
                elif "thought" in output:
                    preview = output["thought"][:50] + "..." if len(output.get("thought", "")) > 50 else output.get("thought", "")
                elif "action" in output:
                    preview = f"æ‰§è¡Œ: {output.get('action', '')[:30]}..."
                else:
                    preview = str(output)[:50] + "..." if len(str(output)) > 50 else str(output)
            else:
                preview = str(output)[:50] + "..." if len(str(output)) > 50 else str(output)
            
            # æ·»åŠ è¡¨æƒ…ç¬¦å·è¡¨ç¤ºçŠ¶æ€
            state_emoji = {
                "success": "âœ…",
                "failed": "âŒ",
                "running": "ğŸ”„",
                "pending": "â³"
            }.get(state, "â“")
            
            status_data.append([
                node_name,
                node_type,
                f"{state_emoji} {state}",
                f"{duration:.2f}" if duration else "0.00",
                preview
            ])
        
        return status_data
    
    def _generate_flow_diagram(self, trace: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæµç¨‹å›¾HTML"""
        if not trace:
            return "<p>æš‚æ— æ‰§è¡Œæµç¨‹</p>"
        
        # ä½¿ç”¨Mermaidç”Ÿæˆæµç¨‹å›¾
        mermaid_code = "graph TD\n"
        
        # æ·»åŠ èŠ‚ç‚¹
        for i, step in enumerate(trace):
            node_name = step.get("node", f"node_{i}")
            node_type = step.get("type", "unknown")
            state = step.get("state", "")
            
            # æ ¹æ®çŠ¶æ€é€‰æ‹©æ ·å¼
            if state == "success":
                style = "fill:#90EE90"
            elif state == "failed":
                style = "fill:#FFB6C1"
            elif state == "running":
                style = "fill:#87CEEB"
            else:
                style = "fill:#F0F0F0"
            
            # æ·»åŠ èŠ‚ç‚¹å®šä¹‰
            label = f"{node_name}\\n[{node_type}]"
            mermaid_code += f"    {node_name}[\"{label}\"]:::state{i}\n"
            mermaid_code += f"    classDef state{i} {style}\n"
            
            # æ·»åŠ è¿æ¥
            if i > 0:
                prev_node = trace[i-1].get("node", f"node_{i-1}")
                mermaid_code += f"    {prev_node} --> {node_name}\n"
        
        # ç”ŸæˆHTML
        html = f"""
        <div id="mermaid-diagram">
            <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
            <script>
                mermaid.initialize({{ startOnLoad: true }});
            </script>
            <div class="mermaid">
                {mermaid_code}
            </div>
        </div>
        <style>
            #mermaid-diagram {{
                width: 100%;
                min-height: 300px;
                background: #f9f9f9;
                border-radius: 8px;
                padding: 20px;
            }}
            .mermaid {{
                text-align: center;
            }}
        </style>
        """
        
        return html
    
    async def _batch_execute(self, batch_input: str, parallel: bool):
        """æ‰§è¡Œæ‰¹é‡ä»»åŠ¡"""
        if not self.current_agent:
            return [["", "é”™è¯¯", "è¯·å…ˆé…ç½®Agentï¼", ""]]
        
        tasks = [line.strip() for line in batch_input.split('\n') if line.strip()]
        results = []
        
        if parallel:
            # å¹¶è¡Œæ‰§è¡Œ
            async_tasks = [self.current_agent.run(task) for task in tasks]
            task_results = await asyncio.gather(*async_tasks, return_exceptions=True)
            
            for task, result in zip(tasks, task_results):
                if isinstance(result, Exception):
                    results.append([task, "å¤±è´¥", str(result), ""])
                else:
                    results.append([
                        task,
                        "æˆåŠŸ" if result.success else "å¤±è´¥",
                        result.result or result.error,
                        f"{result.duration:.2f}s" if result.duration else ""
                    ])
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            for task in tasks:
                try:
                    result = await self.current_agent.run(task)
                    results.append([
                        task,
                        "æˆåŠŸ" if result.success else "å¤±è´¥",
                        result.result or result.error,
                        f"{result.duration:.2f}s" if result.duration else ""
                    ])
                except Exception as e:
                    results.append([task, "å¤±è´¥", str(e), ""])
        
        return results
    
    def launch(self, **kwargs):
        """å¯åŠ¨åº”ç”¨"""
        app = self.create_interface()
        app.launch(**kwargs)
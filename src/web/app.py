"""
Gradioåº”ç”¨ä¸»æ–‡ä»¶ - æä¾›ç±»ChatGPTé£æ ¼çš„ç•Œé¢
"""
import gradio as gr
import asyncio
import logging
from typing import List, Dict, Any, Optional, Tuple
import json
from datetime import datetime

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.types import AgentType, ToolConfig, LLMConfig, TaskResult
from agents.react_agent import ReactAgent
from llm.base import LLMFactory

from tools.mcp_tools import MCPToolManager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class AgentApp:
    """Agentåº”ç”¨ç•Œé¢"""
    
    def __init__(self, 
                 title: str = "ZZZero AI Agent",
                 description: str = "åŸºäºèŠ‚ç‚¹ç¼–æ’çš„AI Agentæ¡†æ¶"):
        self.title = title
        self.description = description
        self.current_agent = None
        self.agent = None  # æ·»åŠ agentå±æ€§
        self.tool_manager = None
        self.llm = None
        # ä¿å­˜å½“å‰é…ç½®
        self.current_config = {
            'llm_provider': 'doubao',
            'model_name': 'ep-20250221154410-vh78x',
            'temperature': 0.7,
            'agent_type': 'react',
            'max_iterations': 5,
            'available_tools': [],
            'enabled_mcp_servers': []
        }
        
    async def _update_agent_config(self):
        """æ›´æ–°Agenté…ç½®"""
        try:
            # åˆ›å»ºå·¥å…·ç®¡ç†å™¨ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
            if not self.tool_manager:
                self.tool_manager = MCPToolManager()
                await self.tool_manager.initialize()
            
            # åˆ›å»ºLLMå®ä¾‹ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
            if not self.llm:
                # åˆ›å»ºLLMé…ç½®å¯¹è±¡
                llm_config = LLMConfig(
                    provider=self.current_config.get('llm_provider', 'doubao'),
                    model_name=self.current_config.get('model_name', 'ep-20250221154410-vh78x'),
                    temperature=self.current_config.get('temperature', 0.7)
                )
                
                # ä½¿ç”¨å·¥å‚åˆ›å»ºLLMå®ä¾‹
                self.llm = LLMFactory.create(llm_config)
                await self.llm.initialize()
            
            # æ›´æ–°å·¥å…·ç®¡ç†å™¨çš„å¯ç”¨æœåŠ¡å™¨ï¼ˆä»…åœ¨å·¥å…·ç®¡ç†å™¨å­˜åœ¨æ—¶ï¼‰
            enabled_servers = self.current_config.get('enabled_mcp_servers', ['csv', 'chromadb'])  # é»˜è®¤å¯ç”¨
            if self.tool_manager:
                self.tool_manager.set_enabled_servers(enabled_servers)
            
            # åˆ›å»ºæˆ–æ›´æ–°Agent
            self.agent = ReactAgent(
                llm=self.llm,  # ä¼ é€’LLMå®ä¾‹ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°
                tool_manager=self.tool_manager,
                max_iterations=self.current_config.get('max_iterations', 10),
                name="æ™ºèƒ½åŠ©æ‰‹"
            )
            
            # åŒæ—¶è®¾ç½®current_agentä»¥å…¼å®¹å…¶ä»–æ–¹æ³•
            self.current_agent = self.agent
            
            logger.info("Agenté…ç½®æ›´æ–°æˆåŠŸ")
            
        except Exception as e:
            error_msg = f"æ›´æ–°Agenté…ç½®å¤±è´¥: {e}"
            logger.error(error_msg)
            return error_msg
    

            
    def create_interface(self) -> gr.Blocks:
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(title=self.title, theme=gr.themes.Soft()) as app:
            # æ ‡é¢˜
            gr.Markdown(f"# {self.title}")
            gr.Markdown(f"{self.description}")
            
            with gr.Row():
                # å·¦ä¾§é…ç½®é¢æ¿
                with gr.Column(scale=1):
                    gr.Markdown("## âš™ï¸ é…ç½®é¢æ¿")
                    
                    # LLMé…ç½®
                    with gr.Accordion("ğŸ§  LLMé…ç½®", open=True):
                        llm_provider = gr.Dropdown(
                            choices=["doubao", "openai"],
                            value="doubao",
                            label="LLMæä¾›å•†"
                        )
                        model_name = gr.Textbox(
                            value="ep-20250221154410-vh78x",  # DOUBAO_MODEL_DEEPSEEKV3
                            label="æ¨¡å‹åç§°",
                            placeholder="ä¾‹å¦‚: ep-20250221154410-vh78x (deepseekv3)"
                        )
                        temperature = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.7,
                            step=0.1,
                            label="ç”Ÿæˆæ¸©åº¦"
                        )
                    
                    # Agenté…ç½®
                    with gr.Accordion("ğŸ¤– Agenté…ç½®", open=True):
                        agent_type = gr.Dropdown(
                            choices=["react"],
                            value="react",
                            label="Agentç±»å‹"
                        )
                        max_iterations = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=5,
                            step=1,
                            label="æœ€å¤§è¿­ä»£æ¬¡æ•°"
                        )
                    
                    # MCPæœåŠ¡å™¨ç®¡ç†
                    with gr.Accordion("ğŸ”Œ MCPæœåŠ¡å™¨ç®¡ç†", open=True):
                        # æœåŠ¡å™¨çŠ¶æ€å’Œå‹¾é€‰åœ¨ä¸€èµ·
                        mcp_servers_status = gr.HTML(
                            value="<p>æ­£åœ¨åŠ è½½MCPæœåŠ¡å™¨ä¿¡æ¯...</p>",
                            label="MCPæœåŠ¡å™¨çŠ¶æ€"
                        )
                        
                        # è·å–åˆå§‹çš„serversåˆ—è¡¨å¹¶è®¾ç½®é»˜è®¤å€¼
                        initial_choices = []
                        default_enabled = []
                        try:
                            from tools.mcp_manager import mcp_manager
                            servers = mcp_manager.list_servers()
                            for server in servers:
                                if 'name' in server and 'id' in server:
                                    choice = (f"{server['name']} ({server['id']})", server['id'])
                                    initial_choices.append(choice)
                                    # é»˜è®¤å‹¾é€‰csvå’Œchromadb
                                    if server['id'] in ['csv', 'chromadb']:
                                        default_enabled.append(server['id'])
                        except Exception as e:
                            print(f"åˆå§‹åŒ–MCPæœåŠ¡å™¨å¤±è´¥: {e}")
                        
                        enabled_mcp_servers = gr.CheckboxGroup(
                            choices=initial_choices,
                            value=default_enabled,
                            label="å¯ç”¨çš„MCPæœåŠ¡å™¨"
                        )
                        
                        # è¿œç¨‹æœåŠ¡å™¨æ·»åŠ 
                        with gr.Row():
                            remote_server_name = gr.Textbox(
                                placeholder="æœåŠ¡å™¨åç§°",
                                scale=2,
                                label="è¿œç¨‹æœåŠ¡å™¨åç§°"
                            )
                            remote_server_url = gr.Textbox(
                                placeholder="http://localhost:3000",
                                scale=3,
                                label="è¿œç¨‹æœåŠ¡å™¨URL"
                            )
                            add_remote_btn = gr.Button("æ·»åŠ è¿œç¨‹æœåŠ¡å™¨", scale=1)
                        
                        refresh_mcp_btn = gr.Button("åˆ·æ–°MCPæœåŠ¡å™¨", variant="secondary")
                    
                    # å·¥å…·é€‰æ‹©
                    with gr.Accordion("ğŸ”§ ä¼ ç»Ÿå·¥å…·é…ç½®", open=False):
                        available_tools = gr.CheckboxGroup(
                            choices=[
                                "web_search",
                                "calculator", 
                                "file_reader",
                                "code_executor",
                                "database_query"
                            ],
                            value=[],
                            label="å¯ç”¨çš„ä¼ ç»Ÿå·¥å…·"
                        )
                    
                    # é…ç½®çŠ¶æ€ï¼ˆåªæ˜¾ç¤ºï¼Œä¸éœ€è¦åº”ç”¨æŒ‰é’®ï¼‰
                    config_status = gr.Textbox(label="é…ç½®çŠ¶æ€", interactive=False, value="âœ… é…ç½®å·²è‡ªåŠ¨åº”ç”¨")
                
                # å³ä¾§èŠå¤©ç•Œé¢
                with gr.Column(scale=3):
                    # èŠå¤©å†å²
                    chatbot = gr.Chatbot(
                        height=500,
                        show_label=False,
                        elem_classes=["chat-window"],
                        type="messages"
                    )
                    
                    # è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        msg_input = gr.Textbox(
                            placeholder="è¾“å…¥æ¶ˆæ¯...",
                            show_label=False,
                            scale=9,
                            lines=1,
                            max_lines=5
                        )
                        send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                    
                    # æ‰¹é‡ä»»åŠ¡
                    with gr.Accordion("ğŸ“‹ æ‰¹é‡ä»»åŠ¡", open=False):
                        batch_input = gr.Textbox(
                            placeholder="æ¯è¡Œä¸€ä¸ªä»»åŠ¡...",
                            lines=5,
                            label="æ‰¹é‡ä»»åŠ¡åˆ—è¡¨"
                        )
                        batch_parallel = gr.Checkbox(
                            label="å¹¶è¡Œæ‰§è¡Œ",
                            value=True
                        )
                        batch_btn = gr.Button("æ‰§è¡Œæ‰¹é‡ä»»åŠ¡")
                        batch_results = gr.Dataframe(
                            headers=["ä»»åŠ¡", "çŠ¶æ€", "ç»“æœ", "è€—æ—¶"],
                            label="æ‰¹é‡ä»»åŠ¡ç»“æœ"
                        )
                    
                    # æ‰§è¡Œè¯¦æƒ…
                    with gr.Accordion("ğŸ“Š æ‰§è¡Œè¯¦æƒ…", open=False):
                        execution_trace = gr.JSON(label="æ‰§è¡Œè½¨è¿¹")
                        metrics_display = gr.Textbox(label="æ‰§è¡ŒæŒ‡æ ‡", lines=3)
                        
                    # æµç¨‹å¯è§†åŒ–
                    with gr.Accordion("ğŸ”„ æµç¨‹å¯è§†åŒ–", open=False):
                        # å®æ—¶èŠ‚ç‚¹çŠ¶æ€
                        node_status = gr.DataFrame(
                            headers=["èŠ‚ç‚¹", "ç±»å‹", "çŠ¶æ€", "è€—æ—¶(s)", "è¾“å‡ºé¢„è§ˆ"],
                            label="èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€",
                            interactive=False
                        )
                        # æµç¨‹å›¾
                        flow_diagram = gr.HTML(label="æ‰§è¡Œæµç¨‹å›¾")
                        # è‡ªåŠ¨åˆ·æ–°
                        auto_refresh = gr.Checkbox(label="è‡ªåŠ¨åˆ·æ–°", value=True)
            
            # === é…ç½®å˜åŒ–è‡ªåŠ¨åº”ç”¨ ===
            async def on_config_change(*args):
                """é…ç½®å˜åŒ–æ—¶è‡ªåŠ¨åº”ç”¨"""
                llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers = args
                
                # æ›´æ–°é…ç½®
                old_config = self.current_config.copy()
                self.current_config.update({
                    'llm_provider': llm_provider,
                    'model_name': model_name,
                    'temperature': temperature,
                    'agent_type': agent_type,
                    'max_iterations': max_iterations,
                    'available_tools': available_tools,
                    'enabled_mcp_servers': enabled_mcp_servers
                })
                
                # åªæœ‰åœ¨é…ç½®çœŸæ­£æ”¹å˜æ—¶æ‰æ›´æ–°Agent
                config_changed = old_config != self.current_config
                if config_changed:
                    await self._update_agent_config()
                    logger.info("é…ç½®å·²æ›´æ”¹ï¼ŒAgentå·²æ›´æ–°")
                
                total_tools = len(available_tools) + len(enabled_mcp_servers)
                status_text = f"âœ… é…ç½®å·²åº”ç”¨ï¼ä½¿ç”¨ {llm_provider}/{model_name}ï¼Œå¯ç”¨ {total_tools} ä¸ªå·¥å…·"
                if not config_changed:
                    status_text += " (æ— å˜åŒ–)"
                
                return status_text
            
            # ç»‘å®šé…ç½®å˜åŒ–äº‹ä»¶
            for component in [llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers]:
                component.change(
                    on_config_change,
                    inputs=[llm_provider, model_name, temperature, agent_type, max_iterations, available_tools, enabled_mcp_servers],
                    outputs=[config_status]
                )
            
            # MCPæœåŠ¡å™¨ç›¸å…³äº‹ä»¶
            refresh_mcp_btn.click(
                self._refresh_mcp_servers,
                outputs=[mcp_servers_status, enabled_mcp_servers]
            )
            
            add_remote_btn.click(
                self._add_remote_server,
                inputs=[remote_server_name, remote_server_url],
                outputs=[remote_server_name, remote_server_url, mcp_servers_status, enabled_mcp_servers]
            )
            
            # é¡µé¢åŠ è½½æ—¶çš„åˆå§‹åŒ–
            async def on_load():
                """é¡µé¢åŠ è½½æ—¶çš„åˆå§‹åŒ–"""
                try:
                    # åˆå§‹åŒ–é…ç½®ï¼ˆMCPæœåŠ¡å™¨å·²åœ¨main.pyä¸­å¯åŠ¨ï¼‰
                    await self._update_agent_config()
                    
                    # è·å–æœåŠ¡å™¨çŠ¶æ€å¹¶æ›´æ–°ç•Œé¢
                    servers_status = self.tool_manager.get_servers_status() if self.tool_manager else {}
                    
                    # ç”ŸæˆçŠ¶æ€HTML
                    status_html = "<div style='font-family: monospace;'>"
                    status_html += "<h4>ğŸ”Œ MCPæœåŠ¡å™¨çŠ¶æ€</h4>"
                    
                    if not servers_status:
                        status_html += "<p>æš‚æ— å¯ç”¨çš„MCPæœåŠ¡å™¨</p>"
                    else:
                        for server_id, info in servers_status.items():
                            status_icon = "ğŸŸ¢" if info['running'] else "ğŸ”´"
                            enable_icon = "âœ…" if info.get('enabled', False) else "âšª"
                            
                            status_html += f"<div style='margin: 8px 0; padding: 8px; border: 1px solid #ddd; border-radius: 4px;'>"
                            status_html += f"<strong>{status_icon} {enable_icon} {info['name']}</strong><br/>"
                            status_html += f"<small>ID: {server_id} | çŠ¶æ€: {'è¿è¡Œä¸­' if info['running'] else 'æœªè¿è¡Œ'}</small><br/>"
                            status_html += f"<small>å·¥å…·: {info.get('enabled_tools', 0)}/{info.get('total_tools', 0)} ä¸ªå¯ç”¨</small><br/>"
                            status_html += f"<small>{info['description']}</small>"
                            status_html += "</div>"
                    
                    status_html += "</div>"
                    
                    # ç”Ÿæˆå¯é€‰æ‹©çš„æœåŠ¡å™¨åˆ—è¡¨
                    choices = []
                    default_enabled = []
                    
                    for server_id, info in servers_status.items():
                        label = f"{info['name']} ({server_id})"
                        choices.append((label, server_id))
                        # é»˜è®¤å‹¾é€‰å·²å¯ç”¨çš„æœåŠ¡å™¨
                        if info.get('enabled', False):
                            default_enabled.append(server_id)
                    
                    # è¿”å›çŠ¶æ€HTMLå’Œæ›´æ–°åçš„CheckboxGroup
                    import gradio as gr
                    return (
                        status_html,
                        gr.update(choices=choices, value=default_enabled)
                    )
                    
                except Exception as e:
                    error_msg = f"é¡µé¢åŠ è½½åˆå§‹åŒ–å¤±è´¥: {e}"
                    logger.error(error_msg)
                    import gradio as gr
                    return (
                        f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}",
                        gr.update(choices=[], value=[])
                    )
            
            app.load(
                on_load,
                outputs=[mcp_servers_status, enabled_mcp_servers]
            )
            
            # MCPæœåŠ¡å™¨å‹¾é€‰å˜åŒ–äº‹ä»¶
            enabled_mcp_servers.change(
                self._on_mcp_servers_change,
                inputs=[enabled_mcp_servers],
                outputs=[mcp_servers_status]
            )
            
            msg_input.submit(
                self._stream_chat,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot, execution_trace, metrics_display, node_status, flow_diagram],
                show_progress=False  # ç¦ç”¨è¿›åº¦æ¡ä»¥æ”¯æŒæµå¼è¾“å‡º
            )
            
            send_btn.click(
                self._stream_chat,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot, execution_trace, metrics_display, node_status, flow_diagram],
                show_progress=False  # ç¦ç”¨è¿›åº¦æ¡ä»¥æ”¯æŒæµå¼è¾“å‡º
            )
            
            batch_btn.click(
                self._batch_execute,
                inputs=[batch_input, batch_parallel],
                outputs=[batch_results]
            )
            
            # æ·»åŠ è‡ªå®šä¹‰CSS
            app.css = """
            * {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
            }
            .chat-window {
                border-radius: 10px;
                border: 1px solid #e0e0e0;
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
            }
            .chat-window .message {
                padding: 10px;
                margin: 5px;
                border-radius: 10px;
            }
            .chat-window .user {
                background-color: #e3f2fd;
                margin-left: 20%;
            }
            .chat-window .bot {
                background-color: #f5f5f5;
                margin-right: 20%;
            }
            .gradio-container {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
                height: 100vh;
                overflow-y: auto;
            }
            """
            
        return app
    
    async def _refresh_mcp_servers(self):
        """åˆ·æ–°MCPæœåŠ¡å™¨çŠ¶æ€"""
        import gradio as gr
        
        try:
            from tools.mcp_manager import mcp_manager
            
            # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•è·å–æœåŠ¡å™¨åˆ—è¡¨
            servers_dict = mcp_manager.list_servers()
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä»¥å…¼å®¹åç»­ä»£ç 
            servers = []
            for server_id, info in servers_dict.items():
                servers.append({
                    'id': server_id,
                    'name': info['name'],
                    'description': info['description'],
                    'connected': info['running'],  # running å¯¹åº” connected
                    'type': 'local_stdio',
                    'tools': []  # ç®€åŒ–ç‰ˆæ²¡æœ‰å·¥å…·åˆ—è¡¨
                })
            
            # ç”ŸæˆçŠ¶æ€HTML
            status_html = "<div style='font-family: monospace;'>"
            status_html += "<h4>ğŸ”Œ MCPæœåŠ¡å™¨çŠ¶æ€</h4>"
            
            if not servers:
                status_html += "<p>æš‚æ— å¯ç”¨çš„MCPæœåŠ¡å™¨</p>"
            else:
                for server in servers:
                    status_icon = "ğŸŸ¢" if server['connected'] else "ğŸ”´"
                    type_icon = {"local_stdio": "ğŸ’»", "remote_http": "ğŸŒ", "local_http": "ğŸ "}.get(server['type'], "â“")
                    
                    status_html += f"<div style='margin: 8px 0; padding: 8px; border: 1px solid #ddd; border-radius: 4px;'>"
                    status_html += f"<strong>{status_icon} {type_icon} {server['name']}</strong><br/>"
                    status_html += f"<small>ID: {server['id']} | ç±»å‹: {server['type']}</small><br/>"
                    status_html += f"<small>çŠ¶æ€: {'å·²è¿æ¥' if server['connected'] else 'æœªè¿æ¥'}</small><br/>"
                    status_html += f"<small>{server['description']}</small>"
                    status_html += "</div>"
            
            status_html += "</div>"
            
            # ç”Ÿæˆå¯é€‰æ‹©çš„æœåŠ¡å™¨åˆ—è¡¨
            choices = []
            for server in servers:
                try:
                    if 'name' in server and 'id' in server:
                        label = f"{server['name']} ({server['id']})"
                        value = server['id']
                        choices.append((label, value))
                except Exception as e:
                    print(f"è·³è¿‡æ— æ•ˆæœåŠ¡å™¨é…ç½®: {e}")
                    continue
            
            return status_html, gr.update(choices=choices)
            
        except Exception as e:
            error_html = f"<div style='color: red;'>âŒ åˆ·æ–°MCPæœåŠ¡å™¨å¤±è´¥: {str(e)}</div>"
            return error_html, gr.update(choices=[])
    
    async def _on_mcp_servers_change(self, enabled_servers: List[str]):
        """å¤„ç†MCPæœåŠ¡å™¨å‹¾é€‰å˜åŒ– - åªæ›´æ–°å·¥å…·æš´éœ²ï¼Œä¸é‡å¯æœåŠ¡å™¨"""
        try:
            # é˜²æŠ¤ï¼šå¦‚æœ enabled_servers ä¸ºç©ºæˆ–è€…æ— æ•ˆï¼Œç›´æ¥è¿”å›å½“å‰çŠ¶æ€
            if not isinstance(enabled_servers, list):
                enabled_servers = []
            
            # æ›´æ–°å·¥å…·ç®¡ç†å™¨çš„å¯ç”¨æœåŠ¡å™¨ï¼ˆåªå½±å“å·¥å…·æš´éœ²ï¼‰
            if self.tool_manager:
                self.tool_manager.set_enabled_servers(enabled_servers)
                logger.info(f"å·²æ›´æ–°å¯ç”¨çš„MCPæœåŠ¡å™¨: {enabled_servers}")
            
            # è·å–æœ€æ–°çš„æœåŠ¡å™¨çŠ¶æ€
            from tools.mcp_manager import mcp_manager
            
            # æ›´æ–°é…ç½®ä¸­çš„enabled_mcp_servers
            self.current_config['enabled_mcp_servers'] = enabled_servers
            
            # è·å–æ‰€æœ‰æœåŠ¡å™¨
            servers_dict = mcp_manager.list_servers()
            if not servers_dict:
                status_html, _ = await self._refresh_mcp_servers()
                return status_html
            
            status_messages = []
            
            for server_id, info in servers_dict.items():
                is_enabled = server_id in enabled_servers
                is_running = info['running']
                
                # åªè®°å½•çŠ¶æ€å˜åŒ–ï¼Œä¸å®é™…å¯åŠ¨/åœæ­¢æœåŠ¡å™¨
                if is_enabled:
                    status_messages.append(f"âœ… å·²å¯ç”¨å·¥å…·: {info['name']}")
                else:
                    status_messages.append(f"âšª å·²ç¦ç”¨å·¥å…·: {info['name']}")
            
            # åˆ·æ–°çŠ¶æ€
            status_html, _ = await self._refresh_mcp_servers()
            
            # æ·»åŠ æ“ä½œæ¶ˆæ¯
            if status_messages:
                messages_html = "<br/>".join(status_messages)
                status_html = f"{status_html}<div style='margin-top: 10px; padding: 10px; background-color: #f0f8ff; border-radius: 4px;'>{messages_html}</div>"
            
            return status_html
            
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè¿”å›åˆ·æ–°åçš„çŠ¶æ€
            try:
                status_html, _ = await self._refresh_mcp_servers()
                error_msg = f"<div style='color: red;'>âŒ å¤„ç†MCPæœåŠ¡å™¨å˜åŒ–å¤±è´¥: {str(e)}</div>"
                return f"{status_html}<br/>{error_msg}"
            except:
                return f"<div style='color: red;'>âŒ å¤„ç†MCPæœåŠ¡å™¨å˜åŒ–å¤±è´¥: {str(e)}</div>"

    async def _add_remote_server(self, name: str, url: str):
        """æ·»åŠ è¿œç¨‹MCPæœåŠ¡å™¨"""
        import gradio as gr
        
        try:
            if not name or not url:
                return name, url, "<div style='color: red;'>âŒ è¯·å¡«å†™æœåŠ¡å™¨åç§°å’ŒURL</div>", gr.update()
            
            from tools.mcp_manager import mcp_manager
            
            # ç”ŸæˆæœåŠ¡å™¨ID
            server_id = f"remote_{name.lower().replace(' ', '_')}"
            
            # æš‚æ—¶ä¸æ”¯æŒæ·»åŠ è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½
            raise NotImplementedError("æš‚æ—¶ä¸æ”¯æŒæ·»åŠ è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½")
            
            # åˆ·æ–°çŠ¶æ€
            status_html, checkbox_update = await self._refresh_mcp_servers()
            
            success_html = f"<div style='color: green;'>âœ… æˆåŠŸæ·»åŠ è¿œç¨‹æœåŠ¡å™¨: {name}</div>"
            
            # æ¸…ç©ºè¾“å…¥æ¡†
            return "", "", success_html, checkbox_update
            
        except Exception as e:
            error_html = f"<div style='color: red;'>âŒ æ·»åŠ è¿œç¨‹æœåŠ¡å™¨å¤±è´¥: {str(e)}</div>"
            return name, url, error_html, gr.update()
    
    async def _stream_chat(self, message: str, history: List[Dict[str, str]]):
        """æµå¼å¤„ç†èŠå¤©æ¶ˆæ¯ï¼Œæ”¯æŒæ‰“å­—æœºæ•ˆæœ"""
        # å¦‚æœæ²¡æœ‰Agentï¼Œå°è¯•åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
        if not self.current_agent:
            try:
                if not self.tool_manager:
                    await self._update_agent_config()
                else:
                    from agents.react_agent import ReactAgent
                    self.agent = ReactAgent(
                        llm=self.llm,
                        tool_manager=self.tool_manager,
                        max_iterations=self.current_config.get('max_iterations', 10),
                        name="æ™ºèƒ½åŠ©æ‰‹"
                    )
                    self.current_agent = self.agent
                    logger.info("Agentåˆ›å»ºå®Œæˆï¼ˆå¤ç”¨ç°æœ‰å·¥å…·ç®¡ç†å™¨ï¼‰")
            except Exception as e:
                print(f"åˆ›å»ºé»˜è®¤Agentå¤±è´¥: {e}")
                history.append({"role": "user", "content": message})
                history.append({"role": "assistant", "content": "æŠ±æ­‰ï¼Œç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åå†è¯•ã€‚"})
                yield "", history, {}, "", [], ""
                return
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        history.append({"role": "user", "content": message})
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯ç”¨äºæµå¼æ›´æ–°
        history.append({"role": "assistant", "content": ""})
        
        try:
            accumulated_response = ""
            tool_calls_made = []
            execution_trace = []
            
            # ä½¿ç”¨æµå¼æ–¹æ³•
            async for chunk_data in self.current_agent.stream_run(message):
                chunk_type = chunk_data.get("type", "")
                chunk_content = chunk_data.get("content", "")
                
                if chunk_type == "text_chunk":
                    # æ–‡æœ¬å— - æ‰“å­—æœºæ•ˆæœ
                    accumulated_response += chunk_content
                    
                    # æ›´æ–°å†å²è®°å½•ä¸­çš„æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯
                    history[-1]["content"] = accumulated_response
                    
                    # è¿”å›æ›´æ–°çš„å†å²è®°å½•å®ç°æ‰“å­—æœºæ•ˆæœ
                    yield "", history, {}, "", [], ""
                    
                    # çŸ­æš‚å»¶è¿Ÿå®ç°æ‰“å­—æœºæ•ˆæœ
                    await asyncio.sleep(0.02)  # 20mså»¶è¿Ÿ
                    
                elif chunk_type == "tool_result":
                    # å·¥å…·è°ƒç”¨ç»“æœ
                    tool_name = chunk_data.get("metadata", {}).get("tool_name", "")
                    tool_input = chunk_data.get("metadata", {}).get("tool_input", "")
                    tool_output = chunk_data.get("metadata", {}).get("tool_output", "")
                    
                    accumulated_response += chunk_content
                    history[-1]["content"] = accumulated_response
                    
                    # è®°å½•å·¥å…·è°ƒç”¨
                    tool_calls_made.append({
                        "tool_name": tool_name,
                        "input": tool_input,
                        "output": tool_output
                    })
                    
                    # æ·»åŠ å·¥å…·è°ƒç”¨åˆ°æ‰§è¡Œè½¨è¿¹
                    execution_trace.append({
                        "node": "tool_execution",
                        "type": "tool",
                        "duration": 0.0,
                        "state": "success",
                        "output": {
                            "tool_name": tool_name,
                            "tool_input": tool_input,
                            "tool_output": tool_output
                        }
                    })
                    
                    yield "", history, execution_trace, "", [], ""
                    
                elif chunk_type == "tool_error":
                    # å·¥å…·æ‰§è¡Œé”™è¯¯
                    error_msg = chunk_data.get("metadata", {}).get("error", "")
                    accumulated_response += chunk_content
                    history[-1]["content"] = accumulated_response
                    
                    execution_trace.append({
                        "node": "tool_error",
                        "type": "tool",
                        "duration": 0.0,
                        "state": "failed",
                        "output": {"error": error_msg}
                    })
                    
                    yield "", history, execution_trace, "", [], ""
                    
                elif chunk_type == "final_result":
                    # æœ€ç»ˆç»“æœï¼ˆå›é€€æ¨¡å¼ï¼‰
                    history[-1]["content"] = chunk_content
                    yield "", history, {}, "", [], ""
            
            # ç”Ÿæˆæœ€ç»ˆæŒ‡æ ‡
            metrics_text = self._format_stream_metrics(tool_calls_made, accumulated_response)
            
            # ç”ŸæˆèŠ‚ç‚¹çŠ¶æ€è¡¨
            node_status = self._generate_node_status(execution_trace)
            
            # ç”Ÿæˆæµç¨‹å›¾
            flow_diagram = self._generate_flow_diagram(execution_trace)
            
            # æœ€ç»ˆè¾“å‡º
            yield "", history, execution_trace, metrics_text, node_status, flow_diagram
            
        except Exception as e:
            # å¤„ç†é”™è¯¯
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"
            print(error_msg)
            history[-1]["content"] = f"æŠ±æ­‰ï¼Œ{error_msg}"
            yield "", history, {}, "", [], ""
    
    def _format_stream_metrics(self, tool_calls: List[Dict], response_text: str) -> str:
        """æ ¼å¼åŒ–æµå¼å¤„ç†æŒ‡æ ‡"""
        metrics = {
            "å·¥å…·è°ƒç”¨æ¬¡æ•°": len(tool_calls),
            "å“åº”å­—ç¬¦æ•°": len(response_text),
            "å·¥å…·ç±»å‹": list(set(call.get("tool_name", "") for call in tool_calls)) if tool_calls else []
        }
        
        lines = []
        for key, value in metrics.items():
            if isinstance(value, list):
                lines.append(f"{key}: {', '.join(value) if value else 'æ— '}")
            else:
                lines.append(f"{key}: {value}")
        
        return "\n".join(lines)
    
    def _generate_node_status(self, trace: List[Dict[str, Any]]) -> List[List[Any]]:
        """ç”ŸæˆèŠ‚ç‚¹çŠ¶æ€è¡¨"""
        if not trace:
            return []
        
        status_data = []
        for step in trace:
            node_name = step.get("node", "")
            node_type = step.get("type", "")
            state = step.get("state", "")
            duration = step.get("duration", 0)
            
            # è·å–è¾“å‡ºé¢„è§ˆ
            output = step.get("output", {})
            if isinstance(output, dict):
                # æå–å…³é”®ä¿¡æ¯ä½œä¸ºé¢„è§ˆ
                if "answer" in output:
                    preview = output["answer"][:50] + "..." if len(output.get("answer", "")) > 50 else output.get("answer", "")
                elif "thought" in output:
                    preview = output["thought"][:50] + "..." if len(output.get("thought", "")) > 50 else output.get("thought", "")
                elif "action" in output:
                    preview = f"æ‰§è¡Œ: {output.get('action', '')[:30]}..."
                else:
                    preview = str(output)[:50] + "..." if len(str(output)) > 50 else str(output)
            else:
                preview = str(output)[:50] + "..." if len(str(output)) > 50 else str(output)
            
            # æ·»åŠ è¡¨æƒ…ç¬¦å·è¡¨ç¤ºçŠ¶æ€
            state_emoji = {
                "success": "âœ…",
                "failed": "âŒ",
                "running": "ğŸ”„",
                "pending": "â³"
            }.get(state, "â“")
            
            status_data.append([
                node_name,
                node_type,
                f"{state_emoji} {state}",
                f"{duration:.2f}" if duration else "0.00",
                preview
            ])
        
        return status_data
    
    def _generate_flow_diagram(self, trace: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæµç¨‹å›¾HTML"""
        if not trace:
            return "<p>æš‚æ— æ‰§è¡Œæµç¨‹</p>"
        
        # ä½¿ç”¨Mermaidç”Ÿæˆæµç¨‹å›¾
        mermaid_code = "graph TD\n"
        
        # æ·»åŠ èŠ‚ç‚¹
        for i, step in enumerate(trace):
            node_name = step.get("node", f"node_{i}")
            node_type = step.get("type", "unknown")
            state = step.get("state", "")
            
            # æ ¹æ®çŠ¶æ€é€‰æ‹©æ ·å¼
            if state == "success":
                style = "fill:#90EE90"
            elif state == "failed":
                style = "fill:#FFB6C1"
            elif state == "running":
                style = "fill:#87CEEB"
            else:
                style = "fill:#F0F0F0"
            
            # æ·»åŠ èŠ‚ç‚¹å®šä¹‰
            label = f"{node_name}\\n[{node_type}]"
            mermaid_code += f"    {node_name}[\"{label}\"]:::state{i}\n"
            mermaid_code += f"    classDef state{i} {style}\n"
            
            # æ·»åŠ è¿æ¥
            if i > 0:
                prev_node = trace[i-1].get("node", f"node_{i-1}")
                mermaid_code += f"    {prev_node} --> {node_name}\n"
        
        # ç”ŸæˆHTML
        html = f"""
        <div id="mermaid-diagram">
            <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
            <script>
                mermaid.initialize({{ startOnLoad: true }});
            </script>
            <div class="mermaid">
                {mermaid_code}
            </div>
        </div>
        <style>
            #mermaid-diagram {{
                width: 100%;
                min-height: 300px;
                background: #f9f9f9;
                border-radius: 8px;
                padding: 20px;
            }}
            .mermaid {{
                text-align: center;
            }}
        </style>
        """
        
        return html
    
    async def _batch_execute(self, batch_input: str, parallel: bool):
        """æ‰§è¡Œæ‰¹é‡ä»»åŠ¡"""
        if not self.current_agent:
            return [["", "é”™è¯¯", "è¯·å…ˆé…ç½®Agentï¼", ""]]
        
        tasks = [line.strip() for line in batch_input.split('\n') if line.strip()]
        results = []
        
        if parallel:
            # å¹¶è¡Œæ‰§è¡Œ
            async_tasks = [self.current_agent.run(task) for task in tasks]
            task_results = await asyncio.gather(*async_tasks, return_exceptions=True)
            
            for task, result in zip(tasks, task_results):
                if isinstance(result, Exception):
                    results.append([task, "å¤±è´¥", str(result), ""])
                else:
                    results.append([
                        task,
                        "æˆåŠŸ" if result.success else "å¤±è´¥",
                        result.result or result.error,
                        f"{result.duration:.2f}s" if result.duration else ""
                    ])
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            for task in tasks:
                try:
                    result = await self.current_agent.run(task)
                    results.append([
                        task,
                        "æˆåŠŸ" if result.success else "å¤±è´¥",
                        result.result or result.error,
                        f"{result.duration:.2f}s" if result.duration else ""
                    ])
                except Exception as e:
                    results.append([task, "å¤±è´¥", str(e), ""])
        
        return results
    
    def launch(self, **kwargs):
        """å¯åŠ¨åº”ç”¨"""
        app = self.create_interface()
        app.launch(**kwargs)
"""
è§’è‰²èµ„æ–™ç”Ÿæˆå·¥ä½œæµç•Œé¢ç»„ä»¶
"""

import gradio as gr
import asyncio
import json
import logging
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime
from pathlib import Path

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from workflow.character_profile_workflow import CharacterProfileWorkflow
from tools.knowledge_base_manager import GlobalKnowledgeBase
from core.types import LLMConfig

logger = logging.getLogger(__name__)

class CharacterProfileInterface:
    """è§’è‰²èµ„æ–™ç”Ÿæˆå·¥ä½œæµç•Œé¢"""
    
    def __init__(self):
        self.workflow = CharacterProfileWorkflow()
        self.knowledge_base = GlobalKnowledgeBase("./workspace")
        
        # ç¼“å­˜æ•°æ®
        self.available_categories = []
        self.available_collections = []
        self._load_categories()
        self._load_collections()
    
    def _load_categories(self):
        """åŠ è½½å¯ç”¨çš„èµ„æ–™ç±»åˆ«"""
        try:
            self.available_categories = self.workflow.get_available_categories()
            logger.info(f"å·²åŠ è½½{len(self.available_categories)}ä¸ªèµ„æ–™ç±»åˆ«")
        except Exception as e:
            logger.error(f"åŠ è½½èµ„æ–™ç±»åˆ«å¤±è´¥: {e}")
            self.available_categories = []
    
    def _load_collections(self):
        """åŠ è½½å¯ç”¨çš„çŸ¥è¯†é›†åˆ"""
        try:
            self.available_collections = self.workflow.get_available_collections()
            logger.info(f"å·²åŠ è½½{len(self.available_collections)}ä¸ªçŸ¥è¯†é›†åˆ")
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†é›†åˆå¤±è´¥: {e}")
            self.available_collections = []
    
    def create_character_profile_interface(self) -> Dict[str, Any]:
        """åˆ›å»ºå®Œæ•´çš„è§’è‰²èµ„æ–™ç”Ÿæˆç•Œé¢"""
        components = {}
        
        with gr.Column():
            # æ ‡é¢˜å’Œæè¿°
            gr.Markdown("## ğŸ­ è§’è‰²èµ„æ–™ç”Ÿæˆå·¥ä½œæµ")
            gr.Markdown("åŸºäºäººç‰©èµ„æ–™éœ€æ±‚è¡¨æ ¼ï¼Œç»“åˆå‘é‡çŸ¥è¯†åº“ï¼Œç”Ÿæˆè¯¦ç»†çš„è§’è‰²èƒŒæ™¯èµ„æ–™")
            
            with gr.Row(equal_height=True):
                # å·¦ä¾§é…ç½®é¢æ¿
                with gr.Column(scale=1, min_width=400):
                    config_components = self._create_config_panel()
                    components.update(config_components)
                
                # å³ä¾§ç”Ÿæˆç»“æœé¢æ¿
                with gr.Column(scale=2, min_width=600):
                    result_components = self._create_result_panel()
                    components.update(result_components)
            
            # åº•éƒ¨æ‰¹é‡å¤„ç†é¢æ¿
            batch_components = self._create_batch_panel()
            components.update(batch_components)
        
        # ç»‘å®šäº‹ä»¶
        self._bind_events(components)
        
        return components
    
    def _create_config_panel(self) -> Dict[str, Any]:
        """åˆ›å»ºé…ç½®é¢æ¿"""
        components = {}
        
        with gr.Column():
            gr.Markdown("### âš™ï¸ ç”Ÿæˆé…ç½®")
            
            # å†å²è®°å½•é€‰æ‹©
            with gr.Group():
                gr.Markdown("#### ğŸ“š å†å²è®°å½•")
                components['history_dropdown'] = gr.Dropdown(
                    label="é€‰æ‹©å†å²è®°å½•",
                    choices=self._get_history_choices(),
                    value=None,
                    interactive=True,
                    info="é€‰æ‹©ä¹‹å‰çš„è§’è‰²é…ç½®"
                )
                
                with gr.Row():
                    components['load_history'] = gr.Button(
                        "è½½å…¥é€‰ä¸­è®°å½•",
                        size="sm",
                        variant="secondary"
                    )
                    
                    components['refresh_history'] = gr.Button(
                        "åˆ·æ–°å†å²",
                        size="sm",
                        variant="secondary"
                    )
            
            # è§’è‰²åŸºæœ¬ä¿¡æ¯
            with gr.Group():
                gr.Markdown("#### è§’è‰²ä¿¡æ¯")
                components['character_name'] = gr.Textbox(
                    label="è§’è‰²åç§°",
                    placeholder="è¯·è¾“å…¥è§’è‰²åç§°...",
                    value=""
                )
                
                components['basic_info'] = gr.Textbox(
                    label="åŸºç¡€äººè®¾",
                    placeholder="è¯·è¾“å…¥è§’è‰²çš„åŸºç¡€äººè®¾ä¿¡æ¯...",
                    lines=6,
                    value=""
                )
            
            # ç±»åˆ«é€‰æ‹©
            with gr.Group():
                gr.Markdown("#### ç”Ÿæˆç±»åˆ«")
                components['category_selector'] = gr.CheckboxGroup(
                    label="é€‰æ‹©è¦ç”Ÿæˆçš„èµ„æ–™ç±»åˆ«",
                    choices=self.available_categories,
                    value=self.available_categories[:3] if self.available_categories else [],
                    interactive=True
                )
                
                components['select_all_categories'] = gr.Button(
                    "å…¨é€‰ç±»åˆ«",
                    size="sm",
                    variant="secondary"
                )
            
            # çŸ¥è¯†åº“é€‰æ‹©
            with gr.Group():
                gr.Markdown("#### çŸ¥è¯†åº“é€‰æ‹©")
                components['knowledge_selector'] = gr.CheckboxGroup(
                    label="é€‰æ‹©å¯ç”¨çš„çŸ¥è¯†é›†åˆ",
                    choices=self.available_collections,
                    value=[],
                    interactive=True,
                    info="é€‰ä¸­çš„çŸ¥è¯†åº“å°†åœ¨ç”Ÿæˆæ—¶æä¾›å‚è€ƒä¿¡æ¯"
                )
                
                components['refresh_collections'] = gr.Button(
                    "åˆ·æ–°çŸ¥è¯†åº“",
                    size="sm",
                    variant="secondary"
                )
            
            # LLMé…ç½®
            with gr.Group():
                gr.Markdown("#### LLMé…ç½®")
                components['llm_provider'] = gr.Dropdown(
                    label="LLMæä¾›å•†",
                    choices=["doubao", "openai"],
                    value="doubao",
                    interactive=True
                )
                
                components['model_name'] = gr.Textbox(
                    label="æ¨¡å‹åç§°",
                    value="ep-20250221154410-vh78x",
                    interactive=True
                )
                
                components['temperature'] = gr.Slider(
                    label="Temperature",
                    minimum=0.0,
                    maximum=2.0,
                    value=0.7,
                    step=0.1,
                    interactive=True
                )
                
                components['max_tokens'] = gr.Number(
                    label="æœ€å¤§Tokenæ•°",
                    value=2000,
                    minimum=100,
                    maximum=8000,
                    interactive=True
                )
            
            # ç”ŸæˆæŒ‰é’®
            components['generate_button'] = gr.Button(
                "ğŸš€ å¼€å§‹ç”Ÿæˆ",
                variant="primary",
                size="lg"
            )
        
        return components
    
    def _create_result_panel(self) -> Dict[str, Any]:
        """åˆ›å»ºç»“æœå±•ç¤ºé¢æ¿"""
        components = {}
        
        with gr.Column():
            gr.Markdown("### ğŸ“‹ ç”Ÿæˆç»“æœ")
            
            # çŠ¶æ€æ˜¾ç¤º
            components['status_display'] = gr.Markdown(
                "**çŠ¶æ€:** ç­‰å¾…ç”Ÿæˆ...",
                visible=True
            )
            
            # è¿›åº¦æ¡ï¼ˆå°†åœ¨éœ€è¦æ—¶ä½¿ç”¨ï¼‰
            # components['progress_bar'] = gr.Progress()  # Progressç»„ä»¶ä¸æ”¯æŒvisibleå‚æ•°
            
            # ç»“æœå±•ç¤ºåŒºåŸŸ
            with gr.Tabs() as tabs:
                with gr.Tab("ğŸ“Š ç»“æœæ¦‚è§ˆ"):
                    components['result_summary'] = gr.Markdown(
                        "æš‚æ— ç”Ÿæˆç»“æœ",
                        visible=True
                    )
                
                with gr.Tab("ğŸ“„ è¯¦ç»†å†…å®¹"):
                    components['result_detail'] = gr.JSON(
                        label="ç”Ÿæˆçš„è§’è‰²èµ„æ–™",
                        value={},
                        visible=True
                    )
                
                with gr.Tab("ğŸ’¾ æ–‡ä»¶ä¸‹è½½"):
                    components['download_file'] = gr.File(
                        label="ä¸‹è½½ç”Ÿæˆçš„è§’è‰²èµ„æ–™æ–‡ä»¶",
                        visible=False
                    )
                    
                    components['file_path_display'] = gr.Textbox(
                        label="æ–‡ä»¶ä¿å­˜è·¯å¾„",
                        interactive=False,
                        visible=False
                    )
        
        return components
    
    def _create_batch_panel(self) -> Dict[str, Any]:
        """åˆ›å»ºæ‰¹é‡å¤„ç†é¢æ¿"""
        components = {}
        
        with gr.Accordion("ğŸ”„ æ‰¹é‡å¤„ç†", open=False):
            gr.Markdown("æ‰¹é‡ç”Ÿæˆå¤šä¸ªè§’è‰²çš„èµ„æ–™")
            
            with gr.Row():
                with gr.Column(scale=2):
                    components['batch_input'] = gr.Textbox(
                        label="æ‰¹é‡è§’è‰²ä¿¡æ¯ (JSONæ ¼å¼)",
                        placeholder="""ç¤ºä¾‹æ ¼å¼ï¼š
[
    {
        "character_name": "è§’è‰²1",
        "basic_info": "è§’è‰²1çš„åŸºç¡€ä¿¡æ¯...",
        "selected_categories": ["åŸºæœ¬ä¿¡æ¯", "å¤–è²Œç‰¹å¾"]
    },
    {
        "character_name": "è§’è‰²2", 
        "basic_info": "è§’è‰²2çš„åŸºç¡€ä¿¡æ¯..."
    }
]""",
                        lines=8,
                        interactive=True
                    )
                
                with gr.Column(scale=1):
                    components['batch_example'] = gr.Button(
                        "åŠ è½½ç¤ºä¾‹",
                        variant="secondary"
                    )
                    
                    components['batch_generate'] = gr.Button(
                        "ğŸš€ æ‰¹é‡ç”Ÿæˆ",
                        variant="primary"
                    )
            
            # æ‰¹é‡ç»“æœå±•ç¤º
            components['batch_results'] = gr.Dataframe(
                label="æ‰¹é‡ç”Ÿæˆç»“æœ",
                headers=["è§’è‰²åç§°", "ç”ŸæˆçŠ¶æ€", "æ–‡ä»¶è·¯å¾„", "é”™è¯¯ä¿¡æ¯"],
                datatype=["str", "str", "str", "str"],
                interactive=False,
                visible=False
            )
        
        return components
    
    def _bind_events(self, components: Dict[str, Any]):
        """ç»‘å®šç•Œé¢äº‹ä»¶"""
        
        # åˆ·æ–°å†å²è®°å½•æŒ‰é’®
        components['refresh_history'].click(
            fn=self._refresh_history,
            outputs=components['history_dropdown']
        )
        
        # è½½å…¥å†å²è®°å½•æŒ‰é’®
        components['load_history'].click(
            fn=self._load_history_record,
            inputs=components['history_dropdown'],
            outputs=[
                components['character_name'],
                components['basic_info'],
                components['category_selector'],
                components['knowledge_selector']
            ]
        )
        
        # å…¨é€‰ç±»åˆ«æŒ‰é’®
        components['select_all_categories'].click(
            fn=lambda: gr.update(value=self.available_categories),
            outputs=components['category_selector']
        )
        
        # åˆ·æ–°çŸ¥è¯†åº“æŒ‰é’®
        components['refresh_collections'].click(
            fn=self._refresh_collections,
            outputs=components['knowledge_selector']
        )
        
        # ç”ŸæˆæŒ‰é’®
        components['generate_button'].click(
            fn=self._generate_character_profile,
            inputs=[
                components['character_name'],
                components['basic_info'],
                components['category_selector'],
                components['knowledge_selector'],
                components['llm_provider'],
                components['model_name'],
                components['temperature'],
                components['max_tokens']
            ],
            outputs=[
                components['status_display'],
                components['result_summary'],
                components['result_detail'],
                components['download_file'],
                components['file_path_display']
            ]
        )
        
        # æ‰¹é‡ç¤ºä¾‹æŒ‰é’®
        components['batch_example'].click(
            fn=self._load_batch_example,
            outputs=components['batch_input']
        )
        
        # æ‰¹é‡ç”ŸæˆæŒ‰é’®
        components['batch_generate'].click(
            fn=self._batch_generate_profiles,
            inputs=[
                components['batch_input'],
                components['knowledge_selector'],
                components['llm_provider'],
                components['model_name'],
                components['temperature'],
                components['max_tokens']
            ],
            outputs=[
                components['batch_results'],
                components['status_display']
            ]
        )
    
    def _get_history_choices(self) -> List[str]:
        """è·å–å†å²è®°å½•é€‰æ‹©é¡¹"""
        try:
            history_records = self.workflow.get_history_records()
            choices = []
            for i, record in enumerate(reversed(history_records)):  # æœ€æ–°çš„åœ¨å‰
                character_name = record.get('character_name', 'æœªçŸ¥è§’è‰²')[:20]
                created_at = record.get('created_at', '')
                if created_at:
                    try:
                        dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                        time_str = dt.strftime('%m-%d %H:%M')
                    except:
                        time_str = created_at[:16]
                else:
                    time_str = 'æœªçŸ¥æ—¶é—´'
                
                choice = f"{character_name} ({time_str})"
                choices.append(choice)
            
            return choices
        except Exception as e:
            logger.error(f"è·å–å†å²è®°å½•é€‰æ‹©é¡¹å¤±è´¥: {e}")
            return []
    
    def _refresh_history(self):
        """åˆ·æ–°å†å²è®°å½•ä¸‹æ‹‰åˆ—è¡¨"""
        try:
            choices = self._get_history_choices()
            return gr.update(choices=choices, value=None)
        except Exception as e:
            logger.error(f"åˆ·æ–°å†å²è®°å½•å¤±è´¥: {e}")
            return gr.update()
    
    def _load_history_record(self, selected_choice: str):
        """è½½å…¥é€‰ä¸­çš„å†å²è®°å½•"""
        try:
            if not selected_choice:
                return "", "", [], []
            
            # è·å–å†å²è®°å½•
            history_records = self.workflow.get_history_records()
            if not history_records:
                return "", "", [], []
            
            # ä»é€‰æ‹©é¡¹ä¸­æå–ç´¢å¼•ï¼ˆåå‘ç´¢å¼•ï¼Œå› ä¸ºæ˜¾ç¤ºæ—¶æ˜¯æœ€æ–°çš„åœ¨å‰ï¼‰
            choices = self._get_history_choices()
            if selected_choice not in choices:
                return "", "", [], []
            
            choice_index = choices.index(selected_choice)
            record_index = len(history_records) - 1 - choice_index  # åå‘ç´¢å¼•
            
            if 0 <= record_index < len(history_records):
                record = history_records[record_index]
                
                character_name = record.get('character_name', '')
                basic_info = record.get('basic_info', '')
                selected_categories = record.get('selected_categories', [])
                selected_collections = record.get('selected_collections', [])
                
                return (
                    character_name,
                    basic_info,
                    selected_categories,
                    selected_collections
                )
            else:
                return "", "", [], []
                
        except Exception as e:
            logger.error(f"è½½å…¥å†å²è®°å½•å¤±è´¥: {e}")
            return "", "", [], []
    
    def _refresh_collections(self):
        """åˆ·æ–°çŸ¥è¯†é›†åˆåˆ—è¡¨"""
        try:
            self._load_collections()
            return gr.update(choices=self.available_collections, value=[])
        except Exception as e:
            logger.error(f"åˆ·æ–°çŸ¥è¯†é›†åˆå¤±è´¥: {e}")
            return gr.update()
    
    def _generate_character_profile(self, 
                                  character_name: str,
                                  basic_info: str,
                                  selected_categories: List[str],
                                  selected_collections: List[str],
                                  llm_provider: str,
                                  model_name: str,
                                  temperature: float,
                                  max_tokens: int):
        """ç”Ÿæˆè§’è‰²èµ„æ–™"""
        try:
            # éªŒè¯è¾“å…¥
            if not character_name or not basic_info:
                return (
                    "**çŠ¶æ€:** âŒ è¯·è¾“å…¥è§’è‰²åç§°å’ŒåŸºç¡€ä¿¡æ¯",
                    "è¯·å…ˆå¡«å†™å¿…è¦ä¿¡æ¯",
                    {},
                    None,
                    ""
                )
            
            # æ›´æ–°çŠ¶æ€
            status_update = "**çŠ¶æ€:** ğŸ”„ æ­£åœ¨ç”Ÿæˆè§’è‰²èµ„æ–™..."
            
            # åˆ›å»ºLLMé…ç½® - æ·»åŠ APIå¯†é’¥
            import os
            api_key = os.getenv('ARK_API_KEY') or os.getenv('DOUBAO_API_KEY')
            if not api_key:
                return (
                    "**çŠ¶æ€:** âŒ ç¼ºå°‘APIå¯†é’¥é…ç½®ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„DOUBAO_API_KEYæˆ–ARK_API_KEY",
                    "è¯·å…ˆé…ç½®APIå¯†é’¥",
                    {},
                    None,
                    ""
                )
            
            # æ ¹æ®æä¾›å•†è®¾ç½®API base URL
            api_base = None
            if llm_provider == "doubao":
                api_base = os.getenv('DOUBAO_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3')
            elif llm_provider == "openai":
                api_base = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            
            llm_config = LLMConfig(
                provider=llm_provider,
                model_name=model_name,
                api_key=api_key,
                api_base=api_base,
                temperature=temperature,
                max_tokens=int(max_tokens)
            )
            
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            workflow = CharacterProfileWorkflow(llm_config=llm_config)
            
            # æ‰§è¡Œç”Ÿæˆï¼ˆåŒæ­¥æ–¹å¼ï¼Œåœ¨å®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦å¼‚æ­¥å¤„ç†ï¼‰
            result = asyncio.run(workflow.generate_character_profile(
                character_name=character_name,
                basic_info=basic_info,
                selected_categories=selected_categories,
                selected_collections=selected_collections
            ))
            
            if result.get('success'):
                # ç”ŸæˆæˆåŠŸ
                profile_data = result.get('generated_profile', {})
                output_file = result.get('output_file', '')
                
                # æ„å»ºæ¦‚è§ˆä¿¡æ¯
                total_categories = len(profile_data)
                total_fields = sum(len(category_data) for category_data in profile_data.values())
                
                summary = f"""
### âœ… ç”ŸæˆæˆåŠŸï¼

- **è§’è‰²åç§°:** {character_name}
- **ç”Ÿæˆç±»åˆ«:** {total_categories} ä¸ª
- **æ€»å­—æ®µæ•°:** {total_fields} ä¸ª
- **ä½¿ç”¨çŸ¥è¯†åº“:** {len(selected_collections)} ä¸ª
- **ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                """
                
                return (
                    "**çŠ¶æ€:** âœ… ç”Ÿæˆå®Œæˆ",
                    summary,
                    profile_data,
                    output_file if Path(output_file).exists() else None,
                    output_file
                )
            else:
                # ç”Ÿæˆå¤±è´¥
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                return (
                    f"**çŠ¶æ€:** âŒ ç”Ÿæˆå¤±è´¥: {error_msg}",
                    f"ç”Ÿæˆå¤±è´¥: {error_msg}",
                    {},
                    None,
                    ""
                )
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆè§’è‰²èµ„æ–™å¤±è´¥: {e}")
            return (
                f"**çŠ¶æ€:** âŒ ç”Ÿæˆå¤±è´¥: {str(e)}",
                f"å‘ç”Ÿé”™è¯¯: {str(e)}",
                {},
                None,
                ""
            )
    
    def _load_batch_example(self):
        """åŠ è½½æ‰¹é‡å¤„ç†ç¤ºä¾‹"""
        example = [
            {
                "character_name": "ç©†æ˜­",
                "basic_info": "22å²ï¼Œç¥ç§˜ç”µç«é«˜æ‰‹ï¼Œä»£å·Jï¼Œå¼‚ç«¯ç»„ç»‡å¤§é˜¿å¡é‚£æˆå‘˜",
                "selected_categories": ["åŸºæœ¬ä¿¡æ¯", "å¤–è²Œç‰¹å¾", "æ€§æ ¼ç‰¹å¾"]
            },
            {
                "character_name": "æµ‹è¯•è§’è‰²A",
                "basic_info": "å‹‡æ•¢çš„æˆ˜å£«ï¼Œæ“…é•¿å‰‘æœ¯ï¼Œæ­£ä¹‰æ„Ÿå¼º",
                "selected_categories": ["åŸºæœ¬ä¿¡æ¯", "æ€§æ ¼ç‰¹å¾", "æŠ€èƒ½èƒ½åŠ›"]
            },
            {
                "character_name": "æµ‹è¯•è§’è‰²B",
                "basic_info": "èªæ˜çš„æ³•å¸ˆï¼Œç²¾é€šé­”æ³•ï¼Œæ€§æ ¼å†…å‘",
                "selected_categories": ["åŸºæœ¬ä¿¡æ¯", "æŠ€èƒ½èƒ½åŠ›"]
            }
        ]
        
        return json.dumps(example, ensure_ascii=False, indent=2)
    
    def _batch_generate_profiles(self,
                               batch_input: str,
                               selected_collections: List[str],
                               llm_provider: str,
                               model_name: str,
                               temperature: float,
                               max_tokens: int):
        """æ‰¹é‡ç”Ÿæˆè§’è‰²èµ„æ–™"""
        try:
            # è§£æè¾“å…¥
            try:
                profiles_data = json.loads(batch_input)
                if not isinstance(profiles_data, list):
                    raise ValueError("è¾“å…¥å¿…é¡»æ˜¯æ•°ç»„æ ¼å¼")
            except json.JSONDecodeError as e:
                return (
                    gr.update(visible=False),
                    f"**çŠ¶æ€:** âŒ JSONæ ¼å¼é”™è¯¯: {str(e)}"
                )
            
            # åˆ›å»ºLLMé…ç½® - æ·»åŠ APIå¯†é’¥
            import os
            api_key = os.getenv('ARK_API_KEY') or os.getenv('DOUBAO_API_KEY')
            if not api_key:
                return (
                    gr.update(visible=False),
                    "**çŠ¶æ€:** âŒ ç¼ºå°‘APIå¯†é’¥é…ç½®ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„DOUBAO_API_KEYæˆ–ARK_API_KEY"
                )
            
            # æ ¹æ®æä¾›å•†è®¾ç½®API base URL
            api_base = None
            if llm_provider == "doubao":
                api_base = os.getenv('DOUBAO_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3')
            elif llm_provider == "openai":
                api_base = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            
            llm_config = LLMConfig(
                provider=llm_provider,
                model_name=model_name,
                api_key=api_key,
                api_base=api_base,
                temperature=temperature,
                max_tokens=int(max_tokens)
            )
            
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            workflow = CharacterProfileWorkflow(llm_config=llm_config)
            
            # æ›´æ–°çŠ¶æ€
            status_update = f"**çŠ¶æ€:** ğŸ”„ æ­£åœ¨æ‰¹é‡ç”Ÿæˆ {len(profiles_data)} ä¸ªè§’è‰²çš„èµ„æ–™..."
            
            # æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ
            results = asyncio.run(workflow.batch_generate_profiles(
                profiles_data=profiles_data,
                selected_collections=selected_collections
            ))
            
            # æ„å»ºç»“æœè¡¨æ ¼
            result_rows = []
            success_count = 0
            
            for result in results:
                character_name = result.get('character_name', 'æœªçŸ¥')
                success = result.get('success', False)
                output_file = result.get('output_file', '')
                error = result.get('error', '')
                
                if success:
                    success_count += 1
                    status = "âœ… æˆåŠŸ"
                else:
                    status = "âŒ å¤±è´¥"
                
                result_rows.append([
                    character_name,
                    status,
                    output_file,
                    error
                ])
            
            final_status = f"**çŠ¶æ€:** âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {success_count}/{len(profiles_data)}"
            
            return (
                gr.update(value=result_rows, visible=True),
                final_status
            )
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            return (
                gr.update(visible=False),
                f"**çŠ¶æ€:** âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}"
            ) 
"""
æµå¼ReAct AgentèŠ‚ç‚¹ - æ”¯æŒæµå¼è¾“å‡ºå’ŒObservationæ£€æµ‹
"""
import sys
import os
import re
import json
import asyncio
from typing import Dict, Any, List, AsyncIterator, Optional

sys.path.append(os.path.join(os.path.dirname(__file__), '../'))

from core.base import BaseNode
from core.types import NodeInput, NodeOutput, NodeType, Message, MessageRole
from llm.base import BaseLLMProvider
from parsers.regex_parser import RegexParser


class StreamReactAgentNode(BaseNode):
    """æ”¯æŒæµå¼è¾“å‡ºå’ŒObservationæ£€æµ‹çš„ReAct AgentèŠ‚ç‚¹"""
    
    def __init__(self, name: str, llm: BaseLLMProvider, tool_manager=None, **kwargs):
        """
        åˆå§‹åŒ–æµå¼ReAct AgentèŠ‚ç‚¹
        
        Args:
            name: èŠ‚ç‚¹åç§°
            llm: LLMæä¾›è€…
            tool_manager: å·¥å…·ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        super().__init__(name, NodeType.AGENT, "æµå¼ReActæ™ºèƒ½ä»£ç†èŠ‚ç‚¹", **kwargs)
        self.llm = llm
        self.tool_manager = tool_manager
        
        # åˆ›å»ºæ­£åˆ™è§£æå™¨ç”¨äºæå–Actionå’ŒAction Input
        self.react_parser = RegexParser({
            'action': r'Action:\s*([^\n]+)',
            'action_input': r'Action Input:\s*(.*?)(?=\nObservation:|$)', 
            'thought': r'Thought:\s*([^\n]+)',
            'observation': r'Observation:\s*([^\n]+)'
        }, flags=re.DOTALL)
        
    async def execute(self, input_data: NodeInput) -> NodeOutput:
        """æ‰§è¡Œæµå¼ReActæ¨ç†é€»è¾‘"""
        context = input_data.context
        
        # è·å–å¯¹è¯å†å²
        messages = context.messages.copy()
        
        # æ·»åŠ ç³»ç»Ÿæç¤º
        system_prompt = self._build_system_prompt(context)
        print(f"[StreamReactAgentNode.execute] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}")
        
        if not any(msg.role == MessageRole.SYSTEM for msg in messages):
            messages.insert(0, Message(
                role=MessageRole.SYSTEM,
                content=system_prompt
            ))
            print(f"[StreamReactAgentNode.execute] å·²æ·»åŠ ç³»ç»Ÿæç¤ºè¯")
        else:
            print(f"[StreamReactAgentNode.execute] å·²å­˜åœ¨ç³»ç»Ÿæç¤ºè¯ï¼Œè·³è¿‡")
        
        # æ‰§è¡Œæµå¼ç”Ÿæˆ
        full_response = ""
        response_chunks = []
        
        async for chunk_data in self._stream_react_generation(messages):
            if chunk_data["type"] == "text_chunk":
                full_response += chunk_data["content"]
                response_chunks.append(chunk_data)
            elif chunk_data["type"] == "tool_result":
                # å·¥å…·æ‰§è¡Œç»“æœ
                full_response += chunk_data["content"]
                response_chunks.append(chunk_data)
        
        # åˆ›å»ºå®Œæ•´çš„å“åº”æ¶ˆæ¯
        response = Message(
            role=MessageRole.ASSISTANT,
            content=full_response,
            metadata={
                "stream_chunks": response_chunks,
                "tool_calls_executed": sum(1 for chunk in response_chunks if chunk["type"] == "tool_result")
            }
        )
        
        # æ·»åŠ å“åº”åˆ°ä¸Šä¸‹æ–‡
        context.messages.append(response)
        
        return NodeOutput(
            data={
                "messages": [response],
                "agent_response": full_response,
                "stream_chunks": response_chunks,
                "has_tool_calls": any(chunk["type"] == "tool_result" for chunk in response_chunks)
            },
            next_node=None,
            should_continue=True,
            metadata={
                "node_type": "stream_react_agent",
                "total_chunks": len(response_chunks),
                "tool_calls_count": sum(1 for chunk in response_chunks if chunk["type"] == "tool_result")
            }
        )
    
    async def _stream_react_generation(self, messages: List[Message]) -> AsyncIterator[Dict[str, Any]]:
        """æµå¼ç”ŸæˆReActå“åº”ï¼Œæ£€æµ‹Observationå¹¶è°ƒç”¨å·¥å…·"""
        # å§”æ‰˜ç»™å¸¦æ·±åº¦æ§åˆ¶çš„ç‰ˆæœ¬ï¼Œåˆå§‹æ·±åº¦ä¸º0
        async for chunk in self._stream_react_generation_with_depth(messages, 0):
            yield chunk
    
    async def _handle_tool_execution(self, accumulated_content: str, messages: List[Message], recursion_depth: int = 0) -> AsyncIterator[Dict[str, Any]]:
        """å¤„ç†å·¥å…·æ‰§è¡Œé€»è¾‘ - ZZZeroåˆ†æç‰ˆæœ¬"""
        # é˜²æ­¢é€’å½’è¿‡æ·±
        if recursion_depth > 10:
            yield {
                "type": "tool_error",
                "content": "æ¨ç†æ·±åº¦è¶…è¿‡é™åˆ¶ï¼Œåœæ­¢è¿›ä¸€æ­¥é€’å½’åˆ†æ\n",
                "error": "é€’å½’æ·±åº¦è¶…è¿‡æœ€å¤§é™åˆ¶"
            }
            return
        
        # è§£æActionå’ŒAction Input
        parsed_content = self.react_parser.parse(accumulated_content)
        
        action = parsed_content.get('action')
        action_input = parsed_content.get('action_input')
        
        if action and self.tool_manager:
            # è°ƒç”¨MCPå·¥å…·
            try:
                tool_result = await self._execute_tool(action.strip(), action_input.strip() if action_input else "")
                
                # ZZZeroå¯¹å·¥å…·ç»“æœè¿›è¡Œåˆ†æå’Œæ ¡éªŒ
                observation_analysis = await self._analyze_tool_result(
                    tool_name=action.strip(),
                    tool_input=action_input.strip() if action_input else "",
                    tool_result=tool_result,
                    context_content=accumulated_content
                )
                
                # æ„é€ ZZZeroé£æ ¼çš„Observationç»“æœ
                observation_text = f" {observation_analysis}\n"
                
                # å‘é€å·¥å…·ç»“æœ
                yield {
                    "type": "tool_result",
                    "content": observation_text,
                    "tool_name": action.strip(),
                    "tool_input": action_input.strip() if action_input else "",
                    "tool_output": tool_result,
                    "analysis": observation_analysis,
                    "recursion_depth": recursion_depth
                }
                
                # æ›´æ–°ç´¯ç§¯å†…å®¹ - å°†åˆ†æç»“æœæ‹¼æ¥åˆ°Observationåé¢
                updated_content = accumulated_content + observation_text
                
                # ç»§ç»­ç”Ÿæˆï¼ŒåŸºäºæ›´æ–°åçš„ä¸Šä¸‹æ–‡
                messages_with_observation = messages.copy()
                messages_with_observation.append(Message(
                    role=MessageRole.ASSISTANT,
                    content=updated_content
                ))
                
                # é€’å½’ç»§ç»­æµå¼ç”Ÿæˆï¼Œä¼ é€’é€’å½’æ·±åº¦
                async for next_chunk in self._stream_react_generation_with_depth(messages_with_observation, recursion_depth + 1):
                    yield next_chunk
                    
            except Exception as e:
                error_text = f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}\n"
                
                yield {
                    "type": "tool_error",
                    "content": error_text,
                    "error": str(e),
                    "recursion_depth": recursion_depth
                }
        else:
            # æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„actionæˆ–tool_manager
            yield {
                "type": "tool_error", 
                "content": "æ— æ³•è§£æActionæˆ–å·¥å…·ç®¡ç†å™¨ä¸å¯ç”¨\n",
                "error": "Actionè§£æå¤±è´¥æˆ–å·¥å…·ç®¡ç†å™¨ä¸å¯ç”¨",
                "parsed_action": action,
                "has_tool_manager": bool(self.tool_manager)
            }
    
    async def _stream_react_generation_with_depth(self, messages: List[Message], recursion_depth: int = 0) -> AsyncIterator[Dict[str, Any]]:
        """å¸¦é€’å½’æ·±åº¦æ§åˆ¶çš„æµå¼ç”ŸæˆReActå“åº”"""
        if recursion_depth > 10:
            yield {
                "type": "stream_error",
                "content": "\næ¨ç†æ·±åº¦è¶…è¿‡é™åˆ¶ï¼Œåœæ­¢è¿›ä¸€æ­¥åˆ†æ\n",
                "error": "é€’å½’æ·±åº¦è¶…è¿‡æœ€å¤§é™åˆ¶"
            }
            return
            
        accumulated_content = ""
        
        # å®šä¹‰ä¸­æ–­æ£€æŸ¥å™¨ï¼Œç”¨äºæ£€æµ‹ReActçš„Observationæ¨¡å¼
        def should_interrupt_for_observation(content: str) -> bool:
            """æ£€æŸ¥æ˜¯å¦åº”è¯¥å› ä¸ºç©ºObservationè€Œä¸­æ–­ç”Ÿæˆ"""
            return self._should_trigger_tool_execution(content)
        
        # å¼€å§‹æµå¼ç”Ÿæˆ
        try:
            # ä½¿ç”¨doubao llmçš„ä¸­æ–­æœºåˆ¶è¿›è¡Œæµå¼ç”Ÿæˆ
            async for chunk in self.llm.stream_generate(
                messages, 
                interrupt_checker=should_interrupt_for_observation
            ):
                accumulated_content += chunk
                
                # å‘é€æ–‡æœ¬å—
                yield {
                    "type": "text_chunk",
                    "content": chunk,
                    "accumulated": accumulated_content,
                    "recursion_depth": recursion_depth
                }
                
                # æ£€æŸ¥æ˜¯å¦å› ä¸ºObservationè€Œä¸­æ–­äº†
                if should_interrupt_for_observation(accumulated_content):
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨é€»è¾‘
                    async for tool_chunk in self._handle_tool_execution(accumulated_content, messages, recursion_depth):
                        yield tool_chunk
                    return
                            
        except Exception as e:
            yield {
                "type": "stream_error",
                "content": f"\næµå¼ç”Ÿæˆå¼‚å¸¸: {str(e)}\n",
                "error": str(e),
                "recursion_depth": recursion_depth
            }
    
    def _has_filled_observation(self, text: str) -> bool:
        """æ£€æŸ¥Observationæ˜¯å¦å·²ç»æœ‰å†…å®¹"""
        import re
        # åŒ¹é… "Observation:" åé¢æœ‰éç©ºç™½å†…å®¹
        pattern = r'Observation:\s*\S+'
        return bool(re.search(pattern, text))
    
    def _should_trigger_tool_execution(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å·¥å…·æ‰§è¡Œ - æ£€æµ‹ç©ºçš„Observation"""
        import re
        
        # æ£€æŸ¥æ˜¯å¦æœ‰Actionå’ŒAction Input
        has_action = "Action:" in text
        has_action_input = "Action Input:" in text
        has_observation = "Observation:" in text
        
        # åªæœ‰å½“æ‰€æœ‰å¿…è¦å…ƒç´ éƒ½å­˜åœ¨æ—¶æ‰è€ƒè™‘è§¦å‘
        if not (has_action and has_action_input and has_observation):
            return False
        
        # ç‰¹æ®Šæƒ…å†µï¼šæ£€æŸ¥æ˜¯å¦ä»¥"Observation:"ç»“å°¾ï¼ˆæ­£åœ¨ç­‰å¾…å·¥å…·æ‰§è¡Œï¼‰
        if text.rstrip().endswith("Observation:"):
            return True
        
        # æŸ¥æ‰¾æ‰€æœ‰Observationçš„ä½ç½®å’Œå†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç©ºçš„Observation
        observation_matches = list(re.finditer(r'Observation:([^\n]*?)(?=\n|$)', text))
        
        for observation_match in observation_matches:
            observation_content = observation_match.group(1).strip()
            
            # å¦‚æœæ‰¾åˆ°ç©ºçš„Observationï¼Œåˆ™åº”è¯¥è§¦å‘å·¥å…·æ‰§è¡Œ
            if not observation_content:
                return True
        return False
    
    async def _execute_tool(self, tool_name: str, tool_input: str) -> str:
        """æ‰§è¡ŒMCPå·¥å…·ï¼ˆæ”¯æŒè§’è‰²æ’ä»¶è‡ªåŠ¨æ³¨å…¥ï¼‰"""
        if not self.tool_manager:
            return "é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„å·¥å…·ç®¡ç†å™¨"
        
        # ä½¿ç”¨åŸºç±»çš„é€šç”¨å‚æ•°è§£ææ–¹æ³•
        arguments = self.parse_tool_arguments(tool_input)
        
        # è°ƒç”¨å·¥å…· - ä¼˜å…ˆä½¿ç”¨MCPToolManagerçš„å¢å¼ºåŠŸèƒ½
        try:
            # ç›´æ¥ä½¿ç”¨å·¥å…·ç®¡ç†å™¨æ‰§è¡Œå·¥å…·
            print(f"[StreamReactAgentNode._execute_tool] æ‰§è¡Œå·¥å…·: {tool_name}")
            result = await self.tool_manager.execute_tool(tool_name, arguments)
            
            # æ ¼å¼åŒ–ç»“æœ
            if isinstance(result, dict):
                return json.dumps(result, ensure_ascii=False, indent=2)
            elif isinstance(result, (list, tuple)):
                return json.dumps(result, ensure_ascii=False, indent=2)
            else:
                return str(result)
                
        except Exception as e:
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    async def _analyze_tool_result(self, tool_name: str, tool_input: str, tool_result: str, context_content: str) -> str:
        """ä¸“ä¸šåˆ†æå·¥å…·æ‰§è¡Œç»“æœ"""
        
        # åˆ†æç»“æœçš„åŸºæœ¬ä¿¡æ¯
        result_length = len(tool_result)
        
        # æ™ºèƒ½æ£€æµ‹æ‰§è¡ŒçŠ¶æ€ - ä¼˜å…ˆè§£æJSONç»“æ„
        has_error = False
        is_json_result = False
        json_data = None
        
        try:
            # å°è¯•è§£æJSONç»“æœ
            json_data = json.loads(tool_result)
            is_json_result = True
            
            # æ£€æŸ¥JSONç»“æ„ä¸­çš„æˆåŠŸ/é”™è¯¯æ ‡å¿—
            if isinstance(json_data, dict):
                # ä¼˜å…ˆæ£€æŸ¥successå­—æ®µ
                if "success" in json_data:
                    has_error = not json_data["success"]
                # æ£€æŸ¥errorå­—æ®µæ˜¯å¦ä¸ºçœŸå€¼
                elif "error" in json_data:
                    has_error = bool(json_data["error"])
                # æ£€æŸ¥statuså­—æ®µ
                elif "status" in json_data:
                    has_error = json_data["status"] not in ["success", "ok", "200"]
                else:
                    # æ²¡æœ‰æ˜ç¡®æ ‡å¿—ï¼ŒåŸºäºæ•°æ®å†…å®¹åˆ¤æ–­
                    has_error = False
            else:
                # éå­—å…¸ç±»å‹çš„JSONï¼ŒåŸºæœ¬è®¤ä¸ºæ˜¯æˆåŠŸçš„
                has_error = False
                
        except json.JSONDecodeError:
            # éJSONç»“æœï¼Œä½¿ç”¨ä¼ ç»Ÿçš„æ–‡æœ¬æ£€æµ‹
            has_error = ("é”™è¯¯" in tool_result or "å¤±è´¥" in tool_result or 
                        "error:" in tool_result.lower() or
                        "exception:" in tool_result.lower() or
                        tool_result.startswith("å·¥å…·æ‰§è¡Œå¤±è´¥"))
        
        # æ„å»ºä¸“ä¸šåˆ†æ
        analysis_parts = ["æ­£åœ¨åˆ†æå·¥å…·æ‰§è¡Œç»“æœ..."]
        
        # 1. æ‰§è¡ŒçŠ¶æ€åˆ†æ
        if has_error:
            analysis_parts.append("âš ï¸ å·¥å…·æ‰§è¡Œé‡åˆ°å¼‚å¸¸")
            if is_json_result and json_data:
                error_detail = json_data.get("error", json_data.get("message", "æœªçŸ¥é”™è¯¯"))
                analysis_parts.append(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
            else:
                analysis_parts.append(f"é”™è¯¯è¯¦æƒ…: {tool_result}")
        else:
            analysis_parts.append("âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
            
            # å¯¹æˆåŠŸç»“æœè¿›è¡Œè¯¦ç»†åˆ†æ
            if is_json_result and json_data:
                if isinstance(json_data, dict):
                    # åˆ†æè¿”å›çš„æ•°æ®ç»“æ„
                    if "count" in json_data:
                        count = json_data["count"]
                        analysis_parts.append(f"ğŸ“Š æ•°æ®é‡: è¿”å›{count}æ¡è®°å½•")
                    
                    if "profiles" in json_data:
                        profiles = json_data["profiles"]
                        if profiles:
                            analysis_parts.append(f"ğŸ‘¤ è§’è‰²ä¿¡æ¯: æ‰¾åˆ°{len(profiles)}ä¸ªè§’è‰²æ¡£æ¡ˆ")
                        else:
                            analysis_parts.append("ğŸ‘¤ è§’è‰²ä¿¡æ¯: æœªæ‰¾åˆ°åŒ¹é…çš„è§’è‰²")
                    
                    if "data" in json_data:
                        data = json_data["data"]
                        if isinstance(data, list):
                            analysis_parts.append(f"ğŸ“‹ æ•°æ®é›†: {len(data)}ä¸ªæ¡ç›®")
                        elif isinstance(data, dict):
                            analysis_parts.append("ğŸ“‹ ç»“æ„åŒ–æ•°æ®å¯¹è±¡")
        
        # 2. æ•°æ®è´¨é‡è¯„ä¼°
        if result_length == 0:
            analysis_parts.append("ğŸ“Š è¿”å›æ•°æ®ä¸ºç©ºï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°")
        elif result_length < 50:
            analysis_parts.append("ğŸ“Š è¿”å›ç®€çŸ­ç»“æœï¼Œæ•°æ®é‡è¾ƒå°")
        elif result_length > 1000:
            analysis_parts.append("ğŸ“Š è¿”å›å¤§é‡æ•°æ®ï¼Œä¿¡æ¯ä¸°å¯Œ")
        else:
            analysis_parts.append("ğŸ“Š è¿”å›é€‚é‡æ•°æ®")
        
        # 3. ç»“æœç±»å‹åˆ†æ
        if is_json_result:
            analysis_parts.append("ğŸ” ç»“æœä¸ºç»“æ„åŒ–JSONæ•°æ®")
        elif tool_result.strip():
            if "\n" in tool_result:
                analysis_parts.append("ğŸ” ç»“æœä¸ºå¤šè¡Œæ–‡æœ¬æ•°æ®")
            else:
                analysis_parts.append("ğŸ” ç»“æœä¸ºå•è¡Œæ–‡æœ¬æ•°æ®")
        
        # 4. åŸºäºä¸Šä¸‹æ–‡åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­
        thought_count = context_content.count("Thought:")
        if thought_count >= 5:
            analysis_parts.append("ğŸ”„ å·²è¿›è¡Œå¤šè½®åˆ†æï¼Œå»ºè®®æ€»ç»“ç»“è®º")
        elif has_error:
            analysis_parts.append("ğŸ”„ å»ºè®®å°è¯•å…¶ä»–å·¥å…·æˆ–è°ƒæ•´å‚æ•°")
        elif "Final Answer" not in context_content:
            analysis_parts.append("ğŸ”„ å¯ä»¥åŸºäºæ­¤ç»“æœç»§ç»­åˆ†ææˆ–ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ")
        
        # 5. åˆ†æå®ŒæˆçŠ¶æ€
        analysis_parts.append("âœ¨ ç»“æœåˆ†æå®Œæˆ")
        
        # 6. å®é™…å·¥å…·ç»“æœï¼ˆç®€åŒ–æ˜¾ç¤ºï¼Œä½†å¯¹äºè§’è‰²ä¿¡æ¯è¦æ˜¾ç¤ºå…³é”®å†…å®¹ï¼‰
        if tool_name.startswith('role_info_') and is_json_result and json_data:
            # è§’è‰²ä¿¡æ¯å·¥å…·çš„ç‰¹æ®Šå¤„ç†
            if isinstance(json_data, dict) and "profiles" in json_data:
                profiles = json_data["profiles"]
                if profiles:
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªè§’è‰²çš„å…³é”®ä¿¡æ¯
                    first_profile = profiles[0]
                    key_info = []
                    for key in ["name", "age", "personality", "background", "description"]:
                        if key in first_profile:
                            value = first_profile[key]
                            if len(str(value)) > 100:
                                value = str(value)[:100] + "..."
                            key_info.append(f"{key}: {value}")
                    
                    analysis_parts.append(f"\nğŸ“‹ è§’è‰²æ¡£æ¡ˆé¢„è§ˆ:\n" + "\n".join(key_info))
                    
                    if len(profiles) > 1:
                        analysis_parts.append(f"ï¼ˆè¿˜æœ‰{len(profiles)-1}ä¸ªç›¸å…³è§’è‰²æ¡£æ¡ˆï¼‰")
                else:
                    analysis_parts.append(f"\nğŸ“‹ å·¥å…·è¾“å‡º:\n{tool_result}")
            else:
                # å…¶ä»–è§’è‰²å·¥å…·ç»“æœ
                if len(tool_result) > 500:
                    display_result = tool_result[:500] + "...[ç»“æœå·²æˆªæ–­]"
                else:
                    display_result = tool_result
                analysis_parts.append(f"\nğŸ“‹ å·¥å…·è¾“å‡º:\n{display_result}")
        else:
            # æ™®é€šå·¥å…·ç»“æœå¤„ç†
            if len(tool_result) > 1000:
                display_result = tool_result[:1000] + "...[ç»“æœå·²æˆªæ–­]"
            else:
                display_result = tool_result
                
            analysis_parts.append(f"\nğŸ“‹ å·¥å…·è¾“å‡º:\n{display_result}")
        
        return "\n".join(analysis_parts)

    def _build_system_prompt(self, context: Any) -> str:
        """æ„å»ºæµå¼ReActç³»ç»Ÿæç¤ºè¯ - ä¸“ä¸šAIåŠ©æ‰‹ç‰ˆæœ¬"""
        base_prompt = ""
        
        print(f"[StreamReactAgentNode._build_system_prompt] å¼€å§‹æ„å»º")
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–è®°å¿†ä¿¡æ¯
        memory_context = ""
        if hasattr(context, 'variables') and context.variables:
            memory_context = context.variables.get("memory_context", "")
            print(f"[StreamReactAgentNode._build_system_prompt] è®°å¿†ä¸Šä¸‹æ–‡: {len(memory_context)}å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§’è‰²ä¿¡æ¯æŸ¥è¯¢å·¥å…·
            if self.tool_manager and hasattr(self.tool_manager, 'list_tools'):
                try:
                    available_tools = self.tool_manager.list_tools()
                    role_info_tools = [tool for tool in available_tools if tool.startswith('role_info_')]
                    if role_info_tools:
                        base_prompt += "=== è§’è‰²ä¿¡æ¯ç³»ç»Ÿ ===\n"
                        base_prompt += "å¦‚éœ€è·å–è§’è‰²è®¾å®šï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š\n"
                        base_prompt += "- role_info_query_profile: æŸ¥è¯¢è§’è‰²äººè®¾\n"
                        base_prompt += "- role_info_search_knowledge: æœç´¢è§’è‰²çŸ¥è¯†åº“\n"
                        base_prompt += "- role_info_get_role_context: è·å–å®Œæ•´è§’è‰²ä¸Šä¸‹æ–‡\n\n"
                        print(f"[StreamReactAgentNode._build_system_prompt] æ£€æµ‹åˆ°{len(role_info_tools)}ä¸ªè§’è‰²ä¿¡æ¯å·¥å…·")
                except Exception as e:
                    print(f"æ£€æŸ¥è§’è‰²ä¿¡æ¯å·¥å…·å¤±è´¥: {e}")
        
        # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
        if memory_context:
            base_prompt += f"=== ç›¸å…³å†å²ä¿¡æ¯ ===\n{memory_context}\n\n"
        
        # è·å–å·¥å…·æè¿°
        tools_desc = ""
        tool_names = []
        
        # ä»å·¥å…·ç®¡ç†å™¨è·å–å·¥å…·ä¿¡æ¯
        if self.tool_manager:
            tools_desc = self.tool_manager.get_tools_description()
            tool_names = self.tool_manager.list_tools()
            print(f"[StreamReactAgentNode._build_system_prompt] å·¥å…·: {tool_names}")
        
        # ä¸“ä¸šAIåŠ©æ‰‹ReActæç¤ºè¯æ¨¡æ¿
        if tools_desc:
            base_prompt += "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œå…·å¤‡å¼ºå¤§çš„æ¨ç†å’Œåˆ†æèƒ½åŠ›ã€‚ä½ å¯ä»¥ä½¿ç”¨å¤šç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚\n\n"
            base_prompt += f"å¯ç”¨å·¥å…·ï¼š\n{tools_desc}\n\n"
            base_prompt += "æ¨ç†æ ¼å¼ï¼š\n"
            base_prompt += "Question: ç”¨æˆ·æå‡ºçš„é—®é¢˜\n"
            base_prompt += "Thought: å¯¹é—®é¢˜çš„åˆ†æå’Œæ€è€ƒè¿‡ç¨‹\n"
            base_prompt += f"Action: é€‰æ‹©æ‰§è¡Œçš„å·¥å…·ï¼Œå¿…é¡»æ˜¯ [{', '.join(tool_names)}] ä¸­çš„ä¸€ä¸ª\n"
            base_prompt += "Action Input: å·¥å…·çš„è¾“å…¥å‚æ•°\n"
            base_prompt += "Observation: å¯¹å·¥å…·æ‰§è¡Œç»“æœçš„åˆ†æå’Œè¯„ä¼°\n"
            base_prompt += "... (å¯ä»¥é‡å¤è¿™ä¸ªæ¨ç†å¾ªç¯ï¼Œç›´åˆ°è·å¾—æ»¡æ„çš„ç»“æœ)\n"
            base_prompt += "Thought: åŸºäºæ‰€æœ‰ä¿¡æ¯çš„æœ€ç»ˆåˆ†æ\n"
            base_prompt += "Final Answer: ç»™ç”¨æˆ·çš„æœ€ç»ˆä¸“ä¸šå›å¤\n\n"
            base_prompt += "å·¥ä½œåŸåˆ™ï¼š\n"
            base_prompt += "1. ğŸ“‹ ä»”ç»†åˆ†æç”¨æˆ·é—®é¢˜ï¼Œåˆ¶å®šåˆç†çš„è§£å†³æ–¹æ¡ˆ\n"
            base_prompt += "2. ğŸ› ï¸ åˆç†é€‰æ‹©å’Œä½¿ç”¨å·¥å…·è·å–æ‰€éœ€ä¿¡æ¯\n"
            base_prompt += "3. ğŸ” åœ¨Observationä¸­æ·±å…¥åˆ†æå·¥å…·ç»“æœçš„æœ‰æ•ˆæ€§å’Œè´¨é‡\n"
            base_prompt += "4. ğŸ”„ å¦‚æœä¿¡æ¯ä¸è¶³æˆ–ç»“æœä¸æ»¡æ„ï¼Œç»§ç»­æ¨ç†å¾ªç¯\n"
            base_prompt += "5. âœ… ç¡®ä¿å›ç­”å®Œæ•´ã€å‡†ç¡®ã€æœ‰ç”¨\n"
            base_prompt += "6. ğŸ’¡ å……åˆ†åˆ©ç”¨å†å²ä¿¡æ¯æä¾›è¿è´¯çš„æœåŠ¡\n"
            base_prompt += "7. ğŸ­ å¦‚éœ€è§’è‰²æ‰®æ¼”ï¼Œå…ˆè·å–è§’è‰²è®¾å®šï¼Œç„¶åæŒ‰ç…§è§’è‰²ç‰¹å¾å›åº”\n"
            base_prompt += "8. ğŸ“ ä¿æŒå›å¤çš„ä¸“ä¸šæ€§å’Œç®€æ´æ€§\n\n"
            base_prompt += "ç°åœ¨å‡†å¤‡ä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„AIåŠ©æ‰‹æœåŠ¡ã€‚"
            print(f"[StreamReactAgentNode._build_system_prompt] ä½¿ç”¨ä¸“ä¸šåŠ©æ‰‹å·¥å…·æ¨¡æ¿")
        else:
            base_prompt += "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œå…·å¤‡ä¸°å¯Œçš„çŸ¥è¯†å’Œåˆ†æèƒ½åŠ›ã€‚\n"
            base_prompt += "è™½ç„¶å½“å‰æ²¡æœ‰å¤–éƒ¨å·¥å…·å¯ç”¨ï¼Œä½†æˆ‘ä¼šåŸºäºæˆ‘çš„çŸ¥è¯†åº“ä¸ºä½ æä¾›ä¸“ä¸šçš„å¸®åŠ©ã€‚\n"
            base_prompt += "å¦‚æœé—®é¢˜è¶…å‡ºæˆ‘çš„çŸ¥è¯†èŒƒå›´ï¼Œæˆ‘ä¼šè¯šå®åœ°å‘ŠçŸ¥å¹¶å»ºè®®å…¶ä»–è§£å†³æ–¹æ¡ˆã€‚\n"
            base_prompt += "æˆ‘ä¼šå……åˆ†åˆ©ç”¨å†å²ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ä¸ºä½ æä¾›è¿è´¯ã€å‡†ç¡®çš„å›å¤ã€‚\n"
            base_prompt += "ç°åœ¨è¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚"
            print(f"[StreamReactAgentNode._build_system_prompt] ä½¿ç”¨ä¸“ä¸šåŠ©æ‰‹æ— å·¥å…·æ¨¡æ¿")
        
        print(f"[StreamReactAgentNode._build_system_prompt] å®Œæˆï¼Œæ€»é•¿åº¦: {len(base_prompt)}")
        return base_prompt

    async def stream_execute(self, input_data: NodeInput) -> AsyncIterator[Dict[str, Any]]:
        """æµå¼æ‰§è¡Œæ–¹æ³• - ä¸“é—¨ç”¨äºæµå¼å¤„ç†"""
        context = input_data.context
        
        # è·å–å¯¹è¯å†å²
        messages = context.messages.copy()
        
        # æ·»åŠ ç³»ç»Ÿæç¤º
        system_prompt = self._build_system_prompt(context)
        print(f"[StreamReactAgentNode.stream_execute] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}")
        
        if not any(msg.role == MessageRole.SYSTEM for msg in messages):
            messages.insert(0, Message(
                role=MessageRole.SYSTEM,
                content=system_prompt
            ))
            print(f"[StreamReactAgentNode.stream_execute] å·²æ·»åŠ ç³»ç»Ÿæç¤ºè¯")
        else:
            print(f"[StreamReactAgentNode.stream_execute] å·²å­˜åœ¨ç³»ç»Ÿæç¤ºè¯ï¼Œè·³è¿‡")
        
        # ç›´æ¥è¿›è¡Œæµå¼ç”Ÿæˆ
        async for chunk_data in self._stream_react_generation(messages):
            yield chunk_data 